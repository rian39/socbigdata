<!DOCTYPE html><html>
<head>
<title></title>
<style type="text/css">
<!--
.xflip {
    -moz-transform: scaleX(-1);
    -webkit-transform: scaleX(-1);
    -o-transform: scaleX(-1);
    transform: scaleX(-1);
    filter: fliph;
}
.yflip {
    -moz-transform: scaleY(-1);
    -webkit-transform: scaleY(-1);
    -o-transform: scaleY(-1);
    transform: scaleY(-1);
    filter: flipv;
}
.xyflip {
    -moz-transform: scaleX(-1) scaleY(-1);
    -webkit-transform: scaleX(-1) scaleY(-1);
    -o-transform: scaleX(-1) scaleY(-1);
    transform: scaleX(-1) scaleY(-1);
    filter: fliph + flipv;
}
-->
</style>
</head>
<body>
<a name=1></a>Supplementary&#160;Appendix&#160;-&#160;Socialising&#160;Big&#160;Data:&#160;From&#160;concept&#160;to&#160;<br/>practice&#160;&#160;<br/>	  <br/>
<b>Background&#160;<br/></b><i>Socialising	  Big	  Data:	  Identifying	  the	  risks	  and	  vulnerabilities	  of	  data-­‐objects</i>	  was	  an	  Economic	  <br/>and	  Social	  Research	  Council	  (ESRC)	  funded	  project	  that	  took	  place	  from	  June	  2013	  to	  Sept	  2014.	  <br/>It	  involved	  col&#160;aboration	  between	  social	  scientists	  from	  a	  range	  of	  backgrounds	  (sociology,	  <br/>anthropology,	  and	  science	  and	  technology	  studies),	  many	  of	  who	  were	  affiliated	  with	  the	  <br/>Centre	  for	  Research	  on	  Socio-­‐Cultural	  Change	  (CRESC	  Manchester	  and	  The	  Open	  University)	  <br/>and	  the	  Centre	  for	  Economic	  and	  Social	  Aspects	  of	  Genomics	  (CESAGEN	  Lancaster),	  but	  also	  <br/>including	  other	  institutions.1	  The	  project	  aimed	  to	  advance	  the	  social	  scientific	  analysis	  of	  Big	  <br/>Data	  and	  digital	  practices	  to	  benefit	  academics,	  students,	  practitioners	  and	  policy	  makers.	  It	  did	  <br/>this	  by	  conducting	  three	  separate	  col&#160;aboratories	  with	  practitioners	  in	  turn	  from	  bioscience,	  <br/>national	  statistics	  and	  waste	  management.	  A	  final	  col&#160;aboratory	  brought	  together	  participants	  <br/>from	  all	  three.	  The	  project	  results	  were	  published	  in	  a	  CRESC	  working	  paper,	  <i>Socialising	  Big	  <br/>Data:	  From	  concept	  to	  practice	  </i>(available	  at:	  http://www.cresc.ac.uk/publications/working-­‐<br/>papers/).	  This	  document	  is	  a	  Supplement	  to	  that	  working	  paper	  and	  consists	  of	  summaries	  of	  <br/>the	  presentations	  and	  discussions	  at	  each	  of	  the	  col&#160;aboratories,	  beginning	  with	  the	  final	  one.	  <br/>
	  <br/>
&#160;<br/>
	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  <br/>
1	  PI:	  Evelyn	  Ruppert,	  Goldsmiths,	  University	  of	  London.	  Co-­‐Is:	  Penny	  Harvey,	  Manchester,	  CRESC;	  Celia	  Lury,	  Centre	  <br/>for	  Interdisciplinary	  Methodologies,	  Warwick;	  Adrian	  Mackenzie,	  Lancaster;	  Ruth	  McNal&#160;y,	  Anglia	  Ruskin.	  <br/>Researchers:	  Stephanie	  Alice	  Baker,	  Goldsmiths,	  University	  of	  London;	  Yannis	  Kal&#160;ianos	  and	  Camil&#160;a	  Lewis,	  <br/>University	  of	  Manchester,	  CRESC.	  <br/>
<hr/>
<a name=2></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
Appendix&#160;A:&#160;Summary&#160;of&#160;Final&#160;Collaboratory&#160;&#160;<br/>The	  collaboratory	  begin	  with	  a	  provocative	  presentation	  on	  ‘Big	  Data	  Claims’	  by	  one	  of	  the	  <br/>project	  team	  members,	  Adrian	  Mackenzie	  from	  the	  University	  of	  Lancaster.	  &#160;The	  rest	  of	  the	  <br/>col&#160;aboratory	  involved	  four	  sessions	  each	  focused	  on	  one	  of	  the	  four	  crosscutting	  themes	  –	  <br/>metrics,	  economies,	  ethics	  and	  col&#160;aboratories.	  &#160;Each	  started	  with	  a	  plenary	  presentation	  by	  a	  <br/>practitioner	  from	  one	  context	  fol&#160;owed	  by	  respondents	  from	  the	  other	  two.	  &#160;Participants	  were	  <br/>then	  divided	  into	  three	  breakout	  roundtables	  consisting	  of	  a	  mix	  of	  practitioners	  and	  project	  <br/>team	  members	  to	  discuss	  the	  theme	  and	  then	  report	  back	  to	  the	  group.	  &#160;The	  col&#160;aboratory	  <br/>ended	  with	  a	  plenary	  discussion	  of	  the	  col&#160;aboratory	  as	  a	  method	  and	  proposals	  for	  next	  steps.	  <br/>
<b>Crosscutting&#160;Theme&#160;1:&#160;Metrics&#160;</b><br/>
<b>Plenary Presentation: Will Spooner,&#160;Eagle&#160;Genomics&#160;&#160;&#160;<br/></b>Wil&#160;	  Spooner	  discussed	  data	  metrics	  in	  genomic	  science.	  The	  field	  of	  genomics	  has	  been	  <br/>working	  with	  Big	  Data	  for	  about	  fifteen	  years	  and	  is	  therefore	  in	  a	  comparably	  advanced	  <br/>position	  compared	  to	  the	  other	  practical	  contexts.	  Genomic	  practitioners	  are	  interested	  in	  how	  <br/>they	  can	  <i>accurately	  </i>analyse	  data	  from	  integrated	  sources.	  Big	  Data	  is	  often	  defined	  in	  terms	  of	  <br/>the	  three	  Vs:	  volume,	  velocity	  and	  variety.	  Volume	  and	  velocity	  are	  becoming	  less	  of	  an	  issue	  <br/>and	  instead	  Wil&#160;	  suggested	  that	  a	  fourth	  ‘V’	  is	  becoming	  more	  important:	  veracity.	  <br/>
In	  the	  last	  decade,	  hybridisation	  technology	  was	  introduced	  which	  enabled	  analysis	  of	  specific	  <br/>parts	  –	  or	  the	  ‘signature’–	  of	  the	  gene.	  This	  technology	  was	  highly	  successful	  but	  it	  was	  subject	  <br/>to	  instrument	  specific	  biases,	  which	  made	  comparing	  data	  from	  other	  studies	  increasingly	  <br/>difficult.	  In	  the	  last	  five	  years,	  new	  technologies	  have	  been	  introduced	  which	  are	  not	  subject	  to	  <br/>the	  same	  biases	  as	  the	  older	  instruments.	  Nevertheless,	  they	  introduce	  a	  new	  set	  of	  biases	  <br/>(more	  data	  does	  not	  mean	  no	  biases)	  when	  measuring	  the	  genome	  sequence.	  One	  of	  the	  <br/>problems	  of	  working	  with	  Big	  Data	  is	  that	  there	  is	  no	  ‘truth	  set’	  and	  this	  givens	  rise	  to	  the	  issue	  <br/>of	  veracity.	  In	  light	  of	  this,	  genomic	  scientists	  are	  trying	  to	  discover	  new	  ways	  in	  which	  data	  can	  <br/>be	  integrated	  and	  remain	  accurate.	  <br/>
Big	  Data	  is	  systematic	  and	  holistic.	  The	  data	  at	  the	  scale	  that	  genomic	  scientists	  work	  with	  is	  <br/>systematic	  and	  covers	  an	  entire	  range	  (e.g.	  the	  whole	  genome).	  Big	  Data	  metrics	  reveal	  <br/>different	  facets	  or	  constitute	  a	  ‘cut	  through’	  that	  range.	  &#160;Today,	  genomic	  scientists	  integrate	  the	  <br/>data	  so	  different	  stakeholders	  can	  make	  use	  of	  it	  (e.g.	  patients,	  clinical	  researchers,	  molecular	  <br/>biologists).	  In	  the	  field	  of	  genomics,	  Big	  Data	  can	  give	  stakeholders	  slices	  through	  these	  very	  <br/>large	  data	  sets.	  The	  notion	  of	  the	  boundary-­‐object,	  as	  employed	  in	  the	  social	  sciences	  and	  <br/>outlined	  in	  the	  working	  paper,	  could	  provide	  a	  useful	  way	  to	  explore	  this	  further.	  <br/>
2	  <br/>
	  <br/>
<hr/>
<a name=3></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
<b>Respondent:&#160;Michail Skaliotis, Eurostat&#160;&#160;&#160;<br/></b>•&#160;&#160;Big	  Data	  ecosystems	  require	  new	  ways	  of	  thinking	  about	  data	  and	  the	  roles	  of	  national	  <br/>
statisticians.	  &#160;Within	  these	  ecosystems	  statisticians	  no	  longer	  design	  and	  produce	  data	  and	  <br/>
need	  to	  think	  about	  and	  approach	  data	  in	  new	  ways.	  Practitioners	  in	  this	  field	  are	  stil&#160;	  <br/>investigating	  what	  can	  be	  done	  with	  new	  forms	  of	  data	  beyond	  those	  produced	  by	  <br/>
traditional	  methods.	  <br/>
•&#160;&#160;At	  present,	  national	  statisticians	  are	  facing	  enormous	  change.	  They	  must	  transform	  their	  <br/>
existing	  infrastructures	  and	  practices	  at	  a	  time	  of	  budget	  restraints.	  One	  of	  the	  main	  <br/>
challenges	  that	  lies	  ahead	  relates	  to	  data	  analysis	  –	  how	  can	  the	  vast	  quantities	  of	  data	  <br/>
available	  be	  made	  into	  meaningful	  metrics	  and	  information?	  There	  are	  also	  many	  risks	  <br/>
associated	  with	  predictive	  analytics.	  These	  issues	  require	  further	  debate	  among	  <br/>
statisticians.	  <br/>
•&#160;&#160;What	  is	  required	  is	  clear	  communication	  of	  the	  risks	  and	  benefits	  of	  working	  with	  Big	  Data.	  <br/>
The	  issues	  wil&#160;	  differ	  depending	  on	  whether	  the	  audience	  is	  practitioners,	  health	  care	  <br/>
operators	  or	  individuals.	  In	  the	  context	  of	  national	  statistics,	  for	  example,	  there	  is	  concern	  <br/>
about	  how	  to	  communicate	  these	  risks	  and	  benefits	  to	  different	  stakeholder	  groups.	  <br/>
•&#160;&#160;Ethical	  codes	  are	  required	  for	  data	  analysis	  because	  of	  new	  security	  concerns.	  Responsibility	  <br/>
is	  generally	  placed	  on	  users	  to	  secure	  their	  data.	  There	  needs	  to	  be	  more	  responsibility	  <br/>
taken	  from	  IT	  specialists	  to	  strengthen	  security	  precautions	  and	  to	  limit	  the	  risks	  associated	  <br/>
with	  data	  storage.	  	  <br/>
•&#160;&#160;It	  is	  generally	  assumed	  that	  genomic	  science	  is	  very	  precise,	  but	  this	  col&#160;aboratory	  has	  <br/>
shown	  that	  genomic	  scientists	  stil&#160;	  face	  many	  outstanding	  questions	  similar	  to	  those	  facing	  <br/>
statisticians	  and	  waste	  practitioners.	  <br/>
<b>Respondent:&#160;Joanna&#160;Hayduk,&#160;WRAP&#160;<br/></b>•&#160;&#160;There	  is	  plenty	  of	  data	  in	  waste	  management	  but	  this	  data	  is	  not	  considered	  ‘Big	  Data’	  per	  <br/>
se.	  Practitioners	  are	  only	  beginning	  to	  think	  about	  how	  Big	  Data	  could	  be	  used	  in	  this	  <br/>
domain.	  Given	  that	  local	  authorities	  are	  facing	  austerity	  cuts,	  one	  key	  question	  is	  whether	  <br/>
Big	  Data	  could	  lead	  to	  efficiency	  gains	  by	  reducing	  costs.<b>	  </b><br/>
•&#160;&#160;At	  present,	  tonnage	  is	  the	  most	  commonly	  accepted	  metric	  used	  by	  practitioners	  to	  <br/>
measure	  waste.	  If	  the	  industry	  embraces	  new	  data	  sources,	  this	  wil&#160;	  raise	  questions	  around	  <br/>
alternative	  metrics	  (e.g.	  what	  units	  wil&#160;	  they	  measure?).	  <br/>
•&#160;&#160;It	  is	  very	  challenging	  to	  create	  a	  consistent	  data	  set	  about	  waste	  in	  the	  UK.	  The	  404	  waste	  <br/>
col&#160;ection	  authorities	  across	  the	  UK	  all	  operate	  slightly	  differently	  (e.g.	  some	  col&#160;ect	  waste	  in	  <br/>
house	  while	  others	  contract	  out,	  different	  col&#160;ection	  regimes	  etc.)	  and	  it	  can	  be	  difficult	  to	  <br/>
develop	  consistent	  and	  comparable	  metrics.<b>	  </b><br/>
<b>Discussion&#160;</b><br/>
Group 1&#160;<br/>
•&#160;&#160;Group	  1	  discussed	  the	  quality	  and	  sustainability	  of	  new	  forms	  of	  data.	  For	  example,	  how	  <br/>
could	  Big	  Data	  supplement	  existing	  data	  sources?	  Would	  Big	  Data	  involve	  the	  same	  metrics?	  <br/>Could	  it	  be	  used	  to	  save	  costs	  of	  data	  col&#160;ection?	  Can	  it	  be	  used	  to	  increase	  recycling	  rates	  <br/>
which	  in	  turn	  can	  improve	  scarce	  resource	  management?	  <br/>
3	  <br/>
	  <br/>
<hr/>
<a name=4></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
•&#160;&#160;Big	  Data	  raises	  issues	  around	  certainty	  and	  trust.	  Existing	  approaches	  such	  as	  the	  analysis	  of	  <br/>
time-­‐series	  data	  are	  wel&#160;	  established	  and	  trusted.	  Wil&#160;	  new	  forms	  of	  data	  be	  trusted?	  How	  <br/>
can	  we	  ensure	  that	  new	  data	  forms	  remain	  reliable?	  Would	  it	  be	  possible	  to	  make	  <br/>
comparisons	  between	  Big	  Data	  sources	  and	  existing	  time-­‐series	  data?	  Could	  they	  be	  <br/>
integrated?	  <b>	  </b><br/>
•&#160;&#160;Big	  Data	  doesn’t	  always	  have	  a	  purpose.	  This	  makes	  it	  difficult	  to	  anticipate	  in	  advance	  what	  <br/>
the	  missing	  metrics	  wil&#160;	  be.	  <br/>
•&#160;&#160;This	  raises	  a	  fundamental	  question,	  what	  is	  a	  metric?	  A	  metric	  is	  generally	  understood	  as	  <br/>
something	  standardised	  that	  counts	  units	  of	  some	  kind.	  Once	  a	  metric	  has	  been	  given	  a	  <br/>
label	  how	  can	  it	  change?	  For	  example,	  there	  could	  be	  two	  metrics	  that	  measure	  exactly	  the	  <br/>
same	  thing	  but	  are	  used	  for	  different	  purposes.	  Once	  you	  have	  a	  metric	  how	  difficult	  is	  it	  to	  <br/>
change	  it?	  There	  could	  be	  opposition	  to	  change	  existing	  metrics	  that	  are	  well	  established	  <br/>
(e.g.	  tons	  in	  waste	  management).	  <br/>
Group 2&#160;<br/>
•&#160;&#160;How	  do	  you	  determine	  what	  is	  relevant	  when	  deciding	  to	  join	  up	  different	  data	  sets?	  In	  <br/>
practice,	  we	  do	  not	  have	  the	  luxury	  of	  endless	  analysis.	  Decisions	  have	  to	  be	  made	  at	  early	  <br/>
stages	  of	  analysis	  such	  as	  deciding	  what	  data	  is	  ‘important’	  and	  how	  it	  can	  be	  translated	  <br/>
into	  meaningful	  information.	  More	  data	  is	  not	  necessarily	  the	  solution.	  &#160;The	  right	  data	  is	  key	  <br/>
and	  the	  challenge	  is	  identifying	  this	  upfront	  and	  then	  making	  decisions	  about	  where	  to	  <br/>
invest	  resources.	  <br/>
•&#160;&#160;There	  has	  been	  a	  move	  from	  prescriptive	  to	  predictive	  analytics.	  Practitioners	  in	  all	  three	  <br/>
fields	  (genomics,	  national	  statistics,	  waste	  management)	  must	  thus	  think	  ahead	  and	  be	  <br/>
prepared	  to	  make	  adjustments	  as	  one	  goes	  along	  and	  things	  change.	  Incremental	  and	  <br/>
iterative	  experiments	  provide	  one	  way	  of	  managing	  this	  relationship.<b>	  </b><br/>
•&#160;&#160;Currently,	  there	  are	  no	  mechanisms	  for	  pooling	  examples	  of	  experiments	  and	  analysing	  <br/>
them	  col&#160;ectively.	  They	  tend	  to	  happen	  on	  a	  smaller	  and	  large-­‐scale	  sharing	  is	  not	  <br/>
happening.	  <br/>
•&#160;&#160;We	  are	  moving	  potentially,	  in	  the	  next	  five	  to	  ten	  years,	  to	  an	  internet	  of	  things	  beyond	  our	  <br/>
imagination	  in	  light	  of	  rapid	  technological	  change.	  As	  a	  consequence,	  redundancy	  needs	  to	  <br/>
be	  built	  into	  systems.	  New	  sensors,	  online	  devices,	  wearable	  devices	  wil&#160;	  be	  generating	  data	  <br/>
in	  ways	  we	  cannot	  imagine.	  The	  generation	  of	  data	  in	  everyday	  lives	  is	  pervasive;	  many	  <br/>
aspects	  of	  lives	  are	  now	  made	  into	  data.	  What	  wil&#160;	  that	  mean	  in	  the	  future	  of	  Big	  Data?	  <b>	  </b><br/>
•&#160;&#160;Veracity	  –	  the	  reliability	  and	  verifiability	  of	  data	  -­‐	  wil&#160;	  likely	  become	  more	  important	  and	  <br/>
those	  sources	  that	  cannot	  demonstrate	  this	  wil&#160;	  likely	  not	  be	  taken	  up.	  	  <b>	  </b><br/>
Group 3&#160;<br/>
•&#160;&#160;New	  metrics	  are	  emerging.	  For	  example,	  national	  statisticians	  are	  trialling	  new	  (real-­‐time)	  <br/>
methods	  such	  as	  using	  social	  media	  platforms	  (e.g.	  Twitter	  and	  Facebook)	  to	  col&#160;ect	  data.	  <br/>
One	  of	  the	  advantages	  of	  these	  sources	  is	  that	  they	  provide	  good	  data	  about	  young	  people.	  <br/>
Smart	  metres	  in	  homes	  also	  provide	  data	  about	  things	  such	  as	  occupancy	  rates.	  <br/>
•&#160;&#160;An	  example	  of	  how	  Big	  Data	  is	  currently	  being	  analysed	  involves	  the	  scraping	  of	  data	  from	  <br/>
websites	  in	  order	  to	  calculate	  the	  rate	  of	  inflation	  by	  comparing	  a	  particular	  number	  of	  <br/>
4	  <br/>
	  <br/>
<hr/>
<a name=5></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
products	  weekly.	  To	  improve	  accuracy,	  measurements	  can	  be	  taken	  at	  different	  intervals	  <br/>
and	  compared.	  	  <br/>
•&#160;&#160;One	  of	  the	  key	  characteristics	  of	  Big	  Data	  is	  that	  it	  can	  be	  re-­‐purposed	  and	  integrated	  with	  <br/>
other	  data	  sets.	  However,	  working	  with	  Big	  Data	  in	  this	  way	  raises	  issues	  around	  data	  <br/>
ownership	  and	  consent.	  When	  is/should	  consent	  be	  given?	  Is	  it	  possible	  for	  individuals	  to	  <br/>
negotiate	  how	  and	  where	  their	  data	  travels?	  &#160;	  <br/>
<b>Crosscutting&#160;Theme&#160;2:&#160;Economies&#160;</b><br/>
<b>Plenary Presentation: Barteld Braaksma, Statistics&#160;Netherlands&#160;&#160;<br/></b>Barteld	  Braaksma	  discussed	  the	  potential	  of	  scarcity	  to	  drive	  economies	  of	  Big	  Data	  in	  an	  <br/>environment	  that	  is	  facing	  severe	  budget	  cuts.	  However,	  careful	  decisions	  must	  be	  made	  about	  <br/>where	  to	  target	  resources	  especially	  in	  the	  face	  a	  lot	  of	  ‘hype’	  around	  Big	  Data.	  In	  spite	  of	  its	  <br/>potential,	  there	  is	  considerable	  uncertainty	  about	  the	  results	  of	  analyses	  and	  this	  makes	  <br/>securing	  future	  investment	  difficult.	  Processing	  and	  analysing	  Big	  Data	  also	  requires	  new	  <br/>technology	  and	  new	  technical	  capacities.	  Within	  the	  climate	  of	  uncertainty	  the	  challenge	  is	  thus	  <br/>how	  to	  prioritise	  resources	  to	  devote	  to	  Big	  Data.	  This	  is	  a	  common	  situation	  in	  the	  commercial	  <br/>world	  but	  the	  public	  sector	  is	  generally	  more	  risk	  adverse.	  	  <br/>
Statisticians	  were	  traditionally	  the	  only	  practitioners	  who	  could	  conduct	  large-­‐scale	  surveys	  of	  <br/>populations,	  but	  now	  the	  situation	  has	  been	  reversed.	  Statisticians	  do	  not	  own	  Big	  Data	  <br/>sources.	  In	  the	  past	  they	  were	  the	  ‘haves’	  and	  now	  they	  have	  become	  the	  ‘have	  nots’.	  At	  the	  <br/>same	  time,	  col&#160;ecting	  data	  in	  new	  ways	  (rather	  than	  asking	  people	  through	  surveys)	  could	  be	  <br/>more	  time	  efficient	  and	  cheaper	  and	  thereby	  address	  the	  challenge	  of	  resource	  scarcity.	  There	  <br/>is	  a	  strong	  feeling	  that	  these	  changes	  cannot	  be	  done	  by	  individual	  statistical	  offices	  alone	  but	  <br/>require	  col&#160;aboration	  as	  in	  the	  field	  of	  genomics	  and	  waste	  management.	  This	  includes	  public-­‐<br/>private	  partnerships,	  which	  involve	  sensitive	  negotiations.	  But	  one	  difficulty	  in	  building	  such	  <br/>partnerships	  is	  that	  the	  private	  sector	  has	  different	  business	  models	  and	  funding	  streams.	  <br/>Finally	  there	  are	  also	  ‘image	  risks’	  and	  issues	  of	  perception	  involved	  in	  using	  some	  Big	  Data	  <br/>sources	  generated	  by	  private	  technology	  industries.	  <br/>
<b>Respondent:&#160;&#160;Gurdeep&#160;Sagoo,&#160;PHG&#160;Foundation&#160;<br/></b>•&#160;&#160;Genomic	  research	  includes	  a	  number	  of	  different	  sectors	  and	  stakeholder	  groups	  that	  have	  <br/>
different	  goals	  and	  interests.	  For	  example,	  in	  the	  private	  sector	  discussions	  tend	  to	  revolve	  <br/>
around	  profit	  whereas,	  in	  academia,	  the	  onus	  is	  on	  knowledge	  creation	  with	  efficiency	  gains	  <br/>
seen	  as	  a	  by-­‐product.	  But	  the	  mixture	  generally	  does	  tend	  to	  work	  wel&#160;	  in	  that	  the	  goals	  are	  <br/>
often	  complementary.	  In	  genomics,	  the	  goal	  of	  using	  Big	  Data	  should	  be	  to	  improve	  the	  <br/>health	  of	  the	  population.	  The	  biggest	  challenge	  centres	  on	  funding	  and	  resources,	  which	  are	  <br/>
relatively	  scarce.	  <br/>
•&#160;&#160;Over	  the	  past	  5	  years	  there	  has	  been	  a	  lot	  of	  discussion	  around	  drug	  development	  and	  <br/>
‘personalised	  medicine’.	  The	  belief	  within	  medicine	  is	  that	  the	  doctor/patient	  relationship	  is	  <br/>
about	  providing	  a	  personalised	  service	  rather	  than	  focusing	  on	  budget	  constraints.	  You	  treat	  <br/>
5	  <br/>
	  <br/>
<hr/>
<a name=6></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
the	  patient	  in	  front	  of	  you	  rather	  than	  worrying	  about	  having	  the	  money	  to	  treat	  the	  patient	  <br/>
coming	  to	  see	  you	  next	  week.	  There	  has	  been	  much	  work	  done	  recently	  on	  drug	  <br/>
development,	  which	  can	  be	  more	  effective	  and	  minimise	  harmful	  reactions.	  Drug	  <br/>
companies	  are	  investing	  a	  lot	  of	  resources	  in	  these	  areas	  of	  ‘personalised’	  medicine.	  	  <br/>
•&#160;&#160;With	  respect	  to	  economies,	  the	  emphasis	  is	  on	  balancing	  the	  health	  needs	  of	  all	  of	  the	  <br/>
population	  within	  a	  relatively	  fixed	  and	  limited	  budget.	  There	  is	  scope	  within	  the	  <br/>
government	  system	  to	  pay	  for	  new	  drugs	  if	  there	  was	  a	  pandemic	  (e.g.	  the	  recent	  Ebola	  <br/>
outbreak),	  but	  action	  requires	  political	  support.	  The	  100,000	  Genomes	  Project,	  which	  has	  <br/>
been	  backed	  by	  British	  Prime	  Minister	  David	  Cameron,	  is	  a	  good	  example	  of	  a	  public-­‐private	  <br/>
partnership.	  The	  emphasis	  is	  on	  both	  improving	  health	  and	  economic	  benefits.	  It	  wil&#160;	  be	  <br/>
interesting	  to	  see	  how	  these	  health	  and	  economic	  benefits	  wil&#160;	  be	  realised	  in	  the	  future.	  <br/>
<b>Respondent:&#160;Steven&#160;Rose,&#160;Strategic&#160;Research,&#160;Birmingham&#160;City&#160;Council&#160;<br/></b>•&#160;&#160;In	  the	  future,	  waste	  is	  likely	  to	  be	  viewed	  as	  a	  resource	  and	  based	  on	  an	  economic	  model	  <br/>
where	  ‘raw	  materials’	  must	  be	  ‘harvested’	  from	  people’s	  bins.	  This	  shift	  in	  thinking	  wil&#160;	  have	  <br/>
a	  significant	  impact	  on	  how	  data	  is	  col&#160;ected	  and	  analysed.	  	  <br/>
•&#160;&#160;There	  is	  a	  lot	  of	  data	  available	  to	  local	  authorities.	  This	  could	  be	  used	  by	  the	  private	  sector	  <br/>
to	  design	  technologies	  such	  as	  the	  GPS	  systems	  for	  fleet	  and	  waste	  vehicles.	  	  <br/>
•&#160;&#160;In	  the	  field	  of	  waste	  management,	  discussions	  focussing	  on	  recycling	  and	  waste	  reduction	  <br/>
tend	  to	  be	  evangelical.	  The	  emphasis	  is	  on	  narratives	  about	  the	  common	  good	  and	  the	  <br/>
public	  ‘pul&#160;ing	  together’.	  But	  individuals	  all	  have	  different	  needs	  and	  behaviours.	  They	  ask	  <br/>
‘what’s	  in	  it	  for	  me’?	  One	  way	  would	  be	  to	  make	  data	  available	  to	  the	  public	  so	  that	  <br/>
individuals	  could	  make	  better	  decisions	  about	  reducing	  waste.	  Alternatively,	  consumers	  <br/>
could	  use	  waste	  data	  to	  push	  companies	  to	  change	  their	  packaging	  materials.	  This	  kind	  of	  <br/>data	  could	  be	  used	  for	  lobbying	  and	  moving	  sustainability	  agendas	  forward.	  <br/>
Discussion&#160;&#160;<br/>
<b>Group	  1	  </b><br/>
•&#160;&#160;There	  is	  growing	  consensus	  that	  Big	  Data	  wil&#160;	  benefit	  the	  country,	  but	  what	  wil&#160;	  the	  actual	  <br/>
benefits	  be?	  There	  needs	  to	  be	  a	  return	  on	  investments	  because	  training	  people	  in	  these	  <br/>
new	  areas	  is	  expensive.	  <br/>
•&#160;&#160;‘Data	  science’	  as	  a	  discipline	  involves	  the	  skil&#160;s	  and	  knowledge	  of	  a	  number	  of	  different	  <br/>
practitioners,	  including	  statisticians,	  data	  analysts,	  and	  information	  technologists.	  	  <br/>
•&#160;&#160;New	  outputs	  and	  insights	  into	  Big	  Data	  must	  be	  flexible	  and	  reactive.	  If	  the	  government	  <br/>
wants	  to	  know	  something	  new	  (e.g.	  the	  number	  of	  people	  on	  zero-­‐hour	  contracts),	  Big	  Data	  <br/>
could	  discover	  this	  information	  more	  quickly	  than	  standard	  practices.	  	  	  	  <br/>
•&#160;&#160;This	  begs	  the	  question,	  ‘If	  you	  had	  an	  infinite	  amount	  of	  money	  to	  spend	  on	  Big	  Data,	  what	  <br/>
would	  you	  do	  with	  it?’	  <br/>
<b>	  </b><br/>
<b>	  </b><br/>
6	  <br/>
	  <br/>
<hr/>
<a name=7></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
<b>Group	  2	  </b><br/>
•&#160;&#160;What	  is	  the	  Big	  Data	  business	  model	  &#160;–	  what	  is	  the	  case	  to	  be	  made	  and	  its	  justification	  –	  for	  <br/>
profit,	  for	  benefit,	  for	  public	  service?	  It	  is	  not	  merely	  about	  money,	  but	  other	  types	  of	  value	  <br/>
(e.g.	  environmental,	  public	  goods	  and	  health).	  	  <br/>
•&#160;&#160;Much	  of	  the	  rhetoric	  about	  Big	  Data	  is	  predicated	  on	  its	  promise,	  it	  is	  being	  sold	  for	  its	  <br/>
potential,	  that	  upfront	  investment	  in	  prevention	  could	  lead	  to	  long	  term	  savings	  and	  that	  in	  <br/>
the	  future	  benefits	  wil&#160;	  be	  derived	  from	  working	  with	  this	  data.	  For	  example,	  in	  genomics	  <br/>
there	  is	  a	  promise	  of	  what	  it	  might	  deliver	  but	  the	  pay-­‐off	  keeps	  getting	  postponed.	  In	  <br/>
official	  statistics	  the	  momentum	  is	  based	  on	  the	  promise	  that	  society	  wil&#160;	  benefit	  in	  the	  long	  <br/>
term.	  There	  is	  also	  the	  assumption	  that	  there	  is	  a	  risk	  of	  missing	  something	  important	  if	  Big	  <br/>
Data	  is	  not	  used.	  &#160;	  <br/>
•&#160;&#160;You	  are	  not	  generating	  data	  organically	  if	  you	  don’t	  have	  a	  platform.	  The	  platform	  is	  an	  <br/>
important	  part	  of	  the	  ecology	  of	  working	  with	  Big	  Data.	  	  <br/>
•&#160;&#160;Consider	  the	  economies	  of	  social	  media	  platforms	  –	  they	  depend	  on	  advertising,	  which	  is	  a	  <br/>
business	  model	  that	  is	  being	  standardised.	  <br/>
•&#160;&#160;Different	  relations	  exist	  between	  different	  actors.	  The	  public	  sector	  has	  an	  interest	  in	  <br/>
commercial	  data	  and	  wants	  to	  access	  it	  so	  they	  can	  change	  their	  working	  practices.	  It	  is	  not	  <br/>
often	  acknowledged	  that	  businesses	  also	  have	  a	  strong	  interest	  in	  public	  data	  (e.g.	  census	  <br/>
data).	  The	  relationships	  and	  dependencies	  go	  in	  many	  directions.	  <br/>
•&#160;&#160;There	  are	  regional	  differences	  in	  how	  the	  public	  sector	  operates.	  Some	  countries	  have	  <br/>
detailed	  information	  about	  the	  commercial	  sector	  and	  others	  do	  not.	  The	  question	  of	  <br/>
economies	  is	  complicated	  by	  these	  different	  circumstances.	  &#160;	  <br/>
<b>Group	  3	  	  </b><br/>
•&#160;&#160;Working	  with	  Big	  Data	  can	  create	  new	  markets.	  For	  example,	  the	  pharmaceutical	  industry’s	  <br/>
use	  of	  genomics	  data.	  	  <br/>
•&#160;&#160;One	  motivation	  behind	  using	  Big	  Data	  could	  be	  to	  acquire	  a	  competitive	  advantage	  (e.g.	  a	  <br/>
new	  contract	  in	  waste	  management).	  The	  length	  of	  these	  contracts	  (often	  25	  years	  or	  more)	  <br/>
makes	  it	  difficult	  to	  adopt	  new	  data	  practices	  once	  a	  public-­‐private	  partnership	  has	  been	  <br/>
established.	  Many	  questions	  emerge	  around	  data	  ownership	  especially	  since	  different	  <br/>
partners	  have	  different	  requirements.	  <br/>
•&#160;&#160;Data	  is	  a	  commodity.	  Why	  are	  we	  paying	  for	  people	  (in	  the	  private	  sector)	  to	  get	  rid	  of	  our	  <br/>
waste	  when	  they	  are	  profiting	  from	  these	  materials?	  <br/>
•&#160;&#160;Questions	  were	  raised	  around	  intel&#160;ectual	  property.	  National	  statistics	  data	  are	  more	  open	  <br/>
and	  transparent	  while	  commercial	  partners	  have	  an	  interest	  in	  patenting	  their	  data,	  which	  is	  <br/>
likely	  to	  prevent	  others	  from	  using	  their	  data.	  <br/>
•&#160;&#160;The	  re-­‐use	  of	  data	  is	  part	  of	  the	  economies	  of	  Big	  Data	  but	  some	  re-­‐uses	  are	  less	  desirable	  <br/>
such	  as	  in	  decisions	  on	  health	  and	  car	  insurance	  that	  penalise	  particular	  groups	  and	  can	  lead	  <br/>
to	  inequalities.	  Compare	  this	  to	  col&#160;ectivised	  uses	  targeted	  at	  better	  services	  and	  efficiency	  <br/>
gains.	  <br/>
7	  <br/>
	  <br/>
<hr/>
<a name=8></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
•&#160;&#160;It	  is	  unclear	  what	  personal	  data	  is	  being	  used	  for	  and	  the	  rules	  about	  data	  protection	  are	  <br/>
unclear.	  For	  example,	  data	  may	  be	  shared	  on	  crowdsourcing	  or	  patient	  sites.	  Questions	  <br/>
emerge	  around	  how	  this	  data	  is	  used	  and	  by	  whom.	  <br/>
<b>Crosscutting&#160;Theme&#160;3:&#160;Ethics&#160;</b><br/>
Plenary&#160;Presentation: John&#160;Bland, Greater&#160;Manchester&#160;Waste Disposal&#160;<br/>
Authority&#160;(GMWDA)&#160;<br/>John	  Bland	  spoke	  about	  the	  ethics	  of	  working	  with	  Big	  Data	  in	  relation	  to	  waste	  management.	  <br/>Big	  Data	  could	  potentially	  revolutionise	  waste	  management	  practices	  through	  improved	  <br/>services	  and	  efficiency	  gains.	  Whereas	  standard	  practice	  has	  traditionally	  been	  to	  col&#160;ect	  <br/>information	  around	  tonnages,	  improving	  waste	  recycling	  requires	  more	  personalised	  services	  <br/>and	  individual	  data	  (i.e.	  so	  that	  barriers	  -­‐	  whether	  physical	  such	  as	  the	  supply	  of	  the	  right	  <br/>“bins”,	  or	  behavioural	  such	  as	  people	  who	  can’t	  be	  bothered	  -­‐	  which	  stop	  residents	  <br/>participating	  are	  able	  to	  be	  more	  effectively	  addressed).	  This	  move	  towards	  integrating	  Big	  Data	  <br/>into	  waste	  management	  could	  facilitate	  behavioural	  change	  through	  peer	  pressure,	  penalties,	  <br/>credits	  or	  rewards.	  At	  the	  same	  time,	  working	  with	  Big	  Data	  raises	  ethical	  issues	  around	  privacy	  <br/>and	  data	  protection	  (e.g.,	  in	  relation	  to	  the	  Data	  Protection	  Act).	  <br/>
The	  determination	  of	  what	  constitutes	  ethical	  action	  is	  not	  always	  clear,	  particularly	  when	  it	  <br/>applies	  to	  pressing	  social	  issues,	  such	  as,	  climate	  change.	  Moreover,	  what	  are	  the	  consequences	  <br/>of	  using	  this	  information	  if	  it	  implicates	  people	  from	  certain	  socioeconomic	  or	  ethnic	  groups?	  <br/>For	  example,	  if	  a	  particular	  ethnic	  community	  produces	  more	  waste	  is	  it	  ethical	  to	  disclose	  this	  <br/>information	  to	  the	  public?	  Is	  it	  ethical	  to	  assimilate	  data	  to	  make	  generalisations	  about	  certain	  <br/>demographic	  groups?	  Is	  it	  ethical	  to	  charge	  people	  for	  residual	  waste	  or	  to	  reward	  them	  for	  <br/>recycling?	  These	  questions	  must	  be	  framed	  not	  only	  in	  relation	  to	  improved	  services	  and	  <br/>efficiency	  gains	  but	  assume	  particular	  significance	  when	  applied	  to	  the	  public	  good.	  <br/>
Respondent:&#160;Pete&#160;Brodie,&#160;Office&#160;for&#160;National&#160;Statistics&#160;(ONS)&#160;<br/>
•&#160;&#160;Pete	  Brodie	  responded	  by	  discussing	  some	  of	  the	  ethical	  issues	  around	  using	  Big	  Data.	  <br/>
These	  concerns	  were	  canvassed	  in	  relation	  to	  current	  research	  on	  Big	  Data	  at	  the	  Office	  for	  <br/>
National	  Statistics	  (ONS).	  <br/>
•&#160;&#160;Pete	  noted	  two	  types	  of	  uses	  of	  data:	  crowd	  (general)	  and	  individual	  (targeted).	  Tesco’s	  <br/>
loyalty	  card	  scheme	  is	  a	  case	  in	  point.	  This	  data	  can	  be	  used	  in	  several	  ways,	  to	  target	  sales	  <br/>
to	  individuals	  via	  special	  offers	  or	  to	  generally	  improve	  services	  by	  configuring	  stores	  to	  <br/>
appeal	  to	  their	  local	  demographic.	  The	  former	  generally	  raise	  more	  concerns	  about	  ethics	  <br/>
though	  the	  latter	  is	  stil&#160;	  profit	  oriented.	  People’s	  attitude	  towards	  Big	  Data	  wil&#160;	  thus	  depend	  <br/>
largely	  upon	  how	  it	  is	  used.	  &#160;	  <br/>
•&#160;&#160;The	  same	  applies	  to	  the	  context	  of	  waste	  management.	  Ethical	  issues	  emerge	  around	  data	  <br/>
usage.	  Is	  Big	  Data	  being	  used	  to	  penalise	  people	  or	  to	  improve	  their	  lives	  via	  better	  <br/>
services?	  The	  public	  is	  likely	  to	  react	  negatively	  if	  Big	  Data	  is	  used	  to	  uncover	  the	  contents	  of	  <br/>their	  bins,	  whereas	  crowd	  information	  could	  be	  used	  to	  encourage	  people	  to	  recycle	  at	  the	  <br/>
8	  <br/>
	  <br/>
<hr/>
<a name=9></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
local	  level	  via	  rewards,	  peer	  pressure	  and	  community	  engagement.	  These	  examples	  <br/>
demonstrate	  the	  importance	  of	  considering	  how	  Big	  Data	  wil&#160;	  be	  used	  as	  this	  is	  likely	  to	  <br/>
shape	  people’s	  attitudes	  and	  behaviour.	  <br/>
•&#160;&#160;The	  ONS	  currently	  run	  four	  projects	  on	  Big	  Data	  involving	  mobile	  phone	  data,	  Twitter	  data,	  <br/>
Smart	  Meter	  data	  and	  Price	  Information	  data	  col&#160;ected	  online.	  These	  different	  modes	  of	  <br/>
data	  col&#160;ection	  each	  raise	  particular	  ethical	  challenges.	  When	  accessing	  mobile	  phone	  or	  <br/>
Twitter	  data,	  for	  example,	  the	  ONS	  has	  to	  consider	  ethical	  issues	  regarding	  surveil&#160;ance,	  <br/>
privacy	  and	  informed	  consent.	  While	  data	  of	  this	  kind	  can	  be	  readily	  accessed,	  people	  have	  <br/>
not	  necessarily	  been	  informed	  that	  it	  wil&#160;	  be	  used	  for	  commercial	  or	  research	  purposes	  and	  <br/>
might	  not	  be	  wil&#160;ing	  to	  have	  organisations	  use	  this	  information.	  The	  issue	  of	  informed	  <br/>
consent	  is	  particularly	  important	  to	  the	  ONS	  because	  it	  is	  a	  trusted	  organisation.	  <br/>
Respondent:&#160;Gurdeep&#160;Sagoo, PHG Foundation&#160;<br/>
•&#160;&#160;Gurdeep	  Sagoo	  responded	  to	  John’s	  presentation	  by	  discussing	  the	  ethics	  of	  working	  with	  <br/>
Big	  Data	  as	  a	  genomic	  practitioner.	  Within	  the	  field	  of	  genomics,	  there	  is	  a	  long	  history	  of	  <br/>
thinking	  about	  the	  ethical,	  legal	  and	  social	  issues	  around	  data.	  The	  Ethical,	  Legal	  and	  Social	  <br/>
Implications	  (ELSI)	  Research	  Program	  was	  established	  in	  1990	  as	  an	  integral	  part	  of	  the	  <br/>
Human	  Genome	  Project	  (HGP)	  to	  foster	  basic	  and	  applied	  research	  on	  the	  ethical,	  legal	  and	  <br/>
social	  implications	  of	  genetic	  and	  genomic	  research	  for	  individuals,	  families	  and	  <br/>
communities.	  <br/>
•&#160;&#160;In	  2014,	  the	  Realising	  Genomics	  (RG)	  project	  focused	  more	  specifically	  on	  the	  ethical,	  legal	  <br/>
and	  social	  issues	  (ELSI)	  raised	  by	  the	  implementation	  of	  WGS/WES	  in	  clinical	  practice.	  The	  <br/>
issues	  associated	  with	  the	  clinical	  implementation	  of	  next	  generation	  sequencing	  (including	  <br/>
WGS	  and	  whole	  exome	  sequencing	  (WES))	  are	  highly	  relevant	  to	  the	  UK	  government’s	  <br/>
100,000	  Genomes	  Project.	  The	  report	  recommended	  using	  targeted	  testing,	  when	  possible.	  <br/>
Coincidental	  or	  incidental	  findings	  raise	  ethical	  questions.	  In	  undertaking	  this	  project,	  the	  <br/>
most	  contentious	  ethical	  issues	  that	  arose	  were	  when	  individual	  rights	  come	  into	  conflict	  <br/>
with	  greater	  public	  and	  societal	  interests.	  Questions	  arose,	  for	  example,	  over	  whether	  <br/>
patients	  should	  be	  able	  to	  opt	  out	  of	  receiving	  incidental	  findings	  when	  they	  are	  clinically	  <br/>
relevant.	  For	  example,	  should	  patients	  be	  able	  to	  limit	  the	  extent	  to	  which	  their	  sequence	  <br/>
data	  is	  shared	  with	  other	  researchers,	  commercial	  providers	  and	  the	  NHS?	  If	  so,	  to	  what	  <br/>
extent	  should	  this	  happen?	  These	  questions	  led	  to	  recommendations	  around	  informed	  <br/>
consent	  and	  increased	  transparency.	  Gurdeep	  then	  asked	  whether	  informed	  consent	  is	  ever	  <br/>
really	  possible?	  There	  are	  significant	  barriers	  to	  acquiring	  informed	  consent,	  particularly	  as	  <br/>
it	  applies	  to	  logistics	  around	  time	  and	  cost.	  <br/>
•&#160;&#160;In	  genomics	  there	  is	  also	  a	  blurring	  between	  research	  and	  clinical	  practice.	  In	  research,	  <br/>
anonymising	  and	  aggregating	  data	  can	  help	  to	  overcome	  some	  of	  these	  ethical	  challenges.	  <br/>
There	  is,	  however,	  a	  concern	  that	  anonymity	  can	  be	  lost	  through	  data	  linkage.	  If	  genomic	  <br/>
data	  is	  linked	  to	  other	  NHS	  databases,	  as	  the	  100,000	  Genomes	  Project	  seeks	  to	  achieve,	  <br/>
then	  it	  could	  become	  relatively	  easy	  to	  de-­‐anonymise	  genomic	  sequence	  data.	  This	  could	  <br/>
lead	  to	  individuals	  being	  discriminated	  against	  on	  the	  basis	  of	  their	  genomic	  sequence.	  <br/>
•&#160;&#160;These	  ethical	  issues	  encourage	  us	  to	  think	  seriously	  about	  whether	  health	  is	  an	  individual	  or	  <br/>
societal	  issue,	  and	  who	  should	  take	  responsibility	  for	  our	  wel&#160;being.	  <br/>
9	  <br/>
	  <br/>
<hr/>
<a name=10></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
Discussion&#160;&#160;<br/>
<b>Group	  1	  </b><br/>
•&#160;&#160;Group	  1	  commenced	  by	  reflecting	  on	  the	  ethical	  issues	  around	  public	  services,	  in	  particular	  <br/>
the	  tension	  between	  individual	  interests	  and	  col&#160;ective	  benefits.	  <br/>
•&#160;&#160;This	  led	  to	  discussion	  about	  the	  distinction	  between	  the	  public	  and	  the	  private.	  The	  <br/>
distinction	  between	  the	  citizen	  as	  a	  participant	  in	  the	  public	  sphere	  as	  opposed	  to	  a	  <br/>
consumer	  interacting	  with	  private	  corporations	  is	  becoming	  blurred	  at	  a	  time	  when	  citizens	  <br/>
are	  being	  asked	  to	  pay	  for	  public	  services.	  	  <br/>
•&#160;&#160;Many	  ethical	  issues	  are	  derived	  from	  the	  uncertainty	  around	  how	  individual	  data	  wil&#160;	  be	  <br/>
used.	  <br/>
•&#160;&#160;Working	  with	  Big	  Data	  raises	  issues	  about	  data	  ownership	  (e.g.	  who	  owns	  the	  data,	  the	  <br/>
individual	  or	  the	  data	  generators?)	  and	  rights.	  Is	  there	  such	  a	  thing	  as	  digital	  human	  rights?	  <br/>
Is	  data	  an	  extension	  of	  the	  person	  and,	  if	  so,	  is	  the	  use	  of	  it	  in	  certain	  contexts	  a	  violation	  of	  <br/>
the	  person?	  	  <br/>
•&#160;&#160;There	  is	  a	  tension	  between	  the	  ethical	  practices	  of	  companies	  and	  academics	  as	  exemplified	  <br/>
by	  the	  controversy	  over	  the	  ethics	  of	  Facebook’s	  recent	  study	  with	  academic	  researchers	  <br/>
that	  involved	  manipulation	  of	  people’s	  emotions	  without	  their	  knowledge	  or	  consent.	  <br/>
<b>Group	  2	  </b><br/>
•&#160;&#160;There	  was	  discussion	  around	  the	  ethical	  implications	  of	  data	  linkage	  and	  consent,	  as	  wel&#160;	  as	  <br/>
the	  practicality	  of	  offering	  anonymity	  or	  the	  right	  to	  withdraw	  data.	  From	  a	  technical	  <br/>
standpoint,	  this	  might	  be	  impractical.	  Instead,	  what	  is	  required	  is	  political	  discussion	  about	  <br/>
the	  risks	  and	  vulnerabilities	  around	  data	  integration,	  particularly	  as	  this	  applies	  to	  health.	  <br/>
•&#160;&#160;The	  preoccupation	  with	  individual	  privacy	  risks	  overshadowing	  other	  important	  ethical	  <br/>
issues.	  For	  example,	  searching	  for	  correlations	  in	  Big	  Data	  sets	  can	  lead	  to	  unexpected	  <br/>
results	  that	  have	  the	  potential	  to	  stigmatise	  certain	  ethnic	  groups.	  <br/>
•&#160;&#160;From	  an	  ethical	  standpoint,	  there	  is	  a	  growing	  need	  to	  consider	  the	  costs	  and	  benefits	  of	  <br/>
working	  with	  Big	  Data.	  If	  these	  ethical	  issues	  are	  not	  communicated	  clearly	  to	  the	  public,	  <br/>
the	  potential	  benefits	  of	  Big	  Data	  can	  be	  lost.	  <br/>
<b>Group	  3	  </b><br/>
•&#160;&#160;Working	  with	  Big	  Data	  raises	  ethical	  issues	  around	  trust.	  There	  is	  a	  need	  for	  people	  to	  know	  <br/>
how	  their	  data	  is	  going	  to	  be	  used	  in	  order	  to	  mitigate	  potential	  ethical	  dilemmas.	  <br/>
Perceptions	  and	  fears	  around	  Big	  Data	  need	  to	  be	  addressed	  and	  distinguished	  from	  myths	  <br/>
about	  how	  data	  is	  used,	  stored	  and	  col&#160;ected.	  <br/>
•&#160;&#160;There	  was	  debate	  over	  whether	  data	  ownership	  is	  an	  ethical	  or	  legal	  issue.	  At	  present,	  the	  <br/>
law	  is	  not	  equipped	  to	  deal	  with	  the	  ethical	  concerns	  associated	  with	  Big	  Data.	  <br/>
•&#160;&#160;In	  order	  to	  assess	  adequately	  the	  costs	  and	  benefits	  of	  working	  with	  Big	  Data,	  there	  needs	  <br/>
to	  be	  an	  emphasis	  on	  assessing	  the	  potential	  risks	  involved.	  <br/>
•&#160;&#160;There	  is	  a	  growing	  need	  to	  identify	  and	  communicate	  the	  overall	  value	  of	  Big	  Data	  rather	  <br/>
than	  merely	  focusing	  on	  the	  negative	  risks	  of	  sharing	  data.	  <br/>
10	  <br/>
	  <br/>
<hr/>
<a name=11></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
<b>Crosscutting&#160;Theme&#160;4:&#160;Collaboratory&#160;</b><br/>
Plenary&#160;Presentation:&#160;Steven&#160;Vale, United Nations Economic Commission for&#160;Europe&#160;<br/>
(UNECE)&#160;<br/>Steven	  Vale	  spoke	  about	  col&#160;aboratories	  as	  a	  method	  to	  engage	  with	  different	  communities	  of	  <br/>practice,	  providing	  reflections	  on	  the	  col&#160;aborative	  approach	  and	  recommendations	  on	  how	  the	  <br/>method	  could	  be	  developed	  in	  the	  future.	  Over	  the	  past	  two	  years	  Big	  Data	  has	  become	  an	  <br/>emerging	  topic	  within	  the	  field	  of	  national	  statistics.	  Yet,	  despite	  growing	  interest	  in	  Big	  Data,	  at	  <br/>present	  there	  is	  not	  much	  understanding.	  Working	  for	  UNECE,	  Steven	  agreed	  to	  attend	  because	  <br/>of	  his	  interest	  in	  Big	  Data	  and	  because	  his	  team	  is	  trying	  to	  introduce	  new	  ways	  of	  working	  with	  <br/>Big	  Data	  in	  official	  statistics.	  In	  this	  regard,	  there	  are	  similarities	  between	  col&#160;aboratories	  as	  a	  <br/>mode	  of	  engagement	  and	  the	  working	  practices	  of	  the	  UNECE,	  which	  brings	  together	  <br/>volunteers	  with	  shared	  interests	  to	  a	  common	  forum	  to	  discuss,	  share,	  explore	  and	  arrive	  at	  <br/>common	  solutions.	  In	  both	  cases,	  practitioners	  commence	  with	  a	  blank	  canvass	  from	  which	  <br/>they	  brainstorm	  and	  address	  key	  questions	  they	  need	  to	  solve	  in	  order	  to	  develop	  a	  common	  <br/>vocabulary	  –	  a	  particularly	  important	  task	  when	  assembling	  people	  from	  diverse	  contexts	  and	  <br/>regions.	  A	  key	  part	  of	  the	  UNECE’s	  work	  revolves	  around	  how	  to	  proceed	  and	  innovate.	  This	  <br/>begs	  the	  question,	  what	  are	  the	  next	  steps	  after	  the	  col&#160;aboratory?	  Steve	  emphasised	  the	  value	  <br/>of	  considering	  these	  questions	  to	  continue	  the	  momentum	  developed	  over	  the	  past	  year.	  <br/>
Despite	  these	  similarities,	  col&#160;aboratories	  also	  differ	  from	  the	  working	  practices	  of	  the	  UNECE	  in	  <br/>significant	  ways.	  The	  UNECE’s	  activities	  are	  situated	  within	  a	  relatively	  specialised	  community.	  <br/>Steve	  found	  it	  interesting	  to	  be	  exposed	  to	  novel	  perspectives,	  methodologies	  and	  metrics	  from	  <br/>different	  practitioner	  groups.	  He	  suggested	  that	  col&#160;aborations	  of	  this	  kind	  create	  the	  <br/>opportunity	  for	  interdisciplinary	  engagement.	  For	  example,	  the	  practices	  of	  genomic	  scientists	  <br/>or	  waste	  management	  practitioners	  could	  inform	  the	  production	  of	  national	  statistics	  in	  new	  <br/>and	  exciting	  ways.	  Moreover,	  much	  of	  the	  UNECE’s	  work	  has	  a	  global	  dimension.	  Whereas	  the	  <br/>col&#160;aboratories	  were	  mainly	  based	  in	  the	  UK,	  it	  could	  be	  interesting	  to	  adopt	  a	  more	  <br/>international	  dimension	  through	  virtual	  communication	  or	  other	  means.	  The	  key	  issue	  is	  to	  be	  <br/>flexible	  and	  wil&#160;ing	  to	  learn,	  realising	  that	  findings	  may	  differ	  from	  what	  was	  initially	  expected.	  <br/>An	  example	  of	  such	  a	  mode	  of	  col&#160;aborative	  exchange	  is	  the	  Big	  Data	  Sandbox,	  which	  provides	  a	  <br/>technical	  platform	  and	  a	  col&#160;aborative	  environment	  where	  statistical	  organisations	  can	  play	  <br/>with	  Big	  Data,	  and	  experiment	  with	  new	  tools	  and	  methods.	  This	  type	  of	  experimentation	  could	  <br/>be	  trialled	  in	  future	  col&#160;aboratories.	  <br/>
Overall,	  Steve	  found	  the	  col&#160;aboratories	  a	  useful	  approach.	  Facilitation	  and	  structure	  is	  key.	  <br/>Getting	  the	  structure	  right	  is	  a	  challenge.	  There	  needs	  to	  be	  enough	  structure	  to	  stimulate	  <br/>meaningful	  exchange	  while	  leaving	  room	  for	  creativity	  and	  debate.	  Col&#160;aboratories	  are	  most	  <br/>effective	  when	  practitioners	  are	  at	  similar	  stage	  of	  development	  as	  is	  typically	  the	  case	  with	  Big	  <br/>
11	  <br/>
	  <br/>
<hr/>
<a name=12></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
Data,	  which	  raises	  common	  issues	  around	  access,	  reliability	  and	  ethics	  across	  the	  different	  <br/>practical	  contexts:	  genomics,	  national	  statistics	  and	  waste	  management.	  In	  sum,	  col&#160;aboratories	  <br/>provide	  a	  very	  useful	  approach	  of	  cross-­‐cultural	  engagement.	  It	  would	  be	  beneficial	  to	  find	  a	  <br/>mechanism	  to	  continue	  these	  discussions	  (via	  an	  electronic	  forum,	  for	  example)	  so	  as	  not	  to	  <br/>lose	  the	  momentum	  established.	  <b>	  </b><br/>
Respondent:&#160;Will&#160;Spooner, Eagle&#160;Genomics&#160;<br/>Fol&#160;owing	  from	  Steven’s	  evaluation	  of	  the	  col&#160;aborative	  approach,	  Wil&#160;	  Spooner	  reflected	  on	  <br/>how	  successful	  the	  col&#160;aboratories	  have	  been.	  He	  discussed	  the	  issues	  that	  arose	  and	  how	  the	  <br/>team	  might	  have	  done	  things	  differently.	  Wil&#160;	  remained	  unclear	  about	  what	  a	  col&#160;aboratory	  is	  <br/>and	  how	  the	  approach	  differs	  from	  other	  forms	  of	  engagement,	  such	  as,	  focus	  groups,	  <br/>networking	  events	  and	  workshops	  where	  people	  assemble	  to	  address	  specific	  topics	  and	  <br/>problems.	  He	  proposed	  that	  col&#160;aboratories	  are	  distinguished	  from	  other	  kinds	  of	  col&#160;aborative	  <br/>research	  because	  they	  examine	  how	  things	  in	  the	  world	  are	  constituted	  as	  objects	  (e.g.	  Big	  Data	  <br/>as	  a	  Digital	  Data	  Object	  (DDO)).	  In	  this	  regard,	  col&#160;aboratories	  could	  be	  said	  to	  disrupt	  existing	  <br/>hierarchies	  and	  to	  challenge	  the	  status	  quo.	  <br/>
The	  central	  aim	  of	  the	  Final	  Col&#160;aboratory	  was	  to	  advance	  the	  analysis	  of	  Big	  Data	  practices.	  For	  <br/>Wil&#160;,	  this	  appeared	  to	  represent	  a	  social	  science	  point	  of	  view.	  Within	  the	  field	  of	  genomics,	  the	  <br/>focus	  is	  on	  establishing	  new	  definitions	  about	  Big	  Data	  and	  novel	  ways	  to	  express	  and	  classify	  <br/>Big	  Data	  that	  recognises	  its	  social	  context	  rather	  than	  merely	  focusing	  on	  its	  technical	  qualities.	  <br/>The	  social	  context	  of	  Big	  Data	  is	  vital.	  What	  is	  it	  about	  the	  social	  and	  cultural	  context	  of	  Big	  Data	  <br/>that	  makes	  it	  “BIG”?	  Wil&#160;	  suggested	  that	  one	  way	  to	  measure	  the	  success	  of	  a	  col&#160;aboratory	  is	  in	  <br/>terms	  of	  its	  <i>usefulness</i>	  to	  practitioners	  and	  the	  community	  it	  seeks	  to	  inform	  –	  the	  findings	  <br/>must	  be	  useful	  to	  the	  community	  and	  practitioner	  groups	  by	  providing	  insight	  into	  a	  specific	  <br/>subject	  area	  and	  the	  ability	  to	  influence	  practice	  and	  policy.	  In	  this	  regard,	  Wil&#160;	  asked	  how	  we	  <br/>intend	  to	  influence	  policy?	  <br/>
Wil&#160;	  attended	  the	  col&#160;aboratories	  in	  order	  to	  acquire	  a	  social	  scientific	  understanding	  about	  Big	  <br/>Data.	  Working	  for	  Eagle	  Genomics,	  a	  company	  that	  uses	  open	  source	  software	  and	  data	  that	  is	  <br/>emerging	  from	  academic	  communities,	  Wil&#160;	  needs	  to	  understand	  the	  real	  value	  of	  open	  data	  in	  <br/>sociological	  terms.	  This	  enables	  formulating	  the	  value	  proposition	  of	  their	  services	  to	  sponsors	  <br/>and	  customers	  through	  a	  common	  vocabulary	  and	  to	  innovate	  new	  services	  that	  can	  increase	  <br/>their	  value.	  Big	  Data	  has	  to	  be	  understood	  in	  the	  context	  of	  disruptive	  innovation	  –	  it	  provides	  a	  <br/>new	  way	  of	  working	  that	  opens	  up	  new	  markets	  that	  companies	  such	  as	  Eagle	  Genomics	  aim	  to	  <br/>target.	  Wil&#160;	  found	  the	  Final	  Col&#160;aboratory	  more	  useful	  than	  the	  first	  because	  it	  exposed	  him	  to	  <br/>different	  perspectives	  and	  practitioner	  groups,	  which	  led	  to	  new	  insights	  and	  ways	  of	  looking	  at	  <br/>Big	  Data.	  He	  found	  the	  working	  paper	  particularly	  useful	  because	  it	  synthesised	  the	  findings	  and	  <br/>provided	  the	  sociological	  terminology	  and	  vocabulary	  that	  he	  originally	  sought.	  For	  example,	  <br/>
12	  <br/>
	  <br/>
<hr/>
<a name=13></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
the	  notion	  of	  Big	  Data	  as	  a	  “boundary	  object”	  demonstrated	  how	  the	  value	  of	  Big	  Data	  might	  be	  <br/>increased.	  For	  Wil&#160;,	  this	  Final	  Col&#160;aboratory	  led	  to	  the	  growing	  realisation	  that	  Big	  Data	  is	  <br/>inherently	  social	  compared	  to	  other	  sorts	  of	  data.	  The	  value	  of	  Big	  Data	  is	  maximised	  by	  <br/>integrating	  multiple	  data	  sources	  to	  arrive	  at	  a	  multidimensional	  viewpoint	  of	  the	  problem	  at	  <br/>hand.	  Big	  Data	  is	  characterised	  as	  a	  data	  object	  that	  has	  relevance	  to	  multiple	  stakeholders	  <br/>beyond	  the	  use	  for	  which	  it	  was	  originally	  col&#160;ected	  (e.g.	  Facebook	  or	  Twitter	  data).	  <br/>
Respondent:&#160;Celia Lury, Centre for&#160;Interdisciplinary Methods, University of&#160;Warwick&#160;<br/>In	  evaluating	  the	  col&#160;aborative	  approach,	  Celia	  Lury	  commenced	  by	  reflecting	  on	  the	  different	  <br/>pronunciations	  of	  the	  term,	  “col&#160;aboratory”,	  which	  she	  suggested	  reflects	  something	  of	  the	  <br/>history	  of	  the	  term.	  Whereas	  the	  term	  “co-­‐laboratory”	  emerged	  in	  a	  scientific	  context,	  the	  <br/>“col&#160;aboratory”	  as	  a	  col&#160;aborative	  method	  is	  more	  widely	  used	  in	  the	  humanities	  and	  social	  <br/>sciences.	  Celia	  contended	  that	  both	  inflections	  are	  useful.	  Employing	  the	  col&#160;aborative	  <br/>approach	  in	  relation	  to	  Big	  Data	  has	  shaped	  how	  the	  team	  organised	  the	  col&#160;aboratories	  in	  <br/>terms	  of	  the	  kinds	  of	  questions	  asked	  and	  the	  practitioners	  with	  whom	  we	  col&#160;aborated.	  <br/>Interdisciplinarity	  is	  often	  precipitated	  by	  a	  notion	  of	  crisis,	  the	  idea	  that	  there	  are	  pressing	  <br/>problems	  that	  require	  disciplines	  to	  come	  together.	  Big	  Data	  is	  an	  emerging	  field	  that	  disrupts	  <br/>and	  challenges	  standard	  working	  practices	  and	  lends	  itself	  to	  interdisciplinarity	  and	  asking	  <br/>questions	  such	  as:	  What	  is	  Big	  Data	  as	  a	  problem	  space	  and	  how	  can	  we	  this	  space	  through	  <br/>different	  modes	  of	  col&#160;aboration?	  Big	  Data	  involves	  a	  redistribution	  of	  data	  col&#160;ection	  and	  <br/>research	  methods	  expertise	  and	  the	  restructuring	  of	  infrastructures,	  which	  necessitate	  <br/>engagements	  with	  a	  wider	  range	  of	  col&#160;aborators.	  In	  order	  to	  address	  questions	  around	  the	  <br/>social	  life	  of	  Big	  Data	  then	  requires	  engagement	  with	  practitioners	  from	  both	  the	  public	  and	  <br/>private	  sector.	  <br/>
From	  a	  social	  science	  perspective,	  col&#160;aboratories	  provide	  a	  testing	  ground	  for	  concept	  <br/>development.	  It	  is	  important	  to	  consider	  whether	  we	  have	  learnt	  anything	  about	  the	  kind	  of	  <br/>“socialising”	  involved.	  For	  example,	  what	  are	  the	  frameworks	  for	  thinking	  about	  Big	  Data?	  In	  <br/>terms	  of	  policy,	  we	  have	  legal,	  economic	  and	  political	  frameworks	  for	  thinking	  about	  Big	  Data.	  <br/>Should	  we	  add	  a	  social	  framework	  for	  thinking	  about	  Big	  Data	  and,	  if	  so,	  how	  would	  a	  social	  <br/>framing	  be	  different	  from	  these	  existing	  modes	  of	  analysis?	  From	  this	  perspective,	  col&#160;aboration	  <br/>may	  be	  thought	  of	  as	  an	  iterative	  process	  distributed	  not	  only	  in	  terms	  of	  space,	  but	  time.	  In	  <br/>terms	  of	  knowledge	  production,	  col&#160;aboratories	  bring	  social	  scientists	  into	  the	  col&#160;aborative	  <br/>process	  from	  the	  outset	  rather	  than	  merely	  being	  there	  to	  challenge,	  critique	  and	  problematise	  <br/>the	  findings	  of	  social	  scientific	  research.	  What	  is	  exciting	  about	  col&#160;aboratories	  is	  that	  they	  help	  <br/>us	  to	  move	  beyond	  individualised	  disciplines	  and	  projects	  by	  providing	  a	  method	  to	  develop	  <br/>and	  tests	  concepts.	  <br/>
13	  <br/>
	  <br/>
<hr/>
<a name=14></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
Respondent:&#160;&#160;Hannah&#160;Knox,&#160;Dept.&#160;of&#160;Anthropology,&#160;University&#160;College&#160;London&#160;<br/>Hannah	  Knox	  responded	  to	  these	  discussions	  by	  reflecting	  on	  the	  genesis	  of	  the	  project.	  She	  <br/>noted	  that	  the	  col&#160;aboratories	  were	  conceived	  at	  CRESC	  as	  a	  way	  to	  make	  academic	  research	  <br/>more	  useful	  and	  to	  have	  a	  greater	  impact.	  The	  method	  was	  designed	  as	  an	  experiment	  to	  trial	  <br/>the	  impact	  of	  opening	  up	  communication	  by	  assembling	  people	  (researchers,	  stakeholders	  and	  <br/>practitioners)	  at	  the	  initial	  stage	  of	  questioning	  and	  agenda	  setting	  rather	  than	  merely	  <br/>documenting	  findings	  towards	  the	  end	  of	  a	  project,	  as	  is	  typically	  the	  case	  in	  academic	  <br/>research.	  <br/>
In	  light	  of	  these	  objectives,	  Hannah	  emphasised	  the	  interrelationship	  between	  col&#160;aboratory	  as	  <br/>method	  and	  the	  topic	  of	  Big	  Data.	  When	  problematised,	  Big	  Data	  requires	  particular	  forms	  of	  <br/>col&#160;aboration	  between	  different	  stakeholders	  and	  practitioners.	  Despite	  the	  wil&#160;	  and	  ambition	  <br/>for	  col&#160;aboration,	  commercial	  and	  political	  interests	  can	  act	  as	  powerful	  boundaries	  to	  <br/>col&#160;aboration	  on	  the	  topic	  of	  Big	  Data.	  This	  Final	  Col&#160;aboratory	  provided	  a	  neutral	  space	  in	  <br/>which	  to	  discuss	  some	  of	  these	  challenges,	  such	  as	  attempts	  to	  integrate	  Nectar	  card	  data	  from	  <br/>Sainsbury’s	  loyalty	  card	  schemes	  with	  that	  of	  other	  organisations,	  which	  was	  blocked	  due	  to	  <br/>Sainsbury’s	  existing	  relationships	  with	  other	  commercial	  enterprises.	  In	  this	  regard,	  <br/>col&#160;aboration	  provides	  a	  useful	  way	  to	  understand	  the	  problems	  of	  working	  with	  Big	  Data.	  <br/>Through	  this	  approach,	  for	  example,	  we	  can	  identify	  who	  the	  important	  players	  are	  and	  ask	  <br/>questions	  about	  this	  burgeoning	  topic.	  The	  Final	  Col&#160;aboratory	  has	  revealed	  some	  of	  the	  key	  <br/>players	  in	  the	  field,	  but	  certain	  stakeholders	  were	  absent,	  such	  as,	  the	  users	  and	  producers	  of	  <br/>Big	  Data.	  <br/>
Hannah	  ended	  her	  presentation	  by	  thinking	  about	  how	  to	  proceed	  with	  the	  col&#160;aborative	  <br/>approach.	  She	  emphasised	  the	  value	  of	  developing	  a	  shared	  vocabulary,	  but	  was	  curious	  about	  <br/>whether	  this	  would	  take	  an	  oral	  or	  written	  form	  (via	  publications	  or	  an	  extension	  of	  the	  working	  <br/>paper,	  for	  example).	  She	  then	  asked	  whether	  col&#160;aboratories	  would	  lead	  to	  new	  modes	  of	  <br/>experimentation	  or	  novel	  research	  projects,	  concluding	  by	  highlighting	  the	  importance	  of	  <br/>talking	  col&#160;ectively	  about	  the	  benefits	  of	  col&#160;aboration	  as	  a	  method.	  <br/>
<b>General&#160;closing&#160;discussion&#160;<br/></b>The	  group	  engaged	  in	  a	  general	  discussion	  and	  raised	  the	  fol&#160;owing	  points	  about	  the	  <br/>col&#160;aboratories	  and	  what	  was	  accomplished.	  <br/>
•&#160;&#160;What	  has	  been	  started	  here	  should	  not	  sit	  on	  a	  shelf;	  this	  was	  just	  a	  beginning.	  <br/>•&#160;&#160;One	  of	  the	  outcomes	  has	  been	  the	  establishment	  of	  a	  diverse	  network	  of	  people	  engaged	  in	  <br/>
questions	  of	  Big	  Data.	  &#160;Out	  of	  this	  we	  could	  consider	  possibilities	  such	  as	  a	  project	  involving	  <br/>
waste	  management	  authorities,	  ONS	  and	  social	  scientists.	  <br/>
•&#160;&#160;The	  project	  has	  widened	  horizons	  and	  enabled	  connections	  that	  might	  not	  otherwise	  have	  <br/>
happened.	  The	  diverse	  and	  conversational	  approach	  of	  the	  final	  col&#160;aboratory	  was	  <br/>
14	  <br/>
	  <br/>
<hr/>
<a name=15></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
appreciated;	  it	  enabled	  people	  to	  speak	  without	  the	  fetters	  of	  ‘credentials’	  and	  provided	  a	  <br/>
safe	  environment	  to	  think	  out	  loud.	  That	  said,	  more	  provocation	  and	  controversy	  could	  <br/>
have	  been	  introduced.	  <br/>
•&#160;&#160;The	  working	  paper	  was	  especially	  helpful.	  &#160;But	  an	  alternative	  approach	  to	  the	  structure	  of	  <br/>
the	  col&#160;aboratories	  would	  be	  good	  to	  consider.	  &#160;The	  position	  of	  the	  social	  scientists	  seemed	  <br/>
to	  be	  more	  as	  observers	  rather	  than	  active	  participants.	  It	  would	  be	  good	  to	  consider	  a	  <br/>
model	  that	  is	  more	  of	  a	  mix.	  <br/>
•&#160;&#160;The	  insights	  of	  the	  project	  need	  to	  come	  forward	  especially	  in	  the	  face	  of	  documents	  such	  <br/>
as	  the	  EC	  data	  driven	  economy	  –	  why	  not	  think	  about	  a	  data	  driven	  society?	  <br/>
•&#160;&#160;More	  private	  sector	  involvement	  would	  be	  a	  good	  next	  step	  as	  wel&#160;	  as	  from	  data	  scientists,	  <br/>
privacy	  groups,	  data	  journalists	  and	  so	  on.	  Additional	  fol&#160;ow-­‐up	  actions	  would	  be	  good	  to	  <br/>
identify.	  <br/>
•&#160;&#160;It	  is	  good	  to	  talk	  about	  Big	  Data	  but	  what	  is	  also	  needed	  is	  a	  space	  for	  not	  just	  flying	  ideas	  <br/>
but	  doing	  Big	  Data	  that	  could	  support	  the	  move	  to	  policy	  development.	  <br/>
•&#160;&#160;The	  concept	  of	  socialising	  is	  useful	  for	  understanding	  the	  different	  norms	  of	  different	  <br/>
disciplines	  and	  interests	  and	  the	  benefits	  of	  mixing	  or	  ‘socialising’	  them.	  <br/>
•&#160;&#160;How	  might	  the	  international	  aspects	  of	  Big	  Data	  be	  better	  leveraged?	  Recognizing	  that	  Big	  <br/>
Data	  generated	  by	  online	  platforms	  cuts	  across	  national	  borders	  it	  would	  be	  useful	  to	  have	  <br/>
forums	  that	  address	  this.	  <br/>
	  <br/>
<b>&#160;</b><br/>
15	  <br/>
	  <br/>
<hr/>
<a name=16></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
Appendix&#160;B:&#160;Summaries&#160;of&#160;Context-specific&#160;Collaboratories&#160;<br/>
<b>Collaboratory 1: Metrics&#160;for DNA&#160;&#160;<br/>How	  to	  make	  sense	  of	  what	  is	  going	  on	  in	  contemporary	  genomics?	  </b><br/>
<b>Overview&#160;<br/></b>Genomics	  is	  possibly	  one	  of	  the	  most	  sustained	  attempts	  at	  counting	  things	  ever	  undertaken	  in	  <br/>the	  modern	  life	  sciences.	  Genomics	  and	  various	  related	  ‘omics’	  fields	  have	  developed	  an	  <br/>intricate	  infrastructure	  for	  generating,	  storing,	  sorting	  out	  and	  counting	  data	  on	  living	  things.	  <br/>
This	  workshop	  brought	  together	  genomic	  researchers,	  social	  scientists,	  various	  experts	  and	  <br/>stakeholders	  to	  discuss	  the	  metrics	  for	  genomic	  data	  in	  various	  contexts	  ranging	  across	  its	  <br/>making,	  its	  circulation	  (through	  databases	  and	  other	  infrastructures),	  and	  its	  analysis	  and	  use	  in	  <br/>various	  settings	  (academic,	  scientific,	  clinical,	  government	  and	  commercial).	  <br/>
A	  core	  question	  was:	  What	  kinds	  of	  metrics	  best	  serve	  and	  account	  for	  genomics	  as	  a	  counting	  <br/>project’?	  <br/>
There	  is	  a	  veritable	  deluge	  of	  data	  metrics	  associated	  with	  genomic	  data:	  base	  pairs/genome,	  <br/>cost/base	  pair,	  runs/day,	  Tb/day,	  Gb/genome,	  $000s/genome,	  15	  months	  ‘doubling	  time’,	  as	  <br/>wel&#160;	  as	  all	  the	  numbers	  and	  counts	  used	  in	  accounts	  of	  genomics	  in	  practice	  (18,000	  genes;	  3	  <br/>bil&#160;ion	  base	  pairs;	  2%	  of	  the	  genome;	  35	  population	  groups;	  23%	  missing	  heritability,	  100,000	  <br/>genomes).	  <br/>
These	  metrics	  often	  drive	  and	  motivate	  developments	  in	  genomics.	  Yet	  at	  the	  same	  time,	  many	  <br/>discussions,	  interventions	  and	  presentations	  on	  genomics	  suggest	  an	  acute	  awareness	  of	  <br/>missing	  metrics;	  of	  the	  need	  to	  develop	  metrics	  that	  are	  more	  refined,	  accurate	  or	  relevant.	  <br/>
When	  and	  for	  whom	  and	  in	  what	  contexts	  are	  basic	  metrics	  useful	  (e.g.	  like	  cost/base	  pair)?	  We	  <br/>are	  interested	  in	  finding	  out	  about	  what	  really	  counts	  in	  genomics	  today	  and	  why.	  <br/>
This	  col&#160;aboratory	  was	  organised	  by	  Professor	  Adrian	  Mackenzie	  and	  Dr	  Ruth	  McNally	  and	  held	  <br/>on	  2	  December	  2013	  at	  the	  Wellcome	  Trust	  Genome	  Campus,	  Hinxton,	  Cambridgeshire,	  UK.	  <br/>
Speakers	  included:	  <br/>
1.&#160;&#160;<b>Neil	  Hall</b>,	  Advanced	  Genomics,	  University	  of	  Liverpool	  <br/>
2.&#160;&#160;<b>Sarah	  Ayling</b>,	  BBSRC	  Genome	  Analysis	  Centre	  (TGAC)	  <br/>
3.&#160;&#160;<b>Lucy	  Raymond</b>,	  Cambridge	  University	  <br/>
4.&#160;&#160;<b>Gurdeep	  Sagoo</b>,	  Public	  Health	  Genomics	  Foundation	  <br/>
5.&#160;&#160;<b>Laura	  Clarke</b>,	  Re-­‐sequencing	  Informatics,	  European	  Bioinformatics	  Institute	  (EBI)	  <br/>
6.&#160;&#160;<b>Chris	  Hayman</b>,	  Amazon	  Web	  Services	  <br/>
7.&#160;&#160;<b>Will	  Spooner</b>,	  Eagle	  Genomics	  <br/>
16	  <br/>
	  <br/>
<hr/>
<a name=17></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
8.&#160;&#160;<b>Rasko	  Leinonen</b>,	  European	  Nucleotide	  Archive	  (ENA),	  European	  Bioinformatics	  <br/>
Institute	  (EBI)	  <br/>
	  <br/>
Some	  background	  readings	  on	  Big	  Data	  and	  Genomics	  were	  circulated	  in	  advance:	  <br/>
•&#160;&#160;Boyle,	  J.	  (2013).	  Biology	  must	  develop	  its	  own	  big-­‐data	  systems.	  <i>Nature</i>.	  499.	  <br/>•&#160;&#160;Cochrane,	  G.,	  Alako,	  B.,	  Amid,	  C.,	  Bower,	  L.,	  Cerdeño-­‐Tárraga,	  A.,	  Cleland,	  I.,...&amp;	  Zalunin,	  V.	  <br/>
(2013).	  Facing	  growth	  in	  the	  European	  nucleotide	  archive.	  <i>Nucleic	  Acids	  Research</i>,	  <i>41</i>(D1),	  <br/>
D30-­‐D35.	  <br/>
•&#160;&#160;Hall,	  N.	  (2013).	  After	  the	  gold	  rush.	  <i>Genome	  Biology</i>,	  <i>14</i>(5),	  115.	  <br/>•&#160;&#160;Kodama,	  Y.,	  Shumway,	  M.,	  &amp;	  Leinonen,	  R.	  (2012).	  The	  Sequence	  Read	  Archive:	  explosive	  <br/>
growth	  of	  sequencing	  data.	  <i>Nucleic	  Acids	  Research</i>,	  <i>40</i>(D1),	  D54-­‐D56.	  <br/>
•&#160;&#160;Piton,	  A.,	  Redin,	  C.,	  &amp;	  Mandel,	  J.	  L.	  (2013).	  XLID-­‐causing	  mutations	  and	  associated	  genes	  <br/>
challenged	  in	  light	  of	  data	  from	  large-­‐scale	  human	  exome	  sequencing.	  <i>The	  American	  Journal	  </i><br/>
<i>of	  Human	  Genetics</i>,	  <i>93</i>(2),	  368-­‐383.	  <br/>
•&#160;&#160;Wetterstrand,	  K.	  A.	  (2013).	  DNA	  Sequencing	  Costs:	  Data	  from	  the	  NHGRI	  Genome	  <br/>
Sequencing	  Program	  (GSP).	  <i>URL	  Available	  at:	  www.	  genome.	  gov/sequencingcosts</i>.	  <br/>
•&#160;&#160;Wright,	  D.	  C.	  (2011).	  Next	  steps	  in	  the	  sequence:	  the	  implications	  of	  whole	  genome	  <br/>
sequencing	  for	  health	  in	  the	  UK.	  PHG	  Foundation.	  <br/>
	  <br/>
<b>Summary&#160;of&#160;Presentations&#160;</b><br/>
Neil Hall: Genomics and economics in a research setting&#160;<br/>Neil	  Hall	  discussed	  the	  relationship	  between	  genomics	  and	  economics	  in	  a	  research	  setting.	  <br/>DNA	  sequencing	  is	  used	  to	  measure	  a	  range	  of	  factors	  from	  sequencing	  genomes,	  assaying	  <br/>differences	  between	  genomes,	  mutation	  screening,	  population	  genetics	  and	  environmental	  <br/>sequencing.	  The	  metrics	  that	  scientists	  are	  most	  interested	  in	  are	  the	  length	  and	  quality	  of	  the	  <br/>sequence.	  Sequencing	  costs	  are	  crucial	  for	  science.	  Rapid	  developments	  in	  DNA	  sequencing	  <br/>technologies	  have	  revolutionised	  contemporary	  genomics.	  In	  just	  10	  years,	  the	  cost	  to	  <br/>sequence	  a	  genome	  has	  reduced	  from	  $100m	  to	  $5k.	  Improvements	  in	  the	  time	  and	  cost	  it	  <br/>takes	  to	  sequence	  a	  human	  genome	  have	  led	  to	  new	  opportunities	  and	  efficiency	  gains	  (e.g.	  <br/>single	  molecule	  sequencing	  provides	  new	  opportunities	  for	  real-­‐time	  research).	  <br/>
Genomic	  sequencing	  has	  become	  a	  commodity	  with	  a	  predictable	  market	  value.	  But	  although	  <br/>the	  cost	  to	  sequence	  a	  genome	  has	  become	  relatively	  predictable,	  project	  complexity	  remains	  <br/>difficult	  to	  quantify	  and	  measure.	  Sequence	  reads	  and	  quality	  scores	  require	  more	  tertiary	  <br/>analysis	  to	  be	  made	  meaningful	  (e.g.	  via	  multi-­‐sample	  processing,	  data	  aggregation	  and	  <br/>population	  structure	  analysis).	  Applications	  and	  platforms,	  moreover,	  can	  produce	  substantially	  <br/>different	  results.	  Part	  of	  the	  problem	  is	  that	  the	  analytical	  tools	  and	  gene	  sequencing	  devices	  <br/>designed	  to	  read	  and	  process	  genomic	  information	  have	  different	  properties,	  errors,	  costs	  and	  <br/>
17	  <br/>
	  <br/>
<hr/>
<a name=18></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
read	  lengths.	  These	  result	  in	  methodological	  differences	  in	  terms	  of	  content,	  quality	  and	  scale.	  <br/>Another	  metric	  that	  cannot	  be	  measured	  is	  the	  time	  is	  wil&#160;	  take	  to	  analyse	  data.	  The	  complexity	  <br/>of	  a	  given	  project	  wil&#160;	  largely	  depend	  on	  what	  data	  is	  produced	  and	  where	  the	  data	  leads,	  which	  <br/>cannot	  be	  known	  beforehand.	  Different	  analyses	  require	  different	  data	  properties.	  We	  are	  not	  <br/>simply	  measuring	  genomes,	  but	  making	  them	  meaningful.	  While	  increased	  throughput	  and	  <br/>decreasing	  costs	  place	  pressure	  on	  analyses,	  for	  some	  projects	  long	  read	  technologies	  are	  <br/>prioritised	  over	  cost.	  In	  short,	  the	  current	  status	  of	  biotechnology	  is	  a	  compromise	  between	  <br/>cost,	  quality	  and	  length.	  <br/>
Sarah&#160;Ayling:&#160;Wheat&#160;Genome&#160;Assembly&#160;Strategies&#160;<br/>Sarah	  Ayling	  discussed	  the	  different	  approaches	  taken	  to	  assemble	  the	  bread	  wheat	  genome:	  a	  <br/>large,	  highly	  repetitive	  and	  polyploid	  genome.	  The	  most	  common	  metric	  used	  to	  describe	  <br/>assembly	  quality	  is	  N50,	  which	  captures	  data	  about	  the	  fragmentation	  of	  the	  assembly.	  <br/>However,	  this	  metric	  neglects	  data	  related	  to	  the	  accuracy	  or	  completeness	  of	  what	  has	  been	  <br/>assembled.	  The	  quality	  assessment	  tool	  (KAT)	  developed	  at	  BBSRC	  Genome	  Analysis	  Centre	  <br/>(TGAC)	  is	  based	  on	  kmer-­‐spectra,	  which	  can	  be	  used	  to	  reveal	  properties	  of	  the	  genome	  <br/>sample,	  in	  addition	  to	  properties	  of	  the	  resulting	  assemblies	  and	  their	  completeness.	  Other	  <br/>metrics	  regularly	  used	  include	  genome/assembly	  size,	  ploidy,	  sequence	  read	  coverage,	  number	  <br/>of	  contigs,	  number	  of	  mapped	  transcripts	  and	  their	  sequence	  similarity	  (percentage	  identity),	  <br/>and	  cost.	  <br/>
Working	  with	  complex	  plant	  genomes	  and	  large	  genomes	  can	  raise	  a	  series	  of	  challenges.	  When	  <br/>working	  with	  genomic	  data,	  the	  problem	  is	  that	  the	  metrics	  you	  want	  to	  know	  before	  <br/>conducting	  your	  sequencing	  experiment	  are	  often	  missing.	  Researchers	  do	  not	  always	  know	  the	  <br/>ploidy,	  heterozygosity	  levels	  or	  genome	  size,	  for	  example,	  before	  they	  start	  sequencing.	  In	  <br/>effect,	  this	  means	  that	  a	  degree	  of	  pilot	  sequencing	  is	  always	  required	  to	  get	  an	  idea	  of	  the	  <br/>scope	  and	  complexity	  required	  for	  the	  project	  design.	  <br/>
Lucy&#160;Raymond:&#160;How&#160;to&#160;make&#160;sense&#160;of&#160;DNA&#160;variants&#160;as&#160;a&#160;cause&#160;of&#160;disease&#160;<br/>Lucy	  Raymond	  discussed	  how	  to	  make	  sense	  of	  DNA	  variants	  as	  a	  cause	  of	  disease.	  Big	  data	  <br/>technologies	  process	  data	  into	  small,	  specific	  and	  true	  variants	  for	  the	  individual	  so	  that	  they	  <br/>can	  understand	  their	  disease	  and	  its	  implications	  to	  their	  wider	  family,	  improve	  their	  treatment	  <br/>and	  access	  to	  appropriate	  health	  care.	  Big	  data	  has	  the	  potential	  to	  help	  researchers	  to	  find	  the	  <br/>single	  variant	  that	  is	  the	  cause	  of	  disease.	  But	  the	  greater	  the	  number	  of	  variants	  in	  the	  data	  <br/>itself,	  the	  more	  difficult	  data	  is	  to	  analyse.	  Issues	  arise,	  for	  example,	  over	  which	  method(s)	  <br/>should	  be	  used	  to	  identify	  the	  true	  sequence	  of	  the	  DNA.	  Complexity	  poses	  a	  potential	  problem	  <br/>for	  analysis	  because	  there	  are	  many	  variables	  to	  measure.	  Paradoxically,	  the	  more	  knowledge	  <br/>that	  emerges	  about	  any	  one	  rare	  variant,	  the	  less	  certain	  we	  seem	  to	  be	  that	  this	  information	  is	  <br/>sufficient	  to	  reveal	  or	  predict	  the	  disease	  severity.	  <br/>
18	  <br/>
	  <br/>
<hr/>
<a name=19></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
At	  present,	  we	  cannot	  measure	  the	  cause	  of	  the	  disease.	  Just	  because	  a	  variant	  is	  detected	  in	  <br/>an	  individual	  with	  a	  disease,	  this	  correlation	  does	  not	  imply	  causation.	  When	  looking	  for	  the	  <br/>important	  variants	  associated	  with	  intel&#160;ectual	  disability,	  for	  example,	  many	  factors	  can	  be	  at	  <br/>play	  (e.g.	  genetically	  highly	  heterogeneous,	  multiple	  possible	  causes).	  Processing	  this	  data	  into	  <br/>meaningful	  information	  consequently	  introduces	  a	  series	  of	  risks,	  which	  include	  balancing	  <br/>judgement	  of	  variant	  causation	  with	  the	  risk	  of	  harm	  if	  the	  data	  is	  incorrect	  or	  misinterpreted.	  <br/>
At	  present,	  the	  key	  metrics	  that	  clinicians	  rely	  on	  daily	  vary	  from	  the	  quality	  assurance	  of	  gene	  <br/>analysis,	  gene	  variation,	  quantity,	  the	  cost	  of	  testing,	  and	  whether	  the	  variant	  has	  been	  <br/>reported	  before.	  In	  the	  long	  term,	  key	  metrics	  wil&#160;	  include	  cost	  reduction,	  improved	  clinical	  <br/>utility,	  and	  the	  potential	  for	  cost	  effective	  individualised	  health	  care.	  To	  improve	  the	  quality	  of	  <br/>analysis	  we	  need	  a	  greater	  volume	  of	  genomic	  data	  pertaining	  to	  patients	  with	  rare	  disease.	  <br/>
Gurdeep&#160;Sagoo, Public Health Genomics Foundation:&#160;Evaluating&#160;the&#160;(costs&#160;and)&#160;<br/>
benefits of&#160;NGS&#160;<br/>Gurdeep	  Sagoo	  evaluated	  the	  &#34;costs”	  and	  benefits	  of	  next	  generation	  sequencing	  (NGS).	  In	  the	  <br/>context	  of	  health	  care,	  economic	  evaluation	  is	  used	  to	  identify,	  measure,	  value	  and	  then	  <br/>compare	  both	  the	  costs	  and	  the	  consequences	  of	  two	  or	  more	  alternative	  programmes	  or	  <br/>interventions	  in	  order	  to	  make	  a	  recommendation	  on	  which	  alternative	  should	  be	  used.	  <br/>Initiatives	  of	  this	  kind	  aim	  to	  accelerate	  the	  application	  of	  advances	  in	  biomedicine	  and	  <br/>genomics	  within	  health	  services	  for	  patient	  benefit	  in	  ways	  that	  are	  fast,	  effective,	  fair	  and	  <br/>responsible.	  <br/>
The	  application	  of	  economic	  evaluation	  in	  the	  field	  of	  the	  genetic	  testing	  using	  next	  generation	  <br/>sequencing	  technology	  has	  raised	  a	  series	  of	  challenges.	  This	  is	  because	  many	  different	  metrics	  <br/>are	  needed	  for	  such	  an	  evaluation.	  These	  can	  be	  epidemiological	  in	  nature	  (prevalence)	  or	  <br/>analytical	  in	  nature	  (measures	  of	  sensitivity	  and	  specificity	  related	  to	  both	  assay	  and	  tests).	  <br/>While	  economic	  evaluation	  can	  introduce	  additional	  metrics	  such	  as	  cost-­‐effectiveness,	  the	  <br/>current	  challenges	  remain	  mostly	  methodological.	  Health	  economists	  must	  develop	  new	  <br/>approaches	  or	  reach	  a	  consensus	  on	  the	  appropriate	  existing	  methodology	  to	  use	  in	  order	  to	  <br/>overcome	  challenges	  related	  to	  which	  analytical	  approach	  to	  use,	  which	  costs	  and	  outcomes	  <br/>should	  be	  measured,	  and	  how	  these	  should	  be	  valued.	  At	  present,	  next	  generation	  sequencing	  <br/>technology	  raises	  more	  questions	  than	  answers.	  <br/>
Laura Clarke:&#160;Metrics&#160;for&#160;high&#160;throughput&#160;genomics&#160;projects&#160;<br/>Laura	  Clarke	  presented	  on	  metrics	  for	  high	  throughput	  genomics	  projects.	  Large	  scale	  data	  <br/>col&#160;ection	  projects,	  such	  as	  the	  1000	  Genomes	  Project,	  Blueprint	  and	  Hipsi,	  col&#160;ect	  metrics	  <br/>about	  their	  data	  which	  fall	  into	  4	  main	  categories:	  quantity,	  quality,	  identity	  and	  consistency.	  <br/>
19	  <br/>
	  <br/>
<hr/>
<a name=20></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
A	  primary	  challenge	  for	  these	  projects	  is	  that	  they	  meet	  their	  targets	  in	  terms	  of	  quantity.	  This	  <br/>includes	  whether	  the	  appropriate	  number	  of	  experiments	  on	  the	  correct	  number	  of	  samples	  <br/>are	  conducted.	  The	  1000	  Genomes	  Project	  overcame	  this	  issue	  by	  tracking	  the	  data	  that	  the	  <br/>different	  sequencing	  centers	  produced	  and	  declaring	  data	  freezes	  to	  track	  how	  much	  data	  was	  <br/>available	  on	  each	  sample	  and	  to	  determine	  whether	  they	  met	  the	  specified	  targets.	  <br/>
In	  addition	  to	  quantity,	  the	  quality	  of	  data	  plays	  an	  important	  role	  in	  deciding	  whether	  the	  <br/>sufficient	  number	  of	  experiments	  have	  been	  completed.	  In	  the	  Blueprint	  Epigenome	  project,	  <br/>for	  example,	  expression	  as	  measured	  by	  RNA-­‐Seq	  experiments	  undergo	  quality	  checks	  by	  <br/>comparing	  the	  alignment	  of	  the	  sequence	  to	  gene	  models	  and	  ensuring	  that	  a	  sufficient	  <br/>proportion	  of	  the	  sequence	  falls	  in	  gene	  bodies.	  Identity	  and	  Consistency	  are	  also	  checked	  to	  <br/>ensure	  that	  samples	  and	  data	  are	  internally	  consistent.	  These	  require	  more	  specialised	  <br/>methods	  that	  are	  created	  for,	  and	  then	  applied	  to,	  the	  project	  in	  question.	  <br/>
Chris&#160;Hayman:&#160;Research&#160;Computing&#160;on&#160;Amazon&#160;Web&#160;Services&#160;<br/>Chris	  Hayman,	  from	  Amazon	  Web	  Services	  (AWS)	  provided	  a	  commercial	  perspective	  on	  <br/>genomics	  and	  cloud	  computing.	  Big	  data	  technologies	  offer	  new	  possibilities	  to	  the	  field	  of	  <br/>genomics.	  New	  DNA	  sequencing	  devices	  have	  the	  potential	  to	  introduce	  efficiency	  gains	  by	  <br/>reducing	  the	  time	  and	  cost	  of	  recording	  the	  series	  of	  bases	  that	  encode	  genetic	  information.	  <br/>
In	  spite	  of	  the	  opportunities	  that	  Big	  Data	  introduce,	  these	  technologies	  raise	  a	  series	  of	  <br/>problems	  regarding	  the	  diversity,	  complexity	  and	  volume	  of	  data	  produced	  by	  gene	  sequencers.	  <br/>The	  challenge	  that	  research	  labs	  experience	  is	  largely	  concerned	  with	  volume	  and	  variety,	  <br/>namely	  how	  to	  manage,	  analyse	  and	  disseminate	  the	  increasingly	  large	  data	  sets	  generated	  by	  <br/>genome	  sequencing	  platforms.	  <br/>
The	  complexity	  of	  genomic	  research	  has	  introduced	  further	  challenges,	  such	  as	  data	  <br/>management	  and	  access	  to	  valuable	  data	  sets.	  Previously,	  large	  data	  sets	  (e.g.	  The	  Human	  <br/>Genome	  Project	  (HGP))	  proved	  difficult	  to	  locate,	  download,	  customise	  and	  analyse.	  Amazon	  <br/>Web	  Services	  has	  devised	  a	  solution	  to	  this	  problem,	  introducing	  new	  technologies	  (e.g.	  AWS	  <br/>Cloud)	  that	  provide	  scalable,	  cost-­‐effective,	  flexible	  and	  secure	  storage	  services	  (e.g.	  Amazon	  <br/>S3)	  to	  manage	  and	  analyse	  genomic	  data	  (e.g.	  Amazon	  Kinesis	  &amp;	  EMR).	  In	  addition	  to	  hosting	  <br/>data,	  this	  service	  also	  provides	  access	  to	  a	  variety	  of	  public	  data	  sets.	  <br/>
Will&#160;Spooner:&#160;Measuring&#160;Commercial&#160;Bioinformatics&#160;&#160;<br/>Wil&#160;	  Spooner,	  the	  founder	  of	  Eagle	  Genomics	  (2008),	  put	  forward	  a	  commercial	  perspective	  on	  <br/>genomics	  R&amp;D.	  Big	  data	  has	  conventionally	  been	  defined	  in	  terms	  of	  the	  &#34;3Vs”:	  Volume,	  <br/>Velocity	  and	  Variety.	  Spooner	  considered	  this	  definition	  inadequate.	  He	  proposed	  an	  emerging	  <br/>fourth	  variable	  metric:	  Veracity.	  This	  move	  towards	  veracity	  as	  an	  integral	  (missing)	  metric	  for	  <br/>genomic	  data	  was	  traced	  through	  a	  history	  of	  the	  field	  of	  genomics.	  From	  a	  commercial	  <br/>
20	  <br/>
	  <br/>
<hr/>
<a name=21></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
standpoint,	  customers	  were	  initially	  focused	  on	  volume,	  namely	  how	  to	  consume,	  store	  and	  <br/>manage	  the	  large	  data	  sets	  and	  resources	  available.	  Customers	  then	  became	  interested	  in	  their	  <br/>own	  genomic	  data,	  and	  the	  increasing	  rate	  at	  which	  it	  was	  being	  generated.	  This	  occasioned	  a	  <br/>shift	  towards	  velocity,	  from	  processing	  their	  data	  on	  workstations	  to	  high	  performance	  <br/>compute	  clusters	  or	  cloud	  computing	  technologies.	  Once	  volume	  and	  velocity	  were	  measured,	  <br/>users	  began	  to	  extract	  value	  from	  the	  data,	  which	  required	  a	  variety	  of	  data	  sources	  (e.g.	  <br/>integration	  both	  with	  the	  consensus	  reference,	  and	  also	  with	  data	  assets	  col&#160;ected	  by	  the	  <br/>enterprise	  in	  previous	  R&amp;D	  efforts).	  More	  recently,	  the	  emphasis	  has	  been	  on	  a	  new	  metric:	  <br/>veracity,	  as	  users	  seek	  to	  assess	  the	  quality	  of	  “raw”	  data.	  <br/>
Assessing	  the	  veracity	  of	  genomic	  data	  raises	  methodological	  issues	  concerned	  with	  processing	  <br/>bioinformatics	  (i.e.	  how	  to	  store,	  organise,	  retrieve,	  and	  analyse	  biological	  data),	  and	  ethical	  <br/>concerns	  regarding	  how	  diagnostics	  developed	  from	  “omics”	  technologies	  should	  be	  regulated	  <br/>in	  the	  clinic?	  At	  present,	  there	  is	  much	  debate	  in	  this	  area,	  which	  represents	  the	  current	  <br/>frontier	  of	  modern	  translational	  genomics.	  <br/>
Rasko&#160;Leinonen:&#160;Organisation&#160;and&#160;growth&#160;of&#160;NGS&#160;data&#160;in&#160;the&#160;European&#160;Nucleotide&#160;<br/>
Archive&#160;<br/>Rasko	  Leinonen	  discussed	  the	  organisation	  and	  growth	  of	  next	  generation	  sequencing	  (NGS)	  <br/>data	  in	  the	  European	  Nucleotide	  Archive.	  NGS	  platforms	  are	  producing	  data	  with	  significantly	  <br/>higher	  throughput	  and	  lower	  cost.	  A	  portion	  of	  this	  capacity	  is	  devoted	  to	  individual	  and	  <br/>community	  scientific	  projects.	  As	  these	  projects	  reach	  publication,	  “raw”	  sequencing	  data	  sets	  <br/>are	  submitted	  into	  next	  generation	  sequence	  data	  archives,	  such	  as	  the	  European	  Nucleotide	  <br/>Archive	  (ENA).	  <br/>
The	  ENA	  is	  a	  public	  data	  archive	  for	  nucleotide	  sequences	  operated	  as	  part	  of	  the	  International	  <br/>Nucleotide	  Sequence	  Database	  Col&#160;aboration	  (INSDC)	  with	  NCBI	  and	  DDBJ.	  The	  ENA	  has	  grown	  <br/>out	  of	  the	  EMBL	  Data	  Library,	  which	  was	  first	  released	  in	  1982.	  ENA	  measures	  the	  growth	  of	  the	  <br/>next-­‐generation	  sequence	  data	  using	  multiple	  metrics.	  The	  metrics	  most	  important	  to	  the	  ENA	  <br/>concern	  the	  number	  of	  sequenced	  samples	  and	  sequencing	  studies	  (e.g.	  the	  cumulative	  count	  <br/>and	  doubling	  time	  of	  studies),	  the	  number	  of	  sequenced	  reads	  and	  bases,	  and	  the	  number	  of	  <br/>sequenced	  genomes	  and	  transcriptomes.	  These	  metrics	  are	  then	  grouped	  by	  the	  INSDC	  Archive	  <br/>(ENA,	  NCBI,	  DDBJ),	  submitters	  and	  users	  (geographic	  region).	  The	  data	  is	  used	  by	  both	  internal	  <br/>and	  external	  user	  groups.	  <br/>
The	  proliferation	  of	  data	  produced	  (e.g.	  the	  volume	  of	  data	  and	  rate	  of	  increase)	  poses	  a	  <br/>potential	  problem	  for	  the	  ENA	  in	  terms	  data	  management	  and	  storage.	  A	  key	  challenge	  is	  how	  <br/>to	  choose	  the	  appropriate	  technology	  for	  data	  persistence	  based	  on	  number	  of	  identifiable	  <br/>objects,	  type	  and	  volume	  of	  data.	  The	  rate	  of	  growth	  must	  be	  monitored	  to	  assess	  future	  <br/>sustainability	  of	  current	  technologies,	  to	  assist	  in	  choice	  and	  adoption	  of	  new	  technologies,	  and	  <br/>
21	  <br/>
	  <br/>
<hr/>
<a name=22></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
to	  factor	  in	  the	  upper	  limit	  to	  identify	  and	  store	  data	  (e.g.	  POSIX	  file	  systems	  are	  not	  convenient	  <br/>for	  storing	  large	  number	  of	  files).	  Large	  volumes	  of	  NGS	  data	  are	  best	  compressed	  and	  stored	  as	  <br/>files	  outside	  any	  database.	  <br/>
	  <br/>
<b>&#160;</b><br/>
22	  <br/>
	  <br/>
<hr/>
<a name=23></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
<b>Collaboratory&#160;2:&#160;What&#160;Counts?&#160;Big&#160;Data&#160;and&#160;Official&#160;Statistics&#160;</b><br/>
Official	  statistics	  is	  one	  of	  the	  most	  comprehensive	  attempts	  to	  provide	  meaningful	  information	  <br/>to	  governments	  and	  decision	  makers.	  National	  Statistical	  Institutes	  (NSIs)	  have	  developed	  <br/>rigorous	  methods	  for	  col&#160;ecting	  and	  analysing	  data	  to	  produce	  and	  publish	  statistics	  related	  to	  <br/>the	  economy,	  population	  and	  society.	  	  <br/>
The	  col&#160;aboratory	  brought	  together	  national	  statisticians	  and	  social	  scientists	  to	  explore	  the	  <br/>range	  of	  meanings	  and	  implications	  of	  Big	  Data	  for	  official	  statistics	  by	  attending	  to	  the	  <br/>question:	  <i>What	  counts	  when	  using	  Big	  Data	  sources	  to	  produce	  official	  statistics?</i>	  <br/>
Big	  Data	  sources	  represent	  both	  an	  opportunity	  and	  challenge	  to	  official	  statistics.	  While	  Big	  <br/>Data	  have	  the	  potential	  to	  introduce	  efficiency	  gains	  (e.g.	  improved	  timeliness,	  cost	  savings),	  <br/>they	  raise	  significant	  methodological	  and	  ethical	  considerations	  regarding	  data	  quality,	  <br/>protection	  and	  management.	  From	  a	  methodological	  standpoint,	  working	  with	  Big	  Data	  sources	  <br/>requires	  new	  technical	  skil&#160;s,	  infrastructures	  and	  capacities.	  In	  this	  col&#160;aboratory,	  we	  focussed	  <br/>on	  how	  these	  issues	  require	  rethinking	  about	  what	  constitutes	  an	  official	  statistic.	  How	  does	  Big	  <br/>Data	  remake	  the	  substance	  and	  meaning	  of	  what	  is	  measured	  and	  captured,	  and	  how	  does	  this	  <br/>come	  to	  inform	  what	  counts?	  What	  counts	  also	  raises	  the	  question	  of	  who	  does	  the	  counting:	  <br/>what	  organisation	  or	  authority	  organises	  and	  mediates	  the	  making	  of	  ‘official’	  statistics,	  with	  <br/>what	  tools,	  methods	  and	  consequences?	  <br/>
These	  questions	  were	  addressed	  with	  regard	  to	  Big	  Data-­‐related	  projects	  and	  initiatives	  <br/>currently	  taking	  place	  within	  NSIs	  (e.g.,	  mobile	  phone	  data,	  social	  media	  sentiment	  analysis,	  <br/>Google	  trends,	  etc.).	  Participants	  included	  the	  Socialising	  Big	  Data	  project	  team	  and	  statisticians	  <br/>from	  England,	  Estonia,	  Ireland,	  Netherlands,	  Eurostat	  and	  the	  UNECE.	  The	  col&#160;aboratory	  was	  <br/>organised	  by	  Dr	  Evelyn	  Ruppert	  and	  held	  3	  -­‐	  4	  February	  2014	  at	  Centre	  for	  Creative	  <br/>Col&#160;aboration,	  London,	  UK.	  <br/>
Speakers	  included:	  <br/>
•&#160;&#160;<b>Barteld	  Braaksma</b>,	  Statistics	  Netherlands	  (CBS)	  <br/>•&#160;&#160;<b>John	  Dunne</b>,	  Central	  Statistical	  Office	  (CSO),	  Ireland	  <br/>•&#160;&#160;<b>Pete	  Brodie</b>,	  Office	  for	  National	  Statistics	  (ONS)	  <br/>•&#160;&#160;<b>Jorrit</b>	  <b>Zwijnenburg</b>,	  Statistics	  Netherlands	  (CBS)	  <br/>•&#160;&#160;Margus	  Tiru,	  Positium	  <br/>•&#160;&#160;<b>Kaja	  Sõstra</b>,	  Statistics	  Estonia	  (SE)	  <br/>•&#160;&#160;<b>Susan	  Williams</b>,	  Office	  for	  National	  Statistics	  (ONS)	  <br/>•&#160;&#160;Michail	  Skaliotis,	  Eurostat	  <br/>•&#160;&#160;<b>Steven	  Vale</b>,	  UN	  Economic	  Commission	  for	  Europe	  (UNECE)	  <br/>
	  <br/>
Some	  background	  readings	  on	  Big	  Data	  and	  Official	  Statistics	  were	  circulated	  in	  advance:	  <br/>
23	  <br/>
	  <br/>
<hr/>
<a name=24></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
•&#160;&#160;Karlberg,	  M.	  and	  M.	  Skaliotis	  (2013).	  Big	  Data	  for	  Official	  Statistics	  –	  Strategies	  and	  Some	  <br/>
Initial	  European	  Applications.	  <i>Conference	  of	  European	  Statisticians</i>.	  Geneva,	  Switzerland:	  1-­‐<br/>
10.	  <br/>
•&#160;&#160;United	  Nations	  Economic	  Commission	  for	  Europe	  (2013).	  Big	  Data,	  Big	  Impact?	  <i>Conference	  </i><br/>
<i>of	  European	  Statisticians</i>.	  Geneva,	  Switzerland:	  1-­‐9.	  <br/>
•&#160;&#160;United	  Nations	  Economic	  and	  Social	  Council	  (2013).	  Big	  Data	  and	  Modernisation	  of	  <br/>
Statistical	  Systems.	  <i>Report	  of	  the	  Secretary-­‐General</i>,	  United	  Nations:	  1-­‐29.	  <br/>
•&#160;&#160;United	  Nations	  Economic	  Commission	  (2013).	  What	  does	  “Big	  Data”	  mean	  for	  Official	  <br/>
Statistics?	  <i>Conference	  of	  European	  Statisticians</i>.	  St	  Petersburg,	  Russia:	  1-­‐9.	  <br/>
<b>Summary&#160;of&#160;Presentations&#160;</b><br/>
Barteld Braaksma: From research&#160;to preparation&#160;for implementation&#160;<br/>Barteld	  Braaksma	  discussed	  several	  Big	  Data	  initiatives	  taking	  place	  at	  Statistics	  Netherlands	  <br/>(CBS).	  Big	  Data	  sources	  (e.g.	  transaction	  data,	  scanner	  data,	  traffic	  sensors,	  satel&#160;ite	  photos,	  <br/>mobile	  phone	  data)	  provide	  new	  opportunities	  to	  measure	  mobility,	  economic	  and	  social	  <br/>activity.	  These	  methods	  tend	  to	  be	  timelier	  and	  more	  frequent	  than	  previous	  approaches,	  but	  <br/>have	  been	  applied	  with	  various	  rates	  of	  success.	  One	  of	  the	  major	  Big	  Data	  initiatives	  at	  CBS	  is	  <br/>using	  social	  media	  to	  monitor	  public	  sentiment.	  Digital	  methods	  (e.g.	  Sentiment	  Analysis)	  can	  <br/>be	  used	  to	  extract	  sentiment	  from	  social	  media	  messages	  and	  analysed	  according	  to	  statistical	  <br/>themes	  (e.g.	  economy,	  education,	  media).	  These	  results	  can	  then	  be	  used	  as	  sentiment	  <br/>indicators	  to	  reproduce	  and/or	  compare	  to	  survey	  measures	  of	  consumer	  confidence.	  <br/>
In	  order	  to	  produce	  high-­‐quality	  information,	  statistical	  processes	  must	  be	  governed	  by	  sound	  <br/>methodologies.	  Statistical	  outputs	  must	  be	  relevant,	  accurate,	  reliable,	  timely,	  accessible,	  <br/>coherent,	  comparable	  and	  consistent.	  In	  this	  regard,	  working	  with	  Big	  Data	  raises	  a	  series	  of	  <br/>familiar	  and	  non-­‐familiar	  methodological	  challenges	  from	  access	  to	  privacy,	  data	  analysis	  and	  <br/>management.	  From	  a	  methodological	  standpoint,	  Big	  Data	  poses	  a	  threat	  to	  traditional	  survey	  <br/>models	  of	  classification	  and	  implementation.	  It	  is	  difficult,	  for	  example,	  to	  compare	  Big	  Data	  to	  <br/>survey	  data	  because	  these	  approaches	  measure	  different	  things	  (behavior	  vs.	  responding,	  often	  <br/>dealing	  with	  devices	  not	  people).	  Big	  Data	  sources	  and	  analysis	  tools	  reconfigure	  what	  we	  <br/>measure	  and	  value.	  What	  counts,	  and	  how	  this	  should	  be	  classified,	  is	  increasingly	  a	  product	  of	  <br/>the	  data	  available	  for	  analysis.	  Classification	  systems	  must	  continue	  to	  be	  relevant	  to	  be	  <br/>implemented	  in	  the	  future	  or	  else	  they	  wil&#160;	  lose	  much	  of	  their	  value.	  So	  a	  key	  methodological	  <br/>priority	  is	  how	  to	  reconcile	  this	  new	  approach	  with	  statisticians’	  established	  desire	  for	  long	  time	  <br/>series	  and	  stable,	  coherent	  classifications	  systems.	  <br/>
Big	  Data	  means	  that	  statisticians	  no	  longer	  have	  a	  monopoly	  over	  data	  col&#160;ection	  and	  <br/>management.	  They	  must	  work	  with	  data	  suppliers,	  which	  raises	  confidentiality	  and	  privacy	  <br/>issues,	  and	  acquire	  new	  technical	  skil&#160;s,	  which	  is	  challenging	  in	  an	  environment	  undergoing	  <br/>severe	  budget	  cuts.	  Big	  Data	  is	  relatively	  quick	  to	  process	  and	  accessible	  at	  an	  unprecedented	  <br/>
24	  <br/>
	  <br/>
<hr/>
<a name=25></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
scale.	  The	  challenge	  is	  how	  to	  ‘cut	  through	  the	  noise’	  and	  overcome	  continuity	  issues	  by	  <br/>producing	  reliable	  and	  relevant	  information	  for	  future	  statistical	  analysis.	  In	  sum,	  despite	  the	  <br/>enthusiasm	  for	  Big	  Data	  research,	  there	  is	  reluctance	  among	  statisticians	  to	  implement	  Big	  Data	  <br/>into	  official	  statistics	  due	  to	  concerns	  about	  traditional	  quality	  measures.	  To	  solve	  these	  issues,	  <br/>statisticians	  wil&#160;	  need	  to	  establish	  new	  partnerships	  outside	  of	  statistics	  and	  work	  with	  data	  <br/>owners,	  researchers	  and	  different	  user	  groups.	  <br/>
John&#160;Dunne:&#160;Big&#160;Data&#160;coming&#160;soon…to&#160;an&#160;NSI&#160;near&#160;you&#160;<br/>John	  Dunne,	  from	  the	  Central	  Statistics	  Office	  (CSO),	  discussed	  some	  of	  the	  opportunities	  and	  <br/>challenges	  of	  working	  with	  Big	  Data	  sources.	  NSIs	  have	  a	  privileged	  place	  in	  legislation	  and	  are	  <br/>perfectly	  positioned	  to	  access	  and	  combine	  data	  sources	  for	  statistical	  purposes.	  Despite	  this	  <br/>power,	  working	  with	  Big	  Data	  raises	  a	  series	  of	  challenges	  that	  correspond	  to	  those	  associated	  <br/>with	  administrative	  data	  sources	  (e.g.	  data	  harvesting,	  linkage,	  classification,	  representation,	  <br/>privacy).	  Connecting	  data	  sources	  has	  proved	  particularly	  problematic.	  The	  CSO	  have	  responded	  <br/>to	  this	  issue	  by	  establishing	  a	  National	  Data	  Infrastructure	  (NDI).	  The	  primary	  differences	  <br/>between	  Big	  Data	  and	  administrative	  data	  relates	  to	  scale	  and	  ownership	  (owners	  typically	  <br/>require	  a	  licence	  to	  operate,	  legal	  constraints	  on	  data	  linkage).	  Large	  data	  sets	  are	  not	  <br/>necessarily	  more	  reliable.	  <br/>
Traditionally,	  statistics	  have	  been	  defined	  by	  the	  questions	  statisticians	  ask	  (e.g.	  survey	  model).	  <br/>Big	  Data,	  conversely,	  is	  configured	  more	  by	  the	  methods	  available	  than	  preconceived	  questions	  <br/>or	  systems	  of	  classification.	  Increasingly,	  it	  is	  the	  data	  that	  drives	  the	  questions	  rather	  than	  the	  <br/>other	  way	  around.	  This	  represents	  a	  significant	  change	  from	  existing	  statistical	  practices.	  <br/>Instead	  of	  trying	  to	  impose	  classification	  models	  onto	  Big	  Data	  sources,	  statisticians	  should	  <br/>focus	  on	  clustering	  and	  distinguishing	  patterns	  from	  these	  new	  data	  sources	  in	  meaningful	  <br/>ways.	  Big	  Data	  sources	  (e.g.	  call	  detail	  records,	  mobile	  positioning	  data,	  transaction	  data,	  <br/>electricity	  consumption	  data)	  mean	  that	  statisticians	  are	  able	  to	  ask	  new	  questions	  of	  data	  that	  <br/>were	  previously	  considered	  impossible.	  Electricity	  Smart	  Meter	  Data,	  for	  example,	  could	  be	  <br/>used	  to	  estimate	  household	  composition	  based	  on	  electricity	  consumption	  patterns.	  One	  of	  the	  <br/>benefits	  of	  this	  new	  approach	  is	  that	  Big	  Data	  tends	  to	  be	  livelier	  and	  cost	  efficient	  than	  <br/>traditional	  statistical	  methods.	  The	  fact	  that	  Big	  Data	  sources	  are	  often	  transnational	  in	  scope	  <br/>also	  presents	  new	  opportunities	  for	  col&#160;aboration.	  <br/>
Given	  the	  sensitive	  nature	  of	  Big	  Data,	  and	  the	  (passive)	  means	  by	  which	  much	  data	  is	  col&#160;ected,	  <br/>NSIs	  must	  demonstrate	  responsible	  statistical	  leadership	  when	  working	  with	  these	  data	  sources	  <br/>by	  establishing	  common	  data	  protection	  principles	  and	  practices	  –	  ‘just	  because	  you	  can,	  <br/>doesn’t	  mean	  you	  should’	  use	  data	  sources.	  Processing	  Big	  Data	  also	  requires	  new	  statistical	  <br/>and	  technical	  capabilities,	  as	  opposed	  to	  management	  skil&#160;s.	  It	  is	  difficult	  to	  justify	  building	  new	  <br/>technical	  infrastructures	  when	  the	  value	  of	  these	  data	  sources	  is	  yet	  to	  be	  specified.	  <br/>
25	  <br/>
	  <br/>
<hr/>
<a name=26></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
Outsourcing	  and	  downsampling	  may	  assist	  in	  overcoming	  these	  technical	  challenges,	  but	  <br/>working	  with	  third	  parties	  raises	  significant	  privacy	  and	  confidentiality	  concerns,	  both	  perceived	  <br/>and	  actual	  (addressing	  these	  concerns	  represents	  a	  further	  challenge).	  <br/>
Big	  Data	  is	  changing	  the	  role	  of	  national	  statistics	  as	  information	  is	  being	  col&#160;ected	  and	  <br/>processed	  at	  an	  unprecedented	  speed	  and	  scale.	  The	  future	  of	  NSIs	  is	  not	  threatened,	  but	  <br/>statistical	  organisations	  wil&#160;	  need	  to	  evolve	  and	  adapt	  by	  developing	  the	  necessary	  capabilities	  <br/>to	  work	  with	  Big	  Data	  sources.	  Each	  data	  source	  (e.g.	  Big	  Data,	  administrative	  data	  and	  open	  <br/>data)	  has	  its	  own	  characteristics	  and	  inherent	  value.	  Rather	  than	  focusing	  on	  definitions,	  <br/>statisticians	  should	  seek	  to	  combine	  this	  data	  to	  enhance	  their	  value	  and	  eliminate	  unnecessary	  <br/>burden	  on	  respondents.	  One	  way	  to	  achieve	  this	  is	  by	  making	  use	  of	  existing	  data	  flows.	  <br/>Statistical	  agencies	  must	  continue	  to	  align	  their	  practices	  with	  the	  UN	  Fundamental	  Principles	  of	  <br/>Statistics	  (particularly,	  Principle	  5:	  choose	  data	  sources	  with	  regard	  to	  quality,	  timeliness,	  costs	  <br/>and	  the	  burden	  on	  respondents)	  and	  demonstrate	  responsible	  statistical	  leadership.	  <br/>
Pete&#160;Brodie:&#160;ONS&#160;data&#160;strategy&#160;–&#160;How&#160;administrative&#160;data&#160;and&#160;Big&#160;Data&#160;fit&#160;together&#160;<br/>Pete	  Brodie,	  from	  the	  Office	  for	  National	  Statistics	  (ONS),	  discussed	  the	  parallels	  between	  <br/>working	  with	  Big	  Data	  and	  administrative	  data,	  both	  of	  which	  form	  a	  crucial	  part	  of	  the	  ONS’s	  <br/>data	  strategy	  (e.g.	  Vision	  of	  2020).	  There	  is	  much	  uncertainty	  around	  what	  constitutes	  Big	  Data.	  <br/>The	  difference	  between	  Big	  Data	  and	  administrative	  data	  is	  arguably	  a	  matter	  of	  volume.	  The	  <br/>practices	  of	  working	  with	  large	  data	  sets	  involve	  issues	  of	  data	  linkage,	  data	  mining,	  <br/>repurposing,	  and	  warehousing.	  The	  kinds	  of	  issues	  that	  arise	  when	  linking	  administrative	  data	  <br/>for	  statistical	  purposes	  correspond	  to	  those	  associated	  with	  linking	  Big	  Data	  sources	  (e.g.	  reuse,	  <br/>repurposing,	  representativeness,	  cleaning,	  classification,	  comparability,	  continuity,	  <br/>confidentiality	  and	  privacy).	  <br/>
The	  increasing	  use	  of	  administrative	  data	  sources	  for	  statistical	  purposes	  introduces	  challenges	  <br/>around	  quality	  measures.	  Assessing	  the	  quality	  of	  data	  sources	  is	  crucial	  to	  statistical	  analysis	  <br/>given	  that	  the	  objective	  of	  NSIs	  is	  to	  produce	  statistics	  to	  inform	  good	  government	  and	  <br/>evidence	  based	  decisions.	  In	  contrast	  to	  survey	  col&#160;ected	  data,	  administrative	  data	  tends	  to	  <br/>provide	  better	  coverage	  (i.e.	  it	  is	  more	  like	  a	  census	  rather	  than	  a	  survey),	  but	  is	  generally	  less	  <br/>timely	  (e.g.	  small	  businesses	  may	  only	  provide	  VAT	  records	  annually)	  and	  produces	  poorer	  <br/>metadata.	  Big	  Data	  should	  be	  more	  timely,	  accessible,	  and	  cost	  effective	  than	  traditional	  <br/>methods.	  At	  the	  same	  time,	  Big	  Data	  is	  more	  prone	  to	  change	  than	  administrative	  data	  (e.g.	  wil&#160;	  <br/>Twitter	  stil&#160;	  be	  popular	  in	  10	  years?),	  and	  its	  methods	  and	  metadata	  are	  less	  transparent.	  <br/>Census	  data,	  by	  contrast,	  is	  relatively	  small	  in	  volume.	  The	  volume	  of	  Big	  Data	  sets	  could	  <br/>potentially	  pose	  major	  storage	  issues	  (data	  warehousing	  could	  possibly	  solve	  this	  problem).	  Big	  <br/>Data	  sources	  are	  not	  governed	  by	  the	  same	  quality	  measures	  as	  surveys.	  Quality	  needs	  to	  be	  <br/>measured	  in	  a	  different	  way.	  Those	  working	  with	  Big	  Data	  need	  to	  focus	  on	  model&#160;ing	  errors	  <br/>
26	  <br/>
	  <br/>
<hr/>
<a name=27></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
rather	  than	  standard	  errors,	  as	  is	  typically	  the	  case	  with	  surveys.	  The	  ONS	  has	  addressed	  these	  <br/>issues	  by	  producing	  23	  basic	  quality	  indicators	  for	  statistics	  involving	  administrative	  data.	  These	  <br/>indicators	  can	  also	  be	  applied	  to	  Big	  Data	  sources.	  <br/>
The	  key	  challenges	  for	  Big	  Data	  centre	  around	  issues	  of	  data	  quality,	  comparability	  and	  storage.	  <br/>Using	  social	  media	  wil&#160;	  produce	  statistics	  based	  on	  social	  behaviour	  rather	  than	  economic	  data.	  <br/>Rather	  than	  seeking	  to	  reproduce	  survey	  quality	  measures	  or	  outputs,	  quality	  should	  be	  <br/>assessed	  according	  to	  whether	  Big	  Data	  is	  useful	  for	  decision-­‐making	  purposes	  and	  policy	  <br/>evaluation	  given	  that	  this	  is	  the	  purpose	  of	  official	  statistics.	  Big	  Data	  could	  be	  used	  for	  auxiliary	  <br/>purposes	  to	  provide	  quality	  checks	  on	  survey	  data.	  Methods	  could	  be	  used	  to	  improve	  and	  <br/>complement	  rather	  than	  replace	  each	  other	  (e.g.	  a	  Bayesian	  dual	  frame	  approach).	  This	  is	  <br/>particularly	  important	  when	  working	  with	  Big	  Data	  sources	  given	  that	  users’	  habits	  can	  change	  <br/>(e.g.	  location	  information	  on	  mobile	  phones,	  preventing	  access	  etc.).	  Big	  Data	  also	  raises	  <br/>questions	  around	  privacy.	  Among	  NSIs	  legislative	  differences	  exist.	  In	  contrast	  to	  Ireland,	  legal	  <br/>access	  is	  currently	  a	  major	  issue	  in	  the	  UK.	  The	  ONS	  have	  established	  an	  Innovation	  Lab	  to	  test	  <br/>new	  methods	  on	  Big	  Data	  in	  secure	  and	  original	  ways.	  Data	  warehousing	  wil&#160;	  be	  a	  key	  priority	  in	  <br/>the	  future	  given	  that	  much	  internal	  data	  at	  the	  ONS	  is	  ‘siloed’	  (processed	  and	  stored	  in	  different	  <br/>systems).	  In	  light	  of	  these	  challenges,	  the	  ONS	  is	  focusing	  on	  three	  areas	  of	  development:	  data	  <br/>integration	  and	  aggregation,	  data	  col&#160;ection	  (i.e.	  seek	  to	  reduce	  burden	  on	  respondents,	  <br/>administrative	  data	  to	  replace	  survey	  data	  where	  possible,	  moves	  toward	  electronic	  data	  <br/>col&#160;ection	  as	  the	  norm),	  and	  data	  storage.	  <br/>
Jorrit&#160;Zwijnenburg:&#160;The&#160;use&#160;of&#160;Big&#160;Data&#160;in&#160;Statistics&#160;on&#160;Employment&#160;and&#160;Wages&#160;<br/>Jorrit	  Zwijnenburg,	  from	  Statistics	  Netherlands	  (CBS),	  discussed	  the	  use	  of	  administrative	  data	  <br/>statistics	  on	  employment	  and	  wages	  (in	  this	  presentation,	  the	  terms	  administrative	  data	  and	  Big	  <br/>Data	  were	  used	  interchangeably).	  CBS	  compile	  statistical	  outputs	  on	  employment,	  wages	  and	  <br/>hours.	  These	  are	  published	  on	  a	  quarterly	  and	  annual	  basis.	  These	  outputs	  have	  different	  <br/>quality	  measures.	  Quarterly	  outputs	  measure	  employment	  and	  wages	  (e.g.	  used	  to	  calculate	  <br/>GDP).	  The	  emphasis	  is	  on	  timeliness,	  as	  compared	  to	  annual	  outputs,	  which	  provide	  much	  more	  <br/>detailed	  levels	  and	  structures	  of	  employment,	  wages	  and	  hours	  and	  measure	  more	  variables	  <br/>(e.g.	  regions,	  gender	  etc.).	  Annual	  outputs	  include	  huge	  mirco	  datasets	  at	  job	  levels.	  This	  <br/>information	  is	  used	  by	  researchers	  to	  link	  employment	  figures	  to	  information	  on	  education	  and	  <br/>health.	  Big	  Data	  provides	  the	  opportunity	  to	  measure	  monthly	  outputs.	  There	  are	  multiple	  uses	  <br/>of	  this	  data	  from	  tax	  authorities	  to	  insurance	  agencies,	  pension	  funds,	  and	  security	  schemes.	  <br/>
Administrative	  data	  is	  col&#160;ected	  from	  several	  different	  sources	  (e.g.	  Tax	  Authorities	  and	  the	  <br/>Employee	  Insurance	  Agency).	  Processing	  this	  data	  can	  be	  challenging	  because	  it	  involves	  data	  <br/>linkage	  (e.g.	  to	  the	  Business	  Register),	  imputation,	  editing	  and	  analysis	  before	  the	  results	  can	  be	  <br/>disseminated.	  Special	  attention	  is	  needed	  for	  completeness,	  relevance,	  imputation	  methods	  for	  <br/>
27	  <br/>
	  <br/>
<hr/>
<a name=28></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
missing	  data,	  seasonal	  patterns,	  and	  distinguishing	  real	  from	  artificial	  changes.	  Despite	  <br/>changing	  the	  input	  source	  from	  survey	  to	  administrative	  data,	  the	  processing	  tools	  that	  CBS	  use	  <br/>for	  analysis	  have	  remained	  the	  same.	  More	  efficient	  tools	  are	  currently	  being	  developed	  to	  deal	  <br/>with	  Big	  Data	  sources.	  <br/>
When	  compared	  to	  previous	  methods,	  Big	  Data	  introduces	  a	  series	  of	  benefits	  from	  better	  <br/>coverage,	  higher	  frequency	  (data	  received	  weekly),	  improved	  timeliness	  and	  efficiency	  gains.	  At	  <br/>the	  same	  time,	  working	  with	  Big	  Data	  generates	  practical	  and	  methodological	  challenges	  from	  <br/>missing	  variables	  to	  comparability	  issues.	  Statisticians	  must	  also	  develop	  new	  technical	  <br/>infrastructures	  and	  capabilities	  to	  process	  this	  data.	  In	  light	  of	  these	  challenges,	  there	  is	  <br/>hesitation	  among	  statisticians	  to	  shift	  to	  Big	  Data.	  <br/>
While	  Big	  Data	  may	  assist	  statistical	  processes	  and	  improve	  timeliness,	  its	  quality	  and	  use	  <br/>differs	  from	  traditional	  approaches	  and	  further	  experimentation	  is	  required	  before	  being	  <br/>adopted	  by	  statisticians.	  Incomplete	  data	  sets	  and	  associated	  issues	  of	  quality,	  comparability	  <br/>and	  availability	  (e.g.	  open	  data)	  raise	  questions	  about	  what	  should	  count	  as	  an	  official	  statistic	  <br/>(e.g.	  “raw”	  data?)	  and	  highlights	  the	  need	  for	  NSIs	  to	  reassess	  their	  role	  as	  statistical	  agencies.	  <br/>How	  NSIs	  use	  data	  sources	  must	  be	  considered	  in	  relation	  to	  user	  needs	  (i.e.	  different	  users	  wil&#160;	  <br/>have	  different	  priorities	  and	  quality	  measures),	  given	  that	  the	  role	  of	  these	  organisations	  is	  to	  <br/>provide	  statistics	  for	  society	  and	  decision-­‐making	  purposes.	  <br/>
Margus&#160;Tiru:&#160;Feasibility&#160;study&#160;on&#160;the&#160;Mobile&#160;Positioning&#160;Data&#160;for&#160;Tourism&#160;Statistics&#160;<br/>Margus	  Tiru	  explored	  the	  possibilities	  of	  using	  mobile	  positioning	  data	  (MPD)	  –	  information	  <br/>about	  the	  positioning	  of	  mobile	  phones	  stored	  by	  mobile	  network	  providers	  (i.e.	  mostly	  call	  <br/>data	  records,	  data	  downloads	  and	  location	  updates)	  –	  to	  measure	  tourism	  flows	  and	  movement	  <br/>patterns.	  MPD	  is	  different	  from	  existing	  data	  sources	  in	  that	  it	  requires	  new	  technologies	  and	  <br/>methods.	  Despite	  raising	  privacy	  concerns,	  this	  data	  is	  highly	  valuable	  to	  statisticians,	  <br/>researchers,	  state	  and	  commercial	  organisations,	  such	  as	  the	  tourism	  industry,	  because	  in	  <br/>tracking	  their	  digital	  geographical	  footprints	  it	  reveals	  the	  behaviour	  of	  individuals	  (e.g.	  what	  <br/>destination	  someone	  has	  visited	  and	  for	  what	  duration)	  and	  can	  therefore	  be	  used	  for	  risk	  <br/>assessment,	  investment	  and	  marketing	  purposes.	  In	  terms	  of	  volume,	  mobile	  positioning	  data	  is	  <br/>relatively	  small	  but	  it	  requires	  significant	  analysis	  and	  computational	  power.	  It	  is	  processing,	  <br/>rather	  than	  storing	  this	  data,	  that	  makes	  it	  challenging	  to	  work	  with.	  <br/>
While	  MPD	  covers	  tourism	  data	  wel&#160;	  (e.g.	  inbound/outbound	  trips,	  duration,	  destination),	  <br/>important	  indicators	  are	  missing	  (e.g.	  accommodation,	  mode	  of	  transportation,	  purpose	  of	  the	  <br/>trip,	  expenditure,	  socio-­‐demographic	  breakdown).	  Assumptions	  can	  be	  made,	  but	  there	  are	  <br/>problems	  with	  deducing	  correlations	  (e.g.	  commuters	  working	  weekends,	  children	  using	  <br/>parents’	  phone).	  It	  would	  be	  beneficial	  to	  measure	  transaction	  data,	  but	  data	  of	  this	  kind	  is	  <br/>highly	  sensitive.	  <br/>
28	  <br/>
	  <br/>
<hr/>
<a name=29></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
MPD	  provides	  many	  benefits	  for	  NSIs	  from	  new	  indicators	  to	  improved	  timeliness	  and	  better	  <br/>coverage,	  but	  large	  quantitative	  samples	  also	  introduce	  methodological	  challenges	  from	  data	  <br/>processing	  to	  data	  linkage/harmonising,	  coverage	  issues,	  comparability,	  data	  ownership	  and	  <br/>management.	  These	  methods,	  moreover,	  are	  not	  always	  reliable	  or	  cost	  efficient.	  Working	  with	  <br/>MPD	  also	  raises	  ethical	  issues	  associated	  with	  legislation	  and	  privacy,	  even	  if	  the	  data	  is	  used	  <br/>with	  ‘good’	  intentions.	  These	  issues	  highlight	  the	  need	  to	  establish	  a	  legal	  framework	  for	  official	  <br/>statistics	  to	  obtain	  data	  in	  legal,	  cost-­‐efficient	  ways.	  <br/>
Susan&#160;Williams:&#160;Internet&#160;Search&#160;queries&#160;within&#160;migration&#160;statistics&#160;<br/>Susan	  Wil&#160;iams,	  from	  the	  Office	  for	  National	  Statistics	  (ONS),	  discussed	  the	  potential	  of	  Big	  Data	  <br/>to	  inform	  statistical	  processes	  in	  general	  and	  to	  measure	  population	  statistics	  in	  particular.	  In	  <br/>one	  ONS	  Big	  Data	  project,	  Internet	  search	  queries	  were	  used	  to	  measure	  migration	  to	  the	  UK	  <br/>using	  Google	  Trends:	  a	  public	  web	  tool	  that	  gives	  a	  search	  volume	  index	  (SVI)	  showing	  how	  <br/>often	  a	  particular	  search-­‐term	  is	  entered	  on	  Google	  search	  relative	  to	  the	  total	  Google	  search	  <br/>volume	  in	  various	  time	  periods	  and	  regions.	  The	  results	  were	  promising	  with	  Google	  search	  <br/>queries	  containing	  the	  term	  ‘polski’,	  for	  example,	  corresponding	  to	  official	  statistics	  from	  <br/>Labour	  Force	  (LF)	  survey	  estimates	  of	  Polish	  nationality.	  <br/>
While	  preliminary	  studies	  suggest	  that	  these	  data	  could	  provide	  insight	  into	  emerging	  events	  <br/>(e.g.	  population	  densities	  and	  flows,	  flu	  outbreaks),	  in	  contrast	  to	  survey	  models,	  Internet	  <br/>search	  queries	  provide	  very	  little	  information	  about	  their	  users	  (e.g.	  age,	  sex,	  nationality),	  <br/>which	  limits	  statistical	  analysis.	  Instead,	  the	  platform	  configures	  what	  type	  of	  data	  can	  be	  <br/>measured	  and	  is	  made	  available	  for	  analysis.	  Although	  the	  device	  provided	  relatively	  accurate	  <br/>results	  regarding	  larger	  EU8	  populations	  new	  to	  UK	  (i.e.	  predominately	  young	  adults,	  who	  <br/>speak	  foreign	  languages	  and	  use	  the	  Internet),	  it	  was	  not	  as	  effective	  for	  measuring	  other	  <br/>populations	  (e.g.	  some	  time	  series	  and	  populations	  were	  too	  small	  to	  track).	  <br/>
Moreover,	  despite	  being	  timely,	  accessible	  and	  free,	  working	  with	  the	  device	  raises	  a	  series	  of	  <br/>methodological	  challenges	  from	  understanding	  how	  data	  is	  produced	  to	  discontinuity	  issues	  <br/>(e.g.	  changing	  APIs),	  which	  raise	  significant	  questions	  around	  reliability,	  consistency	  and	  <br/>representation.	  Despite	  obtaining	  good	  results	  when	  matched	  against	  LF	  statistics,	  within	  the	  <br/>ONS	  there	  is	  only	  the	  appetite	  to	  use	  the	  device	  for	  quality	  assuring	  official	  statistics.	  <br/>
Working	  with	  commercial	  providers	  to	  access	  sensitive	  information	  raises	  further	  concerns	  over	  <br/>privacy	  and	  legislation,	  confidentiality,	  monetisation	  and	  access.	  Those	  working	  with	  these	  data	  <br/>sources	  must	  also	  be	  aware	  that	  users	  could	  modify	  their	  behaviour	  to	  avoid	  detection	  (e.g.	  opt	  <br/>out,	  rejecting	  cookies,	  usage	  of	  Google	  search),	  which	  would	  impact	  the	  future	  success	  of	  these	  <br/>methods.	  <br/>
29	  <br/>
	  <br/>
<hr/>
<a name=30></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
Internet	  search	  tools	  may	  be	  able	  to	  improve	  and	  inform	  statistical	  processes	  by	  providing	  <br/>quality	  assurance	  around	  existing	  statistics	  and	  indicators	  about	  population	  statistics	  (e.g.	  <br/>identifying	  tourists	  and	  migrant	  populations	  before	  they	  enter	  the	  UK).	  While	  the	  potential	  <br/>impact	  of	  Big	  Data	  for	  national	  statistics	  is	  promising,	  at	  present	  it	  is	  hindered	  by	  the	  lack	  of	  <br/>available	  methodology,	  quality	  measures	  and	  access	  to	  underlying	  data.	  To	  move	  forward,	  <br/>statisticians	  need	  to	  col&#160;aborate	  with	  commercial	  providers	  to	  achieve	  better	  access	  and	  learn	  <br/>more	  about	  their	  methods	  (e.g.	  Google).	  <br/>
Kaja&#160;Sõstra:&#160;Big&#160;Data&#160;in&#160;Statistics Estonia&#160;<br/>Kaja	  Sõstra,	  from	  Statistics	  Estonia	  (SE),	  discussed	  some	  of	  the	  issues	  that	  arise	  when	  working	  <br/>with	  Big	  Data	  in	  relation	  to	  initiatives	  currently	  taking	  place	  within	  SE.	  Big	  Data	  forms	  an	  <br/>important	  part	  of	  SE’s	  data	  strategy	  (2013-­‐7).	  Existing	  data	  sources	  are	  mostly	  based	  on	  <br/>surveys.	  They	  tend	  to	  be	  extremely	  burdensome,	  costly	  and	  have	  a	  low	  response	  rate.	  Data	  <br/>col&#160;ection	  in	  contemporary	  statistics,	  by	  contrast,	  is	  mainly	  electronic.	  One	  of	  the	  benefits	  of	  <br/>working	  with	  new	  data	  sources	  is	  that	  they	  can	  be	  used	  to	  produce	  relevant	  and	  timely	  results	  <br/>that	  accord	  with	  SE’s	  objectives.	  By	  using	  resources	  effectively,	  Big	  Data	  technologies	  can	  also	  <br/>result	  in	  efficiency	  gains	  (e.g.	  data	  linkage,	  rapid	  col&#160;ection,	  avoiding	  supplementary	  input	  <br/>work).	  In	  this	  regard,	  Big	  Data	  has	  the	  potential	  to	  solve	  some	  of	  the	  problems	  associated	  with	  <br/>producing	  official	  statistics.	  However,	  in	  order	  to	  process	  Big	  Data,	  statisticians	  require	  new	  <br/>technical	  skil&#160;s	  and	  resources	  which	  is	  challenging	  in	  a	  context	  undergoing	  severe	  budget	  cuts	  <br/>and	  governed	  by	  compulsory	  EU	  regulations	  around	  output	  (e.g.	  regulations	  around	  microdata	  <br/>can	  cause	  problems	  when	  working	  with	  administrative	  data)	  and	  quality	  measures.	  SE	  have	  <br/>responded	  to	  these	  issues	  by	  developing	  and	  implementing	  innovative	  methods	  to	  process	  this	  <br/>data.	  <br/>
Big	  Data	  could	  be	  used	  to	  solve	  some	  of	  the	  problems	  associated	  with	  producing	  official	  <br/>statistics.	  These	  issues	  were	  canvassed	  in	  relation	  to	  several	  case	  studies.	  <br/>
•&#160;&#160;In	  2013,	  SE	  completed	  the	  first	  phase	  of	  developing	  a	  methodology	  for	  a	  register-­‐based	  <br/>
Population	  and	  Housing	  Census.	  Data	  was	  col&#160;ected	  mostly	  from	  administrative	  registers.	  <br/>
There	  were	  several	  problems	  with	  this	  approach,	  a	  major	  issue	  being	  that	  respondents’	  <br/>
registered	  place	  of	  residence	  was	  inconsistent	  with	  their	  real	  place	  of	  residence	  for	  about	  <br/>
twenty	  per	  cent	  of	  the	  Estonian	  population.	  Big	  Data	  sources,	  such	  as	  mobile	  positioning	  <br/>
data,	  could	  potentially	  be	  used	  to	  complement	  these	  methods	  by	  estimating	  the	  Estonian	  <br/>
population	  during	  the	  census.	  <br/>
•&#160;&#160;Working	  with	  secondary	  data	  sources	  also	  raises	  methodological	  issues	  around	  <br/>
classification.	  When	  developing	  methods	  to	  measure	  Energy	  Statistics	  in	  the	  household	  <br/>
sector,	  for	  example,	  statistics	  need	  to	  conform	  to	  certain	  categories	  (e.g.	  cooking,	  lighting,	  <br/>
space	  and	  water	  heating).	  Smart	  meter	  data	  could	  possibly	  solve	  this	  issue	  by	  model&#160;ing	  <br/>
electricity	  end	  use.	  <br/>
30	  <br/>
	  <br/>
<hr/>
<a name=31></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
•&#160;&#160;The	  surveys	  that	  produce	  statistics	  on	  wages	  and	  salaries	  raise	  similar	  practical	  issues.	  Data	  <br/>
col&#160;ection	  tends	  to	  be	  burdensome	  and	  survey	  methods	  can	  produce	  inconsistent	  results	  <br/>
(i.e.	  employers	  report	  similar	  data	  to	  different	  authorities,	  missing	  variables,	  different	  <br/>
reporting	  times).	  One	  way	  to	  resolve	  these	  issues	  could	  be	  to	  combine	  tax	  and	  statistical	  <br/>
data	  used	  for	  producing	  labour	  cost	  index	  statistics.	  <br/>
•&#160;&#160;In	  a	  similar	  way,	  transaction	  data	  could	  be	  used	  to	  reduce	  burden	  on	  respondents,	  improve	  <br/>
response	  rates	  and	  quality	  measures,	  potentially	  replacing	  the	  Household	  Budget	  Survey	  <br/>
(HBS),	  in	  part	  or	  altogether.	  <br/>
In	  conclusion,	  Big	  Data	  sources	  could	  be	  used	  to	  complement	  existing	  statistics	  by	  providing	  <br/>more	  cost	  efficient,	  detailed	  statistics	  and	  better	  timeliness.	  In	  order	  to	  implement	  these	  <br/>changes,	  however,	  extra-­‐resources	  are	  required	  to	  develop	  robust	  methodologies	  (practices	  <br/>and	  software).	  The	  key	  challenge	  for	  NSIs	  is	  how	  to	  work	  with	  Big	  Data	  sources	  in	  a	  way	  that	  is	  <br/>cost-­‐effective,	  consistent	  with	  statistical	  principles	  (impartiality,	  reliability,	  relevancy,	  <br/>profitability,	  confidentiality,	  transparency),	  and	  complies	  with	  intl.	  methods	  and	  regulations.	  <br/>
Michail&#160;Skaliotis:&#160;Closing&#160;Observations&#160;<br/>Michail	  Skaliotis,	  from	  Eurostat,	  provided	  some	  closing	  observations	  on	  the	  col&#160;aboratory.	  The	  <br/>shift	  toward	  Big	  Data	  is	  stil&#160;	  in	  the	  early	  stages	  of	  development	  and	  must	  be	  seen	  as	  an	  <br/>evolution	  in	  order	  to	  assess	  the	  current	  position	  of	  NSIs.	  Implementing	  Big	  Data	  raises	  <br/>significant	  methodological	  and	  economic	  challenges	  (budget	  and	  resource	  constraints),	  <br/>especially	  in	  a	  conservative	  environment	  where	  there	  is	  ambivalence	  about	  its	  value	  and	  <br/>outcomes.	  How	  best	  to	  train	  data	  scientists	  is	  an	  issue	  that	  needs	  to	  be	  considered.	  Despite	  <br/>these	  concerns,	  there	  is	  some	  momentum.	  Constraints	  can	  be	  overcome	  through	  building	  new	  <br/>partnerships	  and	  international	  col&#160;aborations	  with	  various	  experts	  and	  stakeholders	  (e.g.	  <br/>discussions	  about	  creating	  a	  European	  Big	  Data	  Analytic	  Service).	  Col&#160;aborations	  of	  this	  kind	  wil&#160;	  <br/>enable	  statisticians	  to	  learn	  from	  the	  experience	  of	  others	  and	  reduce	  investment	  costs.	  &#160;	  <br/>
Small	  statistical	  offices	  cannot	  compete	  with	  large	  third	  party	  data	  sources.	  Internet	  companies	  <br/>produce	  different	  daily	  and	  hourly	  estimates	  addressing	  similar	  socio-­‐economic	  phenomena	  as	  <br/>statistical	  agencies.	  Perhaps	  the	  future	  of	  official	  statistics	  is	  to	  play	  another	  role:	  providing	  <br/>accreditation	  or	  certification	  as	  a	  statistical	  authority	  on	  what	  measures	  to	  use	  (e.g.	  what	  is	  the	  <br/>best	  inflation	  estimate).	  In	  sum,	  reflecting	  on	  the	  tremendous	  changes	  that	  have	  occurred	  in	  <br/>the	  last	  four	  years	  (2010-­‐2014),	  there	  is	  reason	  to	  be	  very	  optimistic	  about	  the	  future	  of	  <br/>national	  statistics.	  <br/>
Steven&#160;Vale:&#160;Closing&#160;Observations&#160;<br/>Steven	  Vale,	  from	  the	  UN	  Economic	  Commission	  for	  Europe	  (UNECE),	  provided	  some	  closing	  <br/>observations	  on	  the	  col&#160;aboratory.	  <br/>
31	  <br/>
	  <br/>
<hr/>
<a name=32></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
•&#160;&#160;He	  began	  by	  questioning	  the	  value	  of	  the	  term	  ‘Big	  Data’	  suggesting	  that	  ‘big’	  was	  not	  the	  <br/>
key	  characteristic	  of	  the	  data	  sources	  they	  seek	  to	  describe.	  He	  proposed	  using	  the	  term	  <br/>
‘new	  data’	  instead,	  but	  conceded	  that	  it	  raised	  similar	  problems	  of	  relativity	  (i.e.	  what’s	  <br/>
big/new	  now	  wil&#160;	  appear	  small/old	  in	  the	  future).	  <br/>
•&#160;&#160;The	  term	  ‘Secondary	  Data	  Sources’	  (data	  not	  col&#160;ected	  first	  hand	  by	  statistical	  organisations)	  <br/>
was	  proposed	  to	  describe	  these	  new	  data	  sources	  given	  that	  almost	  all	  the	  strategic	  and	  <br/>technical	  issues	  associated	  with	  Big	  Data	  apply	  to	  administrative	  data.	  Thus,	  the	  utility	  of	  <br/>
making	  distinctions	  between	  Big	  Data	  and	  administrative	  data	  sources	  was	  questioned.	  <br/>
•&#160;&#160;Big	  Data	  raises	  significant	  privacy	  concerns.	  Much	  research	  is	  focused	  on	  how	  to	  manage	  <br/>
these	  issues,	  both	  perceived	  (e.g.	  exacerbated	  by	  the	  NSA	  scandal/Snowden	  revelations)	  <br/>
and	  actual.	  In	  reality	  most	  statistical	  offices	  neither	  have	  the	  resources,	  nor	  the	  interest	  to	  <br/>
trace	  specific	  people.	  Instead,	  they	  are	  interested	  in	  discovering	  trends	  and	  aggregates.	  This	  <br/>
needs	  to	  be	  communicated	  to	  the	  public.	  <br/>
•&#160;&#160;Big	  Data	  raises	  methodological	  challenges<b>	  </b>regarding	  classification,	  definitions	  and	  <br/>
comparability.	  What	  is	  being	  measured	  is	  not	  commensurate	  with	  existing	  methods;	  data	  is	  <br/>
increasingly	  driven	  by	  the	  technologies	  available.	  Perhaps	  it	  is	  a	  mistake	  to	  impose	  <br/>
preconceived	  measurements	  and	  modes	  of	  classification	  onto	  Big	  Data	  sources.	  The	  <br/>
alternative	  is	  to	  identify	  what’s	  new	  about	  this	  data	  and	  to	  discover	  what	  they	  allow	  to	  be	  <br/>
measured	  (given	  that	  Big	  Data	  often	  involves	  large	  data	  sets,	  traditional	  sampling	  <br/>
techniques	  could	  be	  used	  to	  acquire	  more	  meaningful	  subsets	  to	  work	  with).	  <br/>
•&#160;&#160;NSIs	  are	  not	  wel&#160;	  equipped	  to	  conduct	  the	  primary	  processing	  and	  aggregation	  of	  Big	  Data,	  <br/>
so	  outsourcing	  and	  partnerships	  with	  data	  suppliers	  requires	  further	  discussion.	  But	  this	  <br/>
calls	  into	  question	  the	  future	  value	  of	  official	  statistics.	  One	  of	  the	  advantages	  of	  statistical	  <br/>
organisations	  is	  their	  capacity	  to	  work	  with	  a	  broad	  range	  of	  data	  sources	  and	  statistical	  <br/>
outputs.	  This	  places	  NSIs	  in	  a	  privileged	  position	  to	  provide	  validations,	  aggregations	  and	  to	  <br/>
combine	  information	  from	  different	  data	  sources.	  In	  the	  future,	  Big	  Data	  wil&#160;	  require	  a	  <br/>
paradigm	  shift	  where	  analysis,	  rather	  than	  col&#160;ection	  (or	  first-­‐stage	  processing	  of	  micro	  <br/>
data),	  is	  the	  primary	  mode	  of	  activity.	  <br/>
•&#160;&#160;If	  these	  changes	  are	  to	  be	  implemented,	  statisticians	  wil&#160;	  have	  to	  convince	  users	  and	  <br/>
suppliers	  of	  the	  value	  of	  these	  data	  sources.	  <br/>
•&#160;&#160;Managing	  discontinuity	  and	  change	  is	  a	  recurring	  concern	  expressed	  by	  statisticians.	  We	  are	  <br/>
moving	  to	  an	  era	  where	  long	  time	  series	  are	  something	  of	  the	  past.	  Society	  is	  not	  as	  stable	  <br/>
as	  it	  once	  was.	  The	  focus	  should	  be	  on	  producing	  timely	  statistics	  to	  measure	  contemporary	  <br/>
phenomena.	  <br/>
•&#160;&#160;Statisticians	  need	  to	  be	  aware	  that	  users’	  behaviour	  can	  change	  and	  that	  this	  can	  create	  <br/>
continuity	  issues.	  If	  users	  were	  to	  hide	  their	  digital	  trail	  as	  a	  result	  of	  privacy	  concerns,	  this	  <br/>
would	  diminish	  the	  value	  of	  certain	  data	  sources.	  <br/>
•&#160;&#160;At	  present,	  NSIs	  have	  been	  opportunistic	  in	  their	  work	  with	  Big	  Data<b>.	  </b>What	  counts	  has	  been	  <br/>
largely	  defined	  in	  terms	  of	  access,	  circumstance	  or	  legislation.	  Statistical	  organisations	  need	  <br/>
to	  move	  away	  from	  this	  approach	  to	  develop	  more	  robust	  data	  strategies	  (e.g.	  <br/>
incorporating	  secondary	  data	  sources	  into	  an	  overall	  data	  strategy).	  <br/>
10.	  &#160;These	  issues	  can	  be	  addressed	  through	  ongoing	  col&#160;aborations.	  <br/>
	  <br/>32	  <br/>
	  <br/>
<hr/>
<a name=33></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
<b>Collaboratory 3: Big Data and Urban&#160;Waste Management&#160;</b><br/>
<b>Overview&#160;<br/></b>Metrics	  are	  integral	  to	  urban	  waste	  management.	  While	  measuring	  and	  counting	  have	  <br/>historically	  occupied	  a	  central	  place	  in	  government	  practices,	  Big	  Data	  introduces	  a	  new	  kind	  of	  <br/>political	  arithmetic	  for	  public	  bodies	  such	  as	  the	  Greater	  Manchester	  Waste	  Disposal	  Authority	  <br/>(GMWDA).	  Concerns	  with	  smart	  cities,	  data	  integration,	  responsive	  systems,	  transparency	  and	  <br/>accountability	  are	  some	  of	  the	  many	  ways	  in	  which	  such	  data	  is	  helping	  to	  reimagine	  and	  realise	  <br/>contemporary	  urban	  government.	  Big	  Data	  is	  of	  increasing	  importance	  to	  contemporary	  urban	  <br/>transformation,	  providing	  the	  potential	  to	  produce	  efficiency	  gains,	  cost	  savings,	  improved	  <br/>public	  services,	  more	  robust	  policy	  outcomes	  and	  environmentally	  sustainable	  modes	  of	  urban	  <br/>living.	  At	  the	  same	  time,	  working	  with	  Big	  Data	  introduces	  a	  series	  of	  challenges	  regarding	  <br/>accessibility,	  representation,	  reliability,	  data	  quality,	  integration	  and	  implementation	  that	  make	  <br/>counting	  and	  measuring	  increasingly	  vulnerable	  and	  unstable.	  These	  are	  some	  of	  the	  risks	  and	  <br/>vulnerabilities	  that	  this	  col&#160;aboratory	  aimed	  to	  interrogate.	  <br/>
The	  col&#160;aboratory	  brought	  together	  social	  scientists	  and	  waste	  practitioners	  to	  explore	  the	  role	  <br/>and	  implications	  of	  Big	  Data	  for	  waste	  management	  by	  attending	  to	  the	  question:	  <i>How	  might	  <br/>big	  data	  enable	  and/or	  constrain	  the	  particular	  relationships	  involved	  in	  waste	  management:	  <br/>between	  public	  and	  private	  sector	  service	  providers,	  between	  levels	  of	  government,	  between	  <br/>service	  providers	  and	  customers,	  between	  public	  bodies	  and	  citizens?</i>	  <br/>
The	  col&#160;aboratory	  was	  structured	  around	  three	  areas	  of	  debate	  with	  roundtable	  presentations	  <br/>and	  discussions	  structured	  around	  a	  number	  of	  questions.	  <br/>
1)&#160;&#160;Data	  and	  Waste	  Management	  was	  structured	  around	  the	  fol&#160;owing	  questions:	  <br/>
•&#160;&#160;How	  does	  Big	  Data	  differ	  from	  other	  types	  of	  data?	  <br/>•&#160;&#160;Are	  new	  measures	  produced?	  <br/>•&#160;&#160;How	  does	  data	  differ	  from	  information?	  <br/>•&#160;&#160;How	  does	  Big	  Data	  do	  counting	  and	  measuring	  differently	  to	  statistical	  or	  administrative	  <br/>
data?	  <br/>
•&#160;&#160;What	  is	  measured	  and	  what	  is	  valued?	  <br/>
	  <br/>
2)&#160;&#160;Ethics	  and	  Openness	  of	  Data	  <br/>
•&#160;&#160;What	  are	  the	  possibilities	  and	  challenges	  of	  working	  with	  Big	  Data	  in	  urban	  waste	  <br/>
management?	  <br/>
•&#160;&#160;Is	  Big	  Data	  open	  data?	  <br/>
33	  <br/>
	  <br/>
<hr/>
<a name=34></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
•&#160;&#160;What	  are	  the	  possibilities	  and	  challenges	  of	  public-­‐private	  partnerships	  for	  data	  <br/>
management?	  <br/>
3)&#160;&#160;Policy	  and	  Behaviour	  Change.	  <br/>
•&#160;&#160;How	  can	  Big	  Data	  be	  used	  to	  shape	  policy	  decisions	  and	  respond	  to	  future	  challenges	  in	  <br/>
waste	  management?	  <br/>
•&#160;&#160;Does	  it	  allow	  a	  different	  relation	  to	  the	  public?	  <br/>
These	  issues	  were	  canvassed	  in	  relation	  to	  the	  existing	  data	  practices	  of	  the	  Greater	  <br/>Manchester	  Waste	  Disposal	  Authority	  (GMWDA),	  in	  addition	  to	  waste	  practitioners’	  aspirations	  <br/>and	  expectations	  about	  how	  Big	  Data	  could	  contribute	  to	  the	  WDA’s	  ambition	  of	  ‘zero	  waste’	  to	  <br/>landfil&#160;	  by	  motivating	  behaviour	  change,	  altering	  consumption	  habits	  and	  encouraging	  recycling.	  <br/>
Participants	  included	  the	  Socialising	  Big	  Data	  project	  team,	  and	  social	  scientists	  and	  academics	  <br/>from	  Durham	  University	  and	  the	  University	  of	  Manchester,	  in	  addition	  to	  waste	  management	  <br/>practitioners	  from	  the	  Greater	  Manchester	  Waste	  Disposal	  Authority	  and	  local	  authority	  <br/>representatives	  from	  from	  Stockport	  Council,	  Bolton	  Council	  and	  Birmingham	  City	  Council.	  The	  <br/>col&#160;aboratory	  was	  organised	  by	  Prof.	  Penny	  Harvey,	  Dr	  Yannis	  Kallianos	  and	  Dr	  Camil&#160;a	  Lewis	  <br/>and	  held	  between	  30	  April	  -­‐	  1	  May	  2014	  at	  the	  Manchester	  Cathedral	  Centre,	  Manchester,	  UK.	  <br/>
Speakers	  included:	  <br/>
•&#160;&#160;<b>Neil	  Swannick</b>,	  Councillor,	  Manchester	  City	  Council	  <br/>•&#160;&#160;<b>Mark	  Muldoon</b>,	  University	  of	  Manchester	  <br/>•&#160;&#160;<b>Celia	  Lury</b>,	  University	  of	  Warwick	  <br/>•&#160;&#160;<b>Steve	  Rose</b>,	  Head	  of	  Strategic	  Research,	  Birmingham	  City	  Council	  <br/>•&#160;&#160;<b>Nicky	  Gregson</b>,	  Durham	  University	  <br/>•&#160;&#160;<b>Joanna	  Hayduk</b>,	  Greater	  Manchester	  Waste	  Disposal	  Authority	  <br/>•&#160;&#160;<b>Peter	  Davies</b>,	  Research	  Officer,	  Greater	  Manchester	  Waste	  Disposal	  Authority	  <br/>•&#160;&#160;<b>Catherine	  Alexander</b>,	  Durham	  University	  <br/>•&#160;&#160;<b>Mark	  Newall</b>,	  Director	  of	  Resources	  and	  Strategy,	  Greater	  Manchester	  Waste	  Disposal	  <br/>
Authority	  <br/>
	  <br/>
Some	  background	  readings	  on	  Waste	  Management	  were	  circulated	  in	  advance:	  <br/>
•&#160;&#160;Gee,	  S.	  &amp;	  Uyarra,	  E.	  (2014).	  Recycling	  and	  Waste	  Management	  Contract.	  Available	  at:	  <br/>
http://www.gmwda.gov.uk/recycling-­‐and-­‐waste-­‐management-­‐contract	  <br/>
•&#160;&#160;Krenchel,	  M.	  &amp;	  Madsbjerg,	  C.	  (2014).	  Your	  Big	  Data	  is	  Useless	  if	  You	  Don’t	  Bring	  it	  into	  the	  <br/>
Real	  World.	  <i>Wired</i>.:	  Available	  at:	  http://wrd.cm/1gS3oC8.	  	  <br/>
•&#160;&#160;Uprichard,	  E.	  (2013).	  Big	  Data,	  Little	  Questions.	  <i>Discover	  Society</i>,	  1.	  Available	  at:	  <br/>
http://www.discoversociety.org/2013/10/01/focus-­‐big-­‐data-­‐little-­‐questions/.	  	  <br/>
34	  <br/>
	  <br/>
<hr/>
<a name=35></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
<b>Summary&#160;of&#160;Presentations&#160;</b><br/>
Neil&#160;Swannick:&#160;Big&#160;Data&#160;–&#160;A&#160;Waste&#160;Perspective&#160;<br/>Council&#160;or	  Neil	  Swannick,	  from	  the	  Greater	  Manchester	  Waste	  Disposal	  Authority	  (WDA),	  <br/>discussed	  the	  future	  challenges	  facing	  urban	  waste	  management	  in	  Manchester,	  and	  how	  Big	  <br/>Data	  could	  data	  be	  incorporated	  into	  the	  WDA’s	  ambition	  to	  reduce	  waste	  and	  encourage	  <br/>recycling.	  Measuring	  the	  content	  of	  bins	  is	  central	  to	  the	  WDA’s	  approach	  to	  waste	  <br/>management	  because	  metrics	  based	  on	  waste	  compositional	  analysis	  determine	  how	  waste	  can	  <br/>be	  disposed	  of	  and	  recycled.	  Data	  recorded	  in	  2011,	  for	  example,	  revealed	  that	  74%	  of	  what	  is	  <br/>disposed	  in	  bins	  is	  potentially	  recyclable.	  This	  information	  can	  then	  be	  used	  to	  determine	  what	  <br/>type	  of	  technology	  should	  be	  deployed	  to	  facilitate	  recycling	  (e.g.	  the	  current	  4	  bin	  recycling	  <br/>system).	  Waste	  management	  is	  a	  dynamic	  process.	  It	  depends	  not	  only	  on	  recycling	  but	  also	  on	  <br/>consumption	  habits	  and,	  accordingly,	  waste	  management	  practitioners	  must	  target	  these	  areas	  <br/>in	  their	  entirety.	  The	  WDA	  have	  used	  sampling	  measures	  to	  analyse	  seasonal	  variations	  in	  <br/>col&#160;ection	  rates,	  interpreting	  these	  results	  in	  relation	  to	  socioeconomic	  factors,	  public	  attitudes	  <br/>and	  behaviours.	  Results	  demonstrate	  variance	  among	  communities	  in	  terms	  of	  consumption,	  <br/>waste	  and	  recycling	  practices.	  Data	  based	  on	  performance	  indicators	  are	  then	  linked	  to	  <br/>information	  on	  waste	  composition.	  <br/>
There	  is	  a	  pressing	  need	  to	  discover	  new	  ways	  to	  change	  attitudes,	  policies	  and	  behaviours	  <br/>around	  waste	  in	  order	  to	  maximise	  resources	  because	  current	  waste	  practices	  are	  not	  <br/>sustainable.	  Such	  an	  approach	  requires	  a	  move	  from	  existing	  data	  practices,	  which	  involves	  <br/>developing	  new	  technical	  skil&#160;s,	  as	  wel&#160;	  as	  a	  cultural	  shift	  in	  how	  the	  population	  view	  and	  <br/>respond	  to	  waste.	  Big	  Data	  could	  be	  incorporated	  into	  the	  WDA’s	  strategy	  to	  advance	  waste	  <br/>management	  practices.	  Once	  col&#160;ected,	  such	  data	  could	  be	  compared	  among	  and	  within	  <br/>municipalities	  at	  both	  a	  local	  and	  international	  level.	  This	  would	  result	  in	  efficiency	  gains	  and	  <br/>cost	  savings	  that	  would	  then	  translate	  into	  improved	  services	  and	  sustainability	  outcomes.	  Big	  <br/>Data	  technologies	  could	  also	  be	  used	  to	  modify	  behaviour	  and	  to	  meet	  waste	  targets.	  By	  using	  <br/>digital	  devices	  and	  sensors	  to	  identify	  those	  individuals	  who	  are	  not	  recycling	  in	  Greater	  <br/>Manchester,	  strategies	  could	  be	  established	  to	  alter	  people’s	  behaviour	  and	  motivate	  them	  to	  <br/>become	  more	  responsible	  citizens.	  <br/>
Despite	  the	  promise	  and	  potential	  of	  Big	  Data,	  adopting	  these	  technologies	  requires	  <br/>overcoming	  a	  series	  of	  challenges.	  In	  addition	  to	  technical	  and	  infrastructural	  issues,	  <br/>practitioners	  remain	  uncertain	  about	  how	  data	  could	  be	  used	  to	  change	  behaviour.	  While	  the	  <br/>population	  appears	  to	  support	  recycling,	  issues	  arise	  when	  attempting	  to	  translate	  beliefs	  into	  <br/>action.	  There	  is	  a	  general	  mistrust	  and	  ambivalence	  toward	  what	  are	  perceived	  to	  be	  intrusive	  <br/>technologies,	  such	  as	  putting	  incinerators	  in	  neighbourhoods	  or	  microchips	  into	  bins.	  In	  order	  <br/>to	  incorporate	  these	  technologies	  into	  waste	  management	  practices,	  the	  WDA	  wil&#160;	  need	  to	  <br/>
35	  <br/>
	  <br/>
<hr/>
<a name=36></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
establish	  public	  trust	  and	  overcome	  political	  opposition	  and	  ethical	  issues	  regarding	  privacy	  and	  <br/>surveil&#160;ance.	  <br/>
<b>Roundtable&#160;1:&#160;Data&#160;and&#160;Waste&#160;Management&#160;</b><br/>
Mark Muldoon&#160;<br/>Mark	  Muldoon,	  from	  the	  University	  of	  Manchester,	  discussed	  some	  of	  the	  opportunities	  and	  <br/>challenges	  of	  working	  with	  Big	  Data	  in	  terms	  of	  what	  can	  be	  measured	  and	  valued.	  He	  noted	  <br/>that	  while	  much	  Big	  Data	  is	  based	  on	  visualisation,	  these	  techniques	  are	  not	  always	  useful.	  For	  <br/>example,	  maps	  of	  small	  social	  networks	  can	  prompt	  interesting	  questions,	  but	  even	  moderately	  <br/>large	  data	  sets	  can	  produce	  indistinguishable	  results.	  When	  visualisation	  is	  effective,	  it	  is	  often	  <br/>because	  of	  some	  sort	  of	  emergent	  behaviour	  in	  which	  many	  identical	  (or	  similar	  things)	  <br/>correspond	  to	  produce	  novel	  phenomena	  not	  readily	  predicted	  from	  the	  properties	  of	  the	  parts	  <br/>(e.g.	  weather	  maps).	  <br/>
Big	  Data	  raises	  issues	  of	  data	  quality.	  This	  is	  especially	  due	  to	  the	  social	  network	  of	  corporate	  <br/>governance,	  where	  individuals	  have	  to	  rely	  on	  commercial	  services	  to	  clean	  and	  process	  the	  <br/>data,	  which	  can	  lead	  to	  sampling	  issues.	  Missing	  metrics	  is	  another	  issue	  associated	  with	  Big	  <br/>Data.	  While	  Big	  Data	  can	  be	  used	  as	  a	  predictive	  tool	  in	  an	  effort	  to	  deal	  with	  uncertainty,	  <br/>incomplete	  samples	  measured	  by	  imperfect	  instruments	  can	  cause	  problems	  for	  those	  working	  <br/>with	  such	  data.	  Minor	  uncertainties	  in	  the	  data,	  whether	  due	  to	  sampling	  problems	  or	  <br/>measurement	  errors,	  can	  produce	  major	  differences.	  Predictive	  computations	  of	  this	  kind	  are	  a	  <br/>second	  source	  of	  “bigness”	  in	  Big	  Data:	  model&#160;ers	  sometimes	  use	  data	  to	  create	  larger	  data	  <br/>sets.	  <br/>
Big	  Data	  software	  and	  analysis	  tools	  could	  open	  up	  new	  possibilities,	  many	  of	  which	  are	  <br/>unknown	  at	  this	  point	  in	  time.	  A	  case	  in	  point	  was	  a	  recent	  contest	  by	  the	  web-­‐analytics	  firm,	  <br/>Kaggle,	  which	  revealed	  that	  because	  the	  volume	  of	  data	  and	  the	  requisite	  computational	  tools	  <br/>are	  much	  larger	  than	  the	  kinds	  of	  things	  that	  academics	  previously	  analysed,	  they	  constitute	  a	  <br/>new	  set	  of	  “tools”	  whose	  uses	  are	  not	  yet	  apparent,	  even	  to	  their	  developers.	  Tools	  have	  a	  way	  <br/>of	  finding	  new	  uses	  for	  themselves.	  Once	  a	  tool	  performs	  a	  task	  with	  ease,	  new	  approaches	  and	  <br/>views	  of	  what	  is	  feasible	  present	  themselves.	  In	  a	  similar	  way,	  much	  of	  the	  potential	  of	  Big	  Data	  <br/>is	  probably	  not	  yet	  realised.	  <br/>
Celia Lury&#160;<br/>Celia	  Lury,	  Director	  of	  the	  Centre	  for	  Interdisciplinary	  Methodologies	  at	  the	  University	  of	  <br/>Warwick,	  presented	  a	  provocation	  based	  on	  the	  views	  of	  Sandy	  Pentland,	  a	  data	  scientist	  from	  <br/>MIT’s	  Media	  Lab,	  to	  stimulate	  discussion	  on	  some	  of	  the	  ways	  that	  Big	  Data	  is	  beginning	  to	  <br/>transform	  social	  scientific	  research.	  As	  an	  advocate	  of	  Big	  Data,	  Pentland	  highlights	  the	  <br/>possibilities	  associated	  with	  Big	  Data.	  He	  believes	  that	  data	  science	  is	  equivalent	  to	  social	  <br/>
36	  <br/>
	  <br/>
<hr/>
<a name=37></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
physics	  with	  the	  capacity	  to	  revolutionise	  society.	  It	  is	  important	  to	  remember	  that	  what	  is	  <br/>emerging	  is	  a	  field	  in	  progress.	  At	  present,	  there	  is	  much	  uncertainty	  about	  what	  data	  science	  is	  <br/>or	  could	  be.	  The	  availability	  of	  Big	  Data	  software	  and	  processing	  tools	  is	  beginning	  to	  transform	  <br/>what	  we	  think	  data	  can	  do.	  In	  order	  to	  be	  useful,	  however,	  Big	  Data	  needs	  to	  move	  beyond	  <br/>methods	  that	  establish	  statistical	  significance.	  Generally,	  the	  volume	  of	  such	  data	  is	  so	  great	  <br/>that	  any	  question	  you	  ask	  of	  it	  wil&#160;	  generate	  a	  statistically	  significant	  answer.	  This	  implies	  that	  <br/>the	  scientific	  method,	  as	  traditionally	  used,	  is	  no	  longer	  effective	  because	  the	  size	  of	  Big	  Data	  <br/>sets	  wil&#160;	  almost	  always	  produce	  significant	  results,	  which	  can	  also	  lead	  to	  false	  correlations.	  <br/>
In	  order	  to	  overcome	  these	  challenges,	  Big	  Data	  requires	  human	  understanding	  of	  the	  <br/>connection	  between	  data	  points.	  This	  involves	  not	  merely	  contrasting	  cause	  and	  correlation,	  <br/>but	  steering	  a	  midcourse	  between	  them.	  The	  emphasis	  would	  move	  away	  from	  causality,	  which	  <br/>is	  bound	  to	  particular	  understandings	  of	  statistical	  significance,	  to	  a	  dialogue	  between	  our	  <br/>human	  intuition	  and	  Big	  Data	  statistics.	  What	  is	  required	  is	  new	  ways	  to	  test	  connections	  in	  the	  <br/>real	  world	  that	  move	  beyond	  laboratory	  experiments,	  col&#160;ection	  and	  computational	  analysis	  to	  <br/>include	  real-­‐life	  experiments.	  With	  social	  phenomena	  comprised	  of	  mil&#160;ions	  of	  small	  <br/>transactions	  between	  individuals,	  averages	  are	  no	  longer	  adequate	  as	  a	  way	  of	  representing	  <br/>society.	  Instead,	  individual	  transactions	  form	  the	  unit	  of	  analysis	  and	  it	  is	  these	  patterns	  that	  <br/>wil&#160;	  provide	  the	  basis	  of	  this	  new	  era	  of	  social	  physics.	  Such	  insights	  have	  important	  implications	  <br/>for	  social	  policy	  in	  terms	  of	  what	  ought	  to	  be	  measured	  and	  valued.	  <br/>
Big	  Data	  raises	  issues	  around	  ethics	  and	  privacy.	  Consent	  and	  anonymity	  might	  no	  longer	  be	  <br/>sufficient	  or	  appropriate	  because	  these	  tend	  to	  remove	  the	  participant	  from	  the	  study,	  thereby,	  <br/>distancing	  the	  subject	  from	  the	  research.	  A	  way	  to	  overcome	  this	  issue	  is	  to	  think	  of	  Big	  Data	  <br/>experiments	  as	  participatory,	  so	  that	  participation	  is	  an	  active	  rather	  than	  a	  passive	  process.	  <br/>
Big	  Data	  focuses	  on	  computational	  techniques,	  but	  these	  must	  be	  understood	  in	  relation	  to	  a	  <br/>broader	  assemblage	  of	  research	  methods.	  These	  could	  be	  based,	  for	  example,	  on	  experiments	  <br/>in	  urban	  laboratories	  and	  iterative	  testing	  of	  correlations,	  which	  would	  provide	  a	  different	  way	  <br/>to	  establish	  the	  significance	  of	  correlations	  in	  which	  you	  imagine	  and	  experimentally	  test	  what	  <br/>could	  be	  significant	  rather	  than	  relying	  on	  statistical	  significance	  alone.	  Urban	  laboratories	  <br/>could	  involve	  actors	  in	  the	  coproduction	  of	  knowledge	  who	  participate	  in	  knowledge	  exchange,	  <br/>fostering	  an	  orientation	  to	  change	  built	  on	  a	  contingency	  of	  uncertainty.	  Working	  with	  Big	  Data	  <br/>in	  this	  way	  raises	  issues	  of	  scaling,	  generalisation,	  marginalisation	  and	  pathologisation,	  but	  it	  is	  <br/>an	  emerging	  mode	  of	  research.	  Simulation	  and	  visualisation	  could	  also	  be	  used	  not	  merely	  to	  <br/>il&#160;ustrate	  a	  finding,	  but	  as	  part	  of	  the	  scientific	  method	  to	  identify	  significant	  relations.	  From	  this	  <br/>perspective,	  problems	  do	  not	  need	  to	  be	  hypothesised	  in	  advance.	  Instead,	  problems	  and	  <br/>significance	  could	  be	  produced	  simultaneously	  if	  visualisation	  is	  used	  as	  part	  of	  the	  process	  to	  <br/>establish	  significance.	  <br/>
37	  <br/>
	  <br/>
<hr/>
<a name=38></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
<b>Roundtable&#160;2:&#160;Ethics&#160;and&#160;Openness&#160;of&#160;Data&#160;</b><br/>
Steve&#160;Rose&#160;<br/>Steve	  Rose,	  Head	  of	  Strategic	  Research	  at	  Birmingham	  City	  Council	  (BCC),	  discussed	  ethics	  and	  <br/>open	  data	  in	  relation	  to	  the	  kind	  of	  data	  col&#160;ected	  from	  fleet	  and	  waste	  services.	  Case	  studies	  <br/>were	  employed	  to	  demonstrate	  the	  innovative	  ways	  that	  the	  City	  Council	  has	  incorporated	  data	  <br/>into	  their	  practices	  to	  il&#160;ustrate	  the	  potential	  of	  working	  with	  Big	  Data.	  BCC	  use	  the	  GPS	  data	  <br/>that	  tracks	  and	  records	  fleet	  vehicle	  movements	  to	  remodel	  the	  refuse	  col&#160;ection	  rounds.	  This	  <br/>minimises	  distance	  travel&#160;ed	  but	  also	  provides	  digital	  routes	  to	  start	  to	  link	  to	  customer	  <br/>relationship	  management	  requirements	  such	  as	  assisted	  col&#160;ections.	  BCC	  also	  conducted	  a	  trial	  <br/>where	  residents	  were	  awarded	  Nectar	  points	  in	  response	  to	  recycling	  participation.	  Rewarding	  <br/>residents	  for	  recycling	  proved	  successful	  in	  terms	  of	  behaviour	  change	  resulting	  in	  9%	  extra	  <br/>tonnage	  and	  a	  10%	  increase	  in	  col&#160;ection	  rates.	  Such	  initiatives	  suggest	  that	  customers	  and	  their	  <br/>data	  could	  be	  at	  the	  forefront	  of	  service	  thinking.	  <br/>
These	  case	  studies	  reveal	  the	  potential	  practical	  applications	  that	  could	  be	  realised	  from	  waste	  <br/>data	  and	  the	  role	  of	  open	  data	  in	  achieving	  this.	  There	  are	  opportunities	  to	  use	  Big	  Data	  <br/>technologies	  to	  develop	  incentives	  based	  on	  loyalty	  and	  reward.	  Big	  data	  could	  be	  used	  to	  <br/>improve	  council	  services,	  especially	  through	  data	  linkage	  and	  integration.	  Despite	  these	  <br/>potentials,	  it	  is	  difficult	  to	  translate	  trials	  into	  action	  and	  to	  change	  existing	  work	  practices.	  In	  <br/>order	  to	  be	  actualised,	  councils	  wil&#160;	  need	  to	  develop	  new	  technical	  skil&#160;s	  and	  partnerships	  <br/>(public-­‐private).	  They	  wil&#160;	  also	  need	  to	  overcome	  a	  series	  of	  ethical	  challenges	  regarding	  trust	  <br/>and	  accountability	  in	  order	  to	  encourage	  users	  to	  exchange	  politically	  sensitive	  information	  and	  <br/>to	  volunteer	  in	  the	  coproduction	  of	  such	  data.	  <br/>
Nicky&#160;Gregson&#160;<br/>Nicky	  Gregson,	  from	  Durham	  University,	  explored	  the	  possibilities	  of	  Big	  Data	  in	  waste	  <br/>management,	  focusing	  on	  the	  potential	  and	  limitations	  of	  smart	  bin	  technologies	  and	  their	  <br/>association	  with	  the	  Internet	  of	  things.	  There	  was	  particular	  emphasis	  on	  the	  differences	  that	  <br/>certain	  devices	  and	  sensors	  could	  make	  to	  waste	  data	  and	  municipal	  waste	  relations.	  In	  the	  UK,	  <br/>the	  debate	  on	  data	  technologies	  is	  generally	  framed	  in	  relation	  to	  bin	  col&#160;ection	  and	  <br/>understood	  in	  terms	  of	  track	  and	  trace,	  and	  chip	  devices.	  The	  problem	  is	  that	  the	  data	  <br/>generated	  by	  these	  devices	  only	  calculates	  specific	  metrics:	  weight	  (tonnage)	  and	  household	  <br/>(non)compliance.	  Such	  an	  approach	  provides	  a	  limited	  way	  of	  thinking	  about	  waste	  generation.	  <br/>These	  devices	  may	  be	  cost	  effective,	  but	  are	  relatively	  ineffective	  because	  they	  use	  the	  same	  <br/>metrics	  and	  subsequently	  as	  a	  technology	  are	  unlikely	  to	  alter	  behaviour,	  individually	  or	  <br/>col&#160;ectively.	  <br/>
Big	  Data	  technologies,	  by	  contrast,	  such	  as	  smart	  bins	  (sensor	  devices	  designed	  to	  produce	  <br/>certain	  metrics)	  col&#160;ect	  real-­‐time	  measurement	  data.	  Data	  is	  measured	  not	  just	  in	  terms	  of	  <br/>38	  <br/>
	  <br/>
<hr/>
<a name=39></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
quantity,	  but	  also	  the	  <i>quality	  </i>of	  the	  content	  of	  bins	  (e.g.	  fil&#160;	  levels	  and	  temperature	  of	  <br/>materials).	  Technologies	  of	  this	  kind	  move	  data	  away	  from	  a	  reactive	  monitoring	  of	  a	  bin	  to	  the	  <br/>possibilities	  of	  waste	  data	  being	  anticipatory	  and	  predictive.	  This	  enables	  new	  possibilities	  of	  <br/>modeling,	  simulation,	  and	  forecasting	  waste	  data	  at	  the	  level	  of	  the	  individual	  household,	  which	  <br/>could	  then	  be	  amalgamated	  up	  to	  the	  level	  of	  the	  municipality.	  An	  example	  of	  such	  initiatives	  <br/>was	  conducted	  by	  the	  Scandinavian	  company,	  Enevo,	  which	  used	  smart	  technologies	  to	  <br/>produce	  efficiency	  savings	  in	  public	  services.	  Sending	  trucks	  on	  near-­‐time	  modeled	  routes,	  <br/>instead	  of	  predetermined	  routes,	  resulted	  in	  a	  30-­‐40%	  reduction	  on	  logistics	  costs.	  These	  <br/>technologies	  have	  the	  capacity	  to	  change	  the	  relationship	  between	  the	  household	  and	  the	  <br/>council,	  leading	  to	  more	  personalised,	  cost	  effective	  services.	  To	  benefit	  from	  these	  <br/>opportunities,	  however,	  requires	  a	  high	  degree	  of	  public	  trust,	  which	  is	  arguably	  absent	  in	  the	  <br/>UK.	  At	  the	  same	  time,	  working	  with	  Big	  Data	  technologies	  raise	  associated	  issues	  of	  public	  fear;	  <br/>resistance;	  data	  integration	  and	  work	  cultures.	  <br/>
In	  sum,	  the	  shift	  towards	  Big	  Data	  signals	  a	  policy	  move	  from	  measuring	  waste	  in	  terms	  of	  <br/>tonnages	  of	  materials	  diverted	  from	  landfil&#160;	  for	  recycling	  to	  secondary	  resources	  circulating	  <br/>within	  a	  circular	  economy.	  These	  real-­‐time	  (or	  near	  time)	  metrics	  wil&#160;	  assume	  increasing	  <br/>significance	  in	  the	  future	  for	  waste	  practitioners.	  From	  this	  perspective,	  it	  is	  important	  to	  think	  <br/>about	  waste	  management	  as	  resource	  harvesting.	  Such	  an	  approach	  has	  implications	  for	  data	  <br/>col&#160;ection	  with	  an	  emphasis	  on	  the	  <i>quality</i>	  of	  content	  as	  opposed	  to	  standard	  measurements	  of	  <br/>quantity	  and	  weight	  (tonnage).	  <br/>
Joanna&#160;Hayduk:&#160;Using&#160;Data&#160;to&#160;Inform&#160;Decisions&#160;<br/>Joanna	  Hayduk,	  from	  the	  Greater	  Manchester	  Waste	  Disposal	  Authority,	  discussed	  how	  local	  <br/>authorities	  use	  data	  to	  inform	  decisions.	  &#160;At	  present,	  LAs	  use	  a	  variety	  of	  data	  sources.	  This	  <br/>includes	  sociodemographic,	  operational	  and	  cost	  data,	  as	  wel&#160;	  as	  recycling	  service	  information,	  <br/>made	  available	  at	  a	  local	  and	  national	  level.	  Examples	  of	  how	  LAs	  use	  data	  were	  then	  discussed	  <br/>in	  relation	  to	  two	  case	  studies:	  WasteDataFlow	  and	  WRAP’s	  Local	  Authority	  Waste	  and	  <br/>Recycling	  Information	  Portal.	  <br/>
Big	  Data	  introduces	  new	  possibilities	  and	  has	  the	  potential	  to	  lead	  to	  efficiency	  and	  cost	  gains.	  <br/>At	  the	  same	  time,	  working	  with	  such	  data	  presents	  a	  series	  of	  challenges	  regarding	  availability;	  <br/>relevance;	  representation;	  skil&#160;	  shortages	  and	  the	  inability	  to	  col&#160;ate	  and	  process	  such	  data.	  <br/>While	  data	  linkage	  could	  provide	  new	  insights	  for	  waste	  practitioners,	  public-­‐private	  <br/>partnerships	  tend	  to	  be	  hindered	  by	  ethical	  issues	  of	  privacy	  and	  confidentiality,	  particularly	  <br/>given	  the	  different	  objectives	  of	  these	  groups.	  <br/>
39	  <br/>
	  <br/>
<hr/>
<a name=40></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
<b>Roundtable&#160;3:&#160;Policy&#160;and&#160;Behaviour&#160;Change&#160;</b><br/>
Peter&#160;Davies:&#160;Socialising&#160;Waste&#160;Data:&#160;The&#160;GM&#160;Experience&#160;<br/>Peter	  Davies,	  from	  Greater	  Manchester	  Waste	  Disposal	  Authority	  (GMWDA),	  discussed	  the	  <br/>WDA’s	  experience	  of	  using	  waste	  data	  to	  encourage	  recycling	  and	  behavior	  change.	  Greater	  <br/>Manchester	  Waste	  Disposal	  Authority	  consists	  of	  nine	  District	  Councils,	  which	  have	  been	  <br/>brought	  together	  under	  a	  25-­‐year	  Recycling	  and	  Waste	  Management	  Contract.	  &#160;The	  majority	  of	  <br/>waste	  is	  delivered	  to	  facilities	  via	  a	  four-­‐stream	  kerbside	  sort	  system,	  or	  taken	  directly	  to	  <br/>household	  waste	  recycling	  centres.	  &#160;Weigh-­‐bridge	  data	  provide	  accurate	  figures	  to	  assess	  the	  <br/>performance	  (e.g.	  landfil&#160;	  diversion,	  recycling	  rate	  and	  the	  contract),	  but	  is	  ineffective	  in	  helping	  <br/>practitioners	  develop	  new	  strategies	  to	  encourage	  waste	  prevention	  and	  recycling.	  <br/>
In	  2011	  a	  waste	  compositional	  analysis	  was	  undertaken.	  This	  study	  provided	  a	  better	  <br/>understanding	  of	  what	  materials	  were	  not	  being	  captured	  and	  the	  type	  of	  households	  and	  <br/>demographics	  that	  were	  not	  recycling.	  When	  combined	  with	  national	  data,	  this	  information	  <br/>was	  used	  to	  formulate	  the	  basis	  of	  the	  LIFE+	  project,	  which	  aimed	  to	  target	  an	  increase	  <br/>recycling	  practices	  among	  specific	  groups	  (e.g.	  rental	  properties).	  <br/>
The	  nature	  and	  variability	  of	  waste	  has	  raised	  significant	  challenges	  for	  the	  WDA,	  particularly	  in	  <br/>terms	  of	  identifying	  areas	  of	  low	  performance	  and	  assessing	  the	  impact	  of	  campaigns	  across	  the	  <br/>population.	  These	  issues	  need	  to	  be	  addressed	  in	  order	  for	  waste	  practitioners	  to	  inform	  policy	  <br/>and	  behaviour	  change.	  Public	  and	  private	  partnerships	  could	  help	  to	  overcome	  this	  issue.	  The	  <br/>academic	  community	  could	  also	  provide	  valuable	  input	  by	  exploring	  new	  ways	  that	  data	  can	  be	  <br/>used	  to	  support	  behavioural	  change.	  <br/>
Catherine&#160;Alexander&#160;<br/>Catherine	  Alexander,	  from	  Durham	  University,	  discussed	  some	  of	  the	  opportunities	  and	  <br/>challenges	  of	  using	  Big	  Data	  in	  the	  context	  of	  waste	  management,	  sustainability	  and	  the	  <br/>environment.	  These	  issues	  were	  canvassed	  in	  relation	  to	  a	  project	  that	  explored	  recycling	  <br/>habits	  and	  third	  sector	  recycling	  companies	  in	  the	  London	  Borough	  of	  Southwark.	  Together	  <br/>with	  col&#160;eagues	  from	  the	  Environmental	  Engineering	  Department	  at	  the	  University	  of	  Surrey	  <br/>working	  on	  the	  project	  called	  LARA	  (Local	  Area	  Resource	  Analysis),	  the	  project	  sought	  to	  <br/>understand	  why	  areas	  featuring	  dense	  housing	  and	  high-­‐rise	  estates	  had	  particularly	  low	  <br/>recycling	  rates.	  Attempts	  to	  col&#160;aborate	  with	  other	  researchers	  working	  on	  similar	  studies	  <br/>raised	  issues	  of	  comparability,	  data	  linkage	  and	  integration	  given	  the	  different	  practices	  of	  <br/>col&#160;ecting	  and	  analysing	  the	  data,	  particularly	  when	  expenditure	  was	  used	  as	  a	  proxy	  for	  <br/>consumption	  to	  predict	  future	  household	  waste,	  as	  was	  the	  case	  with	  LARA.	  <br/>
	  <br/>
40	  <br/>
	  <br/>
<hr/>
<a name=41></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
In	  addition	  to	  these	  methodological	  challenges,	  several	  insights	  arose	  when	  comparing	  <br/>methods	  to	  predict	  waste	  by	  looking	  at	  household	  metabolisms.	  While	  the	  majority	  of	  studies	  <br/>that	  examine	  material	  flows	  take	  place	  in	  households,	  they	  all	  use	  slightly	  different	  methods	  <br/>based	  upon	  different	  assumptions	  and	  metrics	  (e.g.	  using	  expenditure	  as	  a	  proxy	  for	  <br/>consumption	  instead	  of	  metrics	  based	  on	  weight).	  In	  effect,	  this	  means	  that	  although	  there	  is	  <br/>much	  data	  to	  reference,	  there	  is	  no	  cumulative	  data	  object	  or	  “thing”	  that	  researchers	  can	  <br/>track,	  compare	  and	  develop.	  Other	  challenges	  that	  arose	  concerned	  missing	  metrics,	  <br/>incomplete	  or	  unreliable	  waste	  statistics,	  particularly	  in	  deprived	  inner	  city	  areas.	  This	  raised	  <br/>associated	  methodological	  issues	  regarding	  classification	  and	  representation.	  Census	  data	  <br/>proved	  particularly	  unreliable	  as	  it	  had	  a	  low	  rate	  response	  rate	  (52%).	  These	  issues	  were	  <br/>confounded	  as	  census	  classifications	  did	  not	  always	  correspond	  to	  household	  practices	  (e.g.	  <br/>sharing	  income,	  expenditure	  and	  differences	  between	  short-­‐term	  and	  long-­‐term	  rentals),	  just	  <br/>as	  expenditure	  data	  did	  not	  adequately	  represent	  household	  economies	  (e.g.	  childcare	  and	  <br/>income).	  Data	  of	  this	  kind	  resulted	  in	  a	  smoothing	  effect	  that	  failed	  to	  represent	  individual	  <br/>variation	  between	  households	  or	  reflect	  the	  rapid	  turnover	  of	  people	  of	  certain	  populations	  <br/>(due	  to	  relocation	  or	  death,	  for	  example).	  As	  a	  consequence	  figures,	  models	  and	  assumptions	  <br/>had	  to	  be	  re-­‐evaluated.	  Moreover,	  the	  assumption	  that	  you	  could	  predict	  the	  timing	  of	  waste	  <br/>arising	  by	  the	  end	  of	  the	  functional	  life	  of	  something	  was	  problematic	  because	  other	  factors	  <br/>come	  into	  play	  (e.g.	  high	  churn	  rates).	  In	  revealing	  the	  tendency	  to	  infer	  a	  general	  pattern	  from	  <br/>the	  individual	  without	  thinking	  about	  individual	  variations,	  these	  studies	  highlight	  the	  need	  to	  <br/>critically	  assess	  the	  data	  upon	  which	  urban	  waste	  management	  is	  based.	  <br/>
Mark Newall&#160;<br/>Mark	  Newall,	  from	  the	  GMWDA,	  discussed	  how	  Big	  Data	  can	  be	  used	  to	  shape	  policy	  decisions	  <br/>and	  respond	  to	  future	  challenges.	  Waste	  management	  needs	  to	  be	  understood	  in	  the	  context	  <br/>of	  sustainable	  development	  and	  limited	  resources.	  The	  population	  is	  projected	  to	  rise	  from	  c7	  <br/>bil&#160;ion	  in	  2014	  to	  c9	  bil&#160;ion	  in	  2050	  and	  as	  developing	  countries	  continue	  to	  grow	  the	  demand	  <br/>for	  raw	  materials	  is	  increasing	  and	  C02	  emissions,	  particularly	  in	  Asia	  Pacific	  countries,	  are	  rising	  <br/>rapidly.	  This	  requires	  a	  fundamental	  change	  business	  practices	  and	  how	  the	  world	  consumes	  <br/>that	  requires	  the	  public,	  government	  and	  commercial	  sectors	  to	  work	  closely	  together.	  <br/>
Behaviour	  change	  is	  the	  key	  challenge	  currently	  facing	  waste	  practitioners.	  Consumers	  need	  to	  <br/>be	  the	  driving	  force	  for	  sustainable	  goods	  and	  begin	  to	  see	  waste	  as	  a	  resource.	  &#160;Education,	  <br/>high-­‐quality	  data	  and	  consumer	  feedback	  (via	  campaigns	  and	  social	  media,	  for	  example)	  is	  <br/>essential	  if	  behaviour	  change	  is	  to	  take	  place.	  In	  order	  to	  be	  effective,	  these	  must	  occur	  within	  a	  <br/>robust	  policy	  framework.	  &#160;To	  do	  so	  requires	  data	  linkage	  on	  waste	  data,	  the	  environment	  and	  <br/>climate	  change	  and	  sustainable	  consumption	  and	  production	  by	  engaging	  with	  the	  <br/>policymakers,	  businesses	  and	  consumers.	  Only	  then	  can	  new	  practices	  around	  waste	  emerge	  <br/>that	  wil&#160;	  result	  in	  substantive	  effects.	  <br/>
41	  <br/>
	  <br/>
<hr/>
<a name=42></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
<b>Summary&#160;of&#160;Key&#160;Themes&#160;Arising&#160;at&#160;Each Collaboratory&#160;<br/></b>Fol&#160;owing	  each	  of	  the	  col&#160;aboratories,	  the	  project	  team	  reflected	  on	  the	  various	  presentations	  <br/>and	  the	  conversations	  and	  discussions	  that	  ensued.	  For	  each	  col&#160;aboratory	  we	  analysed	  and	  <br/>organised	  the	  outcomes	  in	  different	  ways.	  &#160;For	  Genomics,	  in	  relation	  to	  key	  challenges;	  National	  <br/>Statistics	  in	  relation	  to	  key	  questions;	  and	  Waste	  Management	  in	  relation	  to	  key	  topics.	  These	  <br/>are	  of	  course	  not	  exhaustive	  –	  numerous	  issues	  were	  raised.	  &#160;Here	  we	  sought	  to	  highlight	  what	  <br/>we	  considered	  to	  be	  some	  of	  the	  most	  prominent	  and	  repeated.	  Like	  the	  conduct	  of	  the	  <br/>col&#160;aboratories	  we	  trialled	  different	  ways	  of	  doing	  this	  as	  is	  reflected	  below.	  <br/>
<b>Collaboratory&#160;1:&#160;Genomics&#160;</b><br/>
Indeterminacy, Uncertainty &amp; Errors&#160;<br/>
•&#160;&#160;There	  was	  an	  acute	  awareness	  of	  having	  to	  work	  with	  errors	  and	  uncertainty.	  One	  <br/>
manifestation	  of	  this	  is	  the	  challenge	  of	  distinguishing	  between	  signal	  and	  noise;	  whether	  a	  <br/>
given	  sequence	  variation	  is	  biological	  (i.e.	  real),	  or	  due	  to	  experimental	  artifact	  or	  error?	  <br/>
Other	  points	  of	  indeterminacy	  come	  from	  the	  challenges	  of	  mapping	  a	  given	  sequence	  onto	  <br/>
the	  reference	  genome.	  This	  challenge	  is	  compounded	  by	  the	  repetitive	  nature	  of	  parts	  of	  <br/>
the	  genome	  combined	  with	  very	  high	  focus	  close-­‐ups	  of	  the	  genome	  (short	  reads),	  making	  it	  <br/>
like	  doing	  a	  jigsaw	  puzzle	  that	  has	  lots	  of	  blue	  sky.	  Indeterminacy	  is	  also	  generated	  by	  the	  <br/>
changing	  nature	  of	  the	  reference	  genome.	  A	  further	  area	  of	  indeterminacy	  is	  interpretation	  <br/>
–	  even	  if	  the	  sequence	  is	  correct	  and	  correctly	  mapped	  –	  what	  does	  it	  mean?	  <br/>
•&#160;&#160;Genomics	  practitioners	  are	  very	  aware	  of	  the	  <i>performativity	  of	  their	  methods</i>.	  They	  live	  and	  <br/>
work	  in	  knowledge	  of	  the	  reality	  that	  different	  instruments	  and	  different	  software	  analysis	  <br/>
tools	  find	  different	  data<b>	  </b>in	  the	  same	  sample.	  For	  example,	  when	  instrument	  vendors	  change	  <br/>
their	  quality	  control	  software,	  then	  the	  sequence	  changes!	  <br/>
•&#160;&#160;This	  means	  having	  an	  awareness	  that	  having	  more	  sequence	  data	  produced	  by	  'next	  <br/>
generation	  sequencers'	  (NGS)	  wil&#160;s	  not	  necessarily	  reduce	  uncertainty.	  On	  the	  contrary,	  it	  <br/>
can	  increase	  it.	  For	  rare	  diseases,	  e.g.,	  as	  the	  number	  and	  intensity	  of	  NGS	  studies	  increases,	  <br/>
the	  less	  certain	  the	  meaning	  of	  a	  single	  rare	  variant	  becomes.	  Similarly,	  in	  terms	  of	  <br/>
sequence	  coverage,	  there	  is	  a	  need	  to	  find	  a	  ‘sweet	  spot’	  in	  between	  too	  much	  and	  too	  little	  <br/>
coverage.	  &#160;The	  same	  applies	  to	  software	  tools.	  Instead	  of	  triangulation,	  the	  more	  analytical	  <br/>
tools	  that	  are	  used,	  the	  more	  the	  uncertainty	  can	  proliferate.	  <br/>
•&#160;&#160;Is	  it	  possible	  to	  step	  outside	  of	  NGS	  to	  make	  a	  reality	  check?	  Is	  there	  a	  Gold	  Standard	  for	  <br/>
comparison,	  for	  example,	  is	  Sanger	  sequencing	  used	  to	  determine	  discrepancies	  in	  NGS	  <br/>
data?	  Not	  necessarily.	  Again,	  practitioners	  at	  the	  workshop	  live	  with	  an	  understanding	  of	  <br/>
the	  performativity	  of	  <i>al&#160;	  methods</i>,	  not	  just	  NGS.	  In	  other	  words,	  there	  is	  no	  ‘sky	  hook’	  –	  no	  <br/>
privileged	  position	  –	  from	  which	  to	  get	  unmediated	  access	  to	  the	  real.	  Yet	  work	  continues	  <br/>
despite	  the	  difficulty	  of	  knowing	  what	  is	  real	  and	  what	  is	  artefactual	  or	  error.	  Radical	  <br/>
indeterminacy	  is	  not	  a	  deterrent	  to	  progress.	  Moreover,	  ‘this	  is	  nothing	  new’.	  <br/>
•&#160;&#160;When	  it	  comes	  to	  interpretation	  and	  prediction,	  e.g.,	  severity	  of	  a	  disease,	  NGS	  data	  has	  to	  <br/>
be	  compared	  with	  and	  related	  to	  other	  forms	  of	  data	  to	  get	  an	  ‘orthogonal’	  check	  on	  what	  <br/>
it	  means.	  Selecting	  what	  to	  compare	  a	  given	  set	  of	  results	  which	  requires	  professional	  <br/>
42	  <br/>
	  <br/>
<hr/>
<a name=43></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
judgment	  and	  expertise,	  including	  an	  assessment	  of	  the	  reputation	  of	  other	  scientists	  and	  <br/>
their	  laboratories,	  which	  may	  determine	  whether	  to	  take	  their	  results	  into	  account	  or	  not.	  <br/>
•&#160;&#160;However,	  comparison	  between	  different	  data	  types	  is	  not	  straightforward.	  Integration	  is	  <br/>
problematic.	  There	  is	  awareness	  that	  comparison	  does	  not	  necessarily	  lead	  to	  convergence	  <br/>
since	  different	  assays	  on	  the	  same	  sample	  may	  not	  readily	  align	  with	  a	  singular	  underlying	  <br/>
reality.	  Consistency	  between	  different	  kinds	  of	  data<b>	  </b>is	  itself	  a	  quality	  that	  has	  to	  be	  assessed	  <br/>
and	  measured	  and	  produced	  rather	  than	  a	  given,	  as	  was	  il&#160;ustrated	  in	  the	  case	  of	  multiple	  <br/>
(omic)	  studies	  of	  stem	  cel&#160;s.	  <br/>
Diversity&#160;and&#160;Difference&#160;in&#160;NGS&#160;Producers,&#160;Uses&#160;&amp;&#160;Applications&#160;<br/>
•&#160;&#160;NGS	  data	  are	  produced	  for	  a	  wide	  variety	  of	  uses,	  communities	  and	  applications.	  These	  <br/>
different	  real	  and	  imagined	  downstream	  deployments	  of	  NGS	  dataset	  and	  their	  <br/>
interpretations	  are	  apparent	  in	  how	  they	  are	  evaluated,	  packaged	  and	  stored.	  <br/>
•&#160;&#160;One	  area	  of	  difference	  is	  the	  validity	  of	  result	  and	  the	  rigor	  of	  their	  testing.	  At	  one	  end	  of	  <br/>
the	  spectrum	  are	  clinical	  applications.	  For	  this,	  tolerance	  of	  uncertainty	  is	  very	  low	  because	  <br/>
lives	  may	  be	  at	  stake.	  ‘Are	  the	  results	  and	  analysis	  reliable	  enough	  to	  be	  the	  basis	  of	  <br/>
counseling	  for	  therapeutic	  termination?’	  Further	  down	  the	  spectrum	  is	  the	  realm	  of	  <br/>
scientific	  knowledge	  production.	  Here,	  whilst	  uncertainty	  is	  to	  some	  degree	  minimized,	  the	  <br/>
consequences	  of	  acting	  on	  it	  are	  not	  as	  critical;	  indeed,	  individual	  scientists	  and	  laboratories	  <br/>
may	  be	  tempted	  to	  exploit	  lack	  of	  certainty	  by	  selecting	  modes	  of	  analysis	  that	  yield	  the	  <br/>
most	  ‘interesting’	  or	  publishable	  findings	  rather	  than	  those	  that	  are	  the	  most	  rigorous.	  <br/>
Another	  category	  is	  large-­‐scale	  community	  projects,	  such	  as	  the	  1KGP	  and	  the	  International	  <br/>
Wheat	  Genome	  Sequencing	  Consortium,	  that	  have	  relatively	  more	  resources	  and	  which	  <br/>
check	  all	  stages	  of	  the	  process	  in	  order	  to	  deliver	  a	  quality	  product	  that	  is	  expected	  to	  have	  <br/>
widespread	  future	  uses.	  <br/>
•&#160;&#160;Another	  variation	  that	  reflects	  community	  differences	  is	  the	  degree	  to	  which	  NGS	  datasets	  <br/>
are	  neatly	  packaged	  and	  stored,	  and	  when	  and	  whether	  they	  are	  made	  publicly	  available.	  <br/>
Large-­‐international	  community	  projects,	  notably	  1KGP,	  have	  an	  ‘aggressive’	  metadata<b>	  </b><br/>
standard	  and	  the	  resource,	  including	  at	  the	  key	  repository	  (SRA),	  to	  ensure	  they	  are	  ful&#160;y	  <br/>
documented,	  and	  a	  commitment	  to	  public	  deposition.	  Individual	  labs	  may	  only	  be	  <br/>
motivated	  to	  make	  their	  datasets	  publicly	  available	  in	  order	  to	  publish,	  and	  then	  have	  only	  <br/>
the	  time	  and	  resources	  to	  provide	  minimal	  metadata.	  Then	  there	  are	  the	  myriad	  <br/>
commercial	  NGS	  datasets	  that	  are	  privately	  held	  (but	  whose	  meaning	  and	  value	  can	  only	  be	  <br/>
realized	  through	  comparison	  with	  public	  datasets).	  <br/>
•&#160;&#160;Differences	  among	  uses	  and	  applications	  of	  NGS	  were	  also	  apparent	  in	  relation	  to	  notions	  of	  <br/>
trust	  regarding	  stewardship	  of	  datasets.	  Although	  Amazon	  Web	  Services	  currently	  stores	  a	  <br/>
number	  of	  publicly	  funded	  NGS	  datasets,	  including	  1KGP,	  can	  it	  be	  trusted	  with	  clinical	  <br/>
datasets,	  e.g.	  from	  the	  100,000	  Genome	  Project?	  <br/>
Trust&#160;&amp;&#160;Commercial&#160;Actors&#160;in&#160;the&#160;Ecosystem&#160;<br/>
•&#160;&#160;Commercial	  actors	  are	  integral<b>	  </b>to	  the	  NGS	  ecosystem,	  e.g.,	  as	  instrument	  and	  informatics	  <br/>
vendors,	  data	  service	  providers,	  and	  data	  storage	  providers.	  <br/>
•&#160;&#160;It	  was	  accepted	  as	  a	  matter	  of	  course	  that	  the	  source	  of	  data	  would	  be	  instruments	  that	  are	  <br/>
commercially	  produced	  and	  sold.	  This	  is	  something	  that	  genomic	  scientists	  –	  and	  scientists	  <br/>
43	  <br/>
	  <br/>
<hr/>
<a name=44></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
more	  generally	  –	  are	  accustomed	  to.	  Perhaps	  because	  of	  this,	  the	  centrality	  of	  instruments	  <br/>
did	  not	  seem	  to	  engender	  distrust	  of	  the	  instrument	  providers	  as	  threats	  to	  the	  supply	  of,	  or	  <br/>
access	  to,	  NGS	  data,	  or	  control	  over	  its	  analysis	  (cf	  the	  situation	  with	  respect	  to	  national	  <br/>
statistics).	  Commercial	  instruments	  and	  their	  providers	  (and	  commercial	  facilities	  that	  <br/>
operate	  them)	  are	  a	  familiar	  and	  accepted	  part	  of	  the	  NGS	  ecosystem.	  Moreover,	  NGS	  <br/>
practitioners	  are	  ful&#160;y	  in	  control	  of	  the	  samples	  (again	  compares	  with	  national	  statistics).	  <br/>
Historically	  they	  have	  been	  originators	  of	  the	  analytic	  algorithms	  (cf	  Google	  Analytics	  and	  <br/>
national	  statistics).	  However,	  some	  of	  quality	  control	  algorithms	  are	  built	  into	  the	  <br/>
instruments,	  and	  when	  these	  change	  so	  does	  the	  data!	  <br/>
•&#160;&#160;This	  trust	  of	  the	  NGS	  ecosystem	  was	  in	  contrast	  to	  the	  position	  of	  AWS	  (Amazon	  Web	  <br/>
Services)	  whose	  participation	  in	  the	  ecosystem	  as	  provider	  of	  data	  storage	  and	  analysis	  in	  <br/>
the	  cloud	  was	  not	  universally	  trusted	  -­‐	  although,	  as	  one	  participant	  questioned,	  why	  trust	  <br/>
Illumina	  and	  not	  AWS?	  Coming	  from	  a	  different	  context	  and	  a	  newcomer	  to	  academic	  and	  <br/>
clinical	  research,	  AWS	  was	  felt	  by	  some	  participants	  to	  lack	  ‘street	  credibility’,	  with	  much	  to	  <br/>
prove	  as	  a	  credible	  and	  trustworthy	  custodian	  of	  clinical	  data.	  <br/>
Middle Phase NGS&#160;<br/>
•&#160;&#160;There	  was	  a	  keen	  sense	  of	  periodicity<b>	  </b>from	  some	  of	  the	  speakers;	  that	  NGS	  is	  now	  in	  a	  <br/>
second,	  or	  middle	  phase	  –	  that	  there	  was	  an	  earlier	  period	  of	  genomics	  (‘Noah's	  Ark’)	  that	  <br/>
was	  different	  to	  the	  present,	  and	  a	  future	  phase	  that	  that	  is	  going	  to	  be	  different	  yet	  again.	  <br/>
This	  was	  expressed	  in	  various	  ways	  using	  a	  variety	  of	  metrics.&#160;<br/>
•&#160;&#160;Compared	  to	  the	  past,	  the	  present	  is	  marked	  by	  increasing	  numbers	  of	  genomes	  being	  <br/>
sequenced,	  and	  increasing	  volume	  of	  sequence	  data.	  We	  are	  in	  a	  different	  phase	  from	  the	  <br/>
‘Noah’s	  ark’	  period,	  when	  the	  big	  genome	  period	  studied	  just	  one	  of	  everything	  to	  using	  <br/>
NGS	  for	  testing	  hypotheses	  and	  experimentation.	  However,	  this	  is	  matched	  by	  falling	  costs	  <br/>
of	  sequencing	  and	  falling	  costs	  of	  data	  storage.	  &#160;Therefore,	  for	  NGS,	  according	  to	  one	  <br/>
speaker,	  the	  challenges	  of	  Volume	  and	  Velocity	  are	  a	  thing	  of	  the	  past.	  The	  challenge	  today	  <br/>
is	  Variety.&#160;<br/>
•&#160;&#160;Even	  the	  speaker	  who	  pointed	  out	  that	  the	  dramatic	  fall	  in	  sequencing	  costs	  was	  leveling	  <br/>
out,	  agreed	  that	  the	  cost	  bottleneck	  is	  no	  longer	  sequencing.	  The	  cost	  bottleneck	  today	  is	  <br/>
upstream	  and	  downstream	  of	  sequencing,	  and	  looking	  to	  the	  future,	  this	  is	  liable	  to	  be	  the	  <br/>
case	  even	  more	  so.	  Another	  third	  kind	  of	  uncertainty	  was	  in	  relation	  to	  costs,	  in	  particular	  <br/>
the	  costs	  of	  analytics.	  With	  the	  broadening	  of	  the	  applications	  of	  NGS	  from	  community	  <br/>
sequencing	  activities	  to	  testing	  hypotheses	  through	  experimentation,	  the	  costs	  of	  analysis	  <br/>
become	  more	  unknowable	  in	  advance	  as	  they	  attempt	  to	  decipher	  the	  complexities	  of	  living	  <br/>
systems.	  &#160;&#160;<br/>
•&#160;&#160;Whereas	  in	  the	  past,	  10-­‐15	  years	  ago,	  the	  human	  eye	  would	  pass	  over	  all	  of	  the	  data	  as	  <br/>
teams	  of	  people	  analysed	  it	  in	  depth,	  nowadays	  the	  data	  generated	  are	  never	  ful&#160;y	  <br/>
analysed.&#160;<br/>
•&#160;&#160;In	  terms	  of	  an	  &#160;‘innovation	  timeline’,	  the	  past	  was	  the	  ‘invention’	  phase;	  the	  present	  is	  the	  <br/>
‘development’	  phase,	  and	  the	  future	  is	  the	  ‘productisation’	  phase.&#160;<br/>
44	  <br/>
	  <br/>
<hr/>
<a name=45></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
Metrics&#160;<br/>Participants	  from	  different	  parts	  of	  the	  NGS	  ecosystem	  attend	  to	  different	  risks	  and	  <br/>uncertainties;	  they	  have	  different	  priorities;	  and	  they	  relate	  what	  they	  do	  to	  different	  metrics.	  <br/>These	  are	  apparent	  in	  the	  three	  ‘ideal’	  types	  that	  were	  initially	  identified	  by	  the	  project	  team	  <br/>prior	  to	  the	  col&#160;aboratory	  and	  then	  ‘mapped’	  onto	  the	  different	  organisations	  and	  practices.	  <br/>
•&#160;&#160;These	  are	  the	  practitioners	  involved	  with	  creating	  sequencing	  data	  and	  making	  it	  fit	  for	  <br/>
others	  to	  use.	  These	  practitioners	  are	  focused	  on	  the	  integrity	  of	  the	  sequence	  –	  that	  it	  is	  <br/>
accurate,	  in	  the	  right	  order,	  and	  that	  it	  is	  what	  it	  says	  it	  is,	  i.e.	  that	  the	  chain	  of	  custody	  is	  <br/>
secure.	  They	  are	  providing	  and	  curating	  and	  resource	  for	  others	  to	  use	  –	  either	  individual	  <br/>
clients	  or	  communities.	  <br/>
•&#160;&#160;BBSRC	  Genome	  Analysis	  Centre	  (TGAC)	  –	  turning	  samples	  into	  sequence	  -­‐	  generating	  <br/>
sequence	  as	  a	  service	  –	  samples	  come	  into	  TGAC,	  sequences	  go	  out.	  In	  between,	  the	  sample	  <br/>
goes	  through	  instruments.	  But	  the	  data	  that	  come	  out	  of	  the	  NGS	  instruments	  are	  in	  bits.	  Al&#160;	  <br/>
these	  bits	  have	  to	  be	  reassembled	  in	  as	  good	  as	  order	  as	  possible	  within	  the	  available	  <br/>
analytical	  and	  financial	  limits.	  Can	  they	  bring	  it	  all	  back	  together	  again?	  The	  speaker	  from	  <br/>
TGAC	  relates	  to	  metrics	  about	  species	  and	  their	  genomes	  (how	  big?	  how	  many	  repeats?)	  <br/>
and	  how	  best	  to	  package	  it	  for	  the	  instruments;	  and	  to	  metrics	  about	  the	  sequence	  data;	  <br/>
and	  metrics	  about	  analytics	  –	  N50	  and	  K-­‐mers.	  <br/>
•&#160;&#160;Centre	  for	  Genomic	  Research.	  Leads	  a	  lab	  that	  uses	  NGS	  data	  and	  instruments	  to	  address	  <br/>
biological	  questions,	  to	  test	  hypotheses.	  Is	  aware	  of	  instrument	  metrics	  –	  cost	  of	  <br/>
instruments,	  costs	  of	  sequencing,	  speed,	  read	  length.	  Is	  also	  aware	  of	  costs	  of	  sample	  <br/>
preparation	  and,	  in	  particular,	  the	  costs	  of	  analytics.	  These	  are	  the	  new	  bottlenecks.	  The	  <br/>
costs	  of	  analytics,	  in	  particular,	  is	  becoming	  increasingly	  unknown	  and	  unknowable	  in	  <br/>
advance.	  This	  source	  of	  uncertainty	  is	  increasing	  as	  NGS	  is	  used	  for	  purposes	  other	  than	  <br/>
sequencing,	  e.g.	  for	  doing	  biological	  experiments.	  Indeed,	  this	  source	  of	  uncertainty	  is	  a	  <br/>
reflection	  of	  the	  unknown	  complexities	  of	  biological	  systems	  compared	  to	  the	  relative	  <br/>
simplicity	  of	  the	  molecule	  DNA.	  <br/>
•&#160;&#160;These	  are	  the	  practitioners	  who	  use	  and	  apply	  data	  in	  novel	  ways.	  Further	  downstream,	  <br/>
arguably	  they	  deal	  with	  more	  unknowns	  and	  unknowables	  than	  classes	  A	  and	  C	  because	  <br/>
they	  are	  integrating	  data	  with	  other	  data	  and	  with	  biological,	  social	  and	  economic	  systems.	  <br/>
•&#160;&#160;Rare	  Diseases	  -­‐	  using	  NGS	  data	  to	  try	  to	  identify	  what	  causes	  rare	  diseases	  for	  knowledge	  <br/>
that	  can	  be	  used	  in	  clinical	  practice.	  &#160;On	  the	  hunt	  for	  genomic	  variation.	  But	  aware	  that	  <br/>
variation	  might	  not	  be	  real	  –	  it	  could	  be	  error.	  So	  uses	  very,	  very	  high	  stringencies	  that	  miss	  <br/>
things	  in	  the	  interests	  of	  only	  finding	  what’s	  real.	  And	  even	  if	  it	  is	  real,	  it	  might	  not	  be	  <br/>
biologically	  meaningful.	  Because	  of	  NGS	  as	  a	  unified	  way	  of	  studying	  them,	  rare	  diseases	  are	  <br/>
becoming	  common.	  By	  lumping	  rare	  diseases	  together	  as	  having	  a	  common	  cause	  –	  a	  <br/>
genetic	  basis	  detectable	  in	  the	  DNA	  –	  they	  are	  becoming	  a	  bigger	  number	  –	  even	  if	  they	  are	  <br/>
all	  different	  from	  each	  other.	  Balancing	  uncertainty	  and	  risk	  are	  key	  qualities	  to	  grapple	  <br/>
with.	  As	  a	  clinician,	  the	  key	  question	  is	  ‘Am	  I	  certain	  enough	  –	  are	  the	  data	  certain	  enough	  –	  <br/>
to	  sanction	  termination?	  <br/>
•&#160;&#160;Public	  Health	  Genomics	  –	  translating	  NGS	  into	  NHS.	  Here	  the	  metrics	  are	  expressed	  in	  terms	  <br/>
of	  costs	  and	  benefits.	  But	  the	  limits	  in	  time	  and	  space	  are	  hard	  to	  draw	  –	  whose	  costs?	  <br/>
45	  <br/>
	  <br/>
<hr/>
<a name=46></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
Whose	  benefits?	  When?	  And	  in	  relation	  to	  what?	  More	  questions	  than	  answers.	  Raises	  <br/>
questions	  rather	  than	  relating	  to	  metrics	  because	  the	  metrics	  are	  too	  hard	  to	  define	  as	  you	  <br/>
move	  further	  downstream	  to	  application,	  particularly	  clinical	  application.	  <br/>
•&#160;&#160;Eagle	  Genomics.	  Eagle	  uses	  publicly	  available	  NGS	  data	  to	  add	  value	  to	  /	  make	  sense	  of	  <br/>
private	  /	  commercial	  NGS	  data	  sets.	  Is	  not	  the	  volume	  or	  velocity	  of	  NGS	  data	  that	  is	  the	  <br/>
challenge;	  it	  is	  its	  heterogeneity.	  <br/>
•&#160;&#160;These	  are	  the	  practitioners	  who	  are	  concerned	  with	  the	  bulk	  handling	  and	  warehousing	  of	  <br/>
data,	  with	  making	  it	  available	  and	  discoverable	  for	  community	  use	  and	  providing	  the	  means	  <br/>
to	  access	  and	  work	  with	  it.	  <br/>
•&#160;&#160;EMBL	  –	  EBI	  Resequencing	  Informatics.	  Processes	  the	  datasets	  from	  large	  scale	  community	  <br/>
projects.	  Is	  focused	  on	  projects	  and	  their	  resultant	  datasets.	  Is	  a	  quality-­‐control	  operation.	  <br/>
Wants	  to	  scrutinise	  the	  quality	  of	  the	  stuff	  that	  is	  going	  to	  be	  put	  in	  the	  warehouse	  before	  it	  <br/>
is	  distributed.	  &#160;What	  is	  their	  quantity	  –	  how	  many	  genomes,	  how	  many	  Nbytes?	  What	  is	  <br/>
their	  quality	  –	  do	  they	  make	  sense	  biologically,	  what	  virtual	  analyses	  can	  we	  do	  to	  test	  this?	  <br/>
Are	  they	  what	  they	  say	  they	  are	  -­‐	  their	  identity?	  &#160;What	  is	  their	  consistency	  with	  other	  kinds	  <br/>of	  data?	  <br/>
•&#160;&#160;European	  Nucleotide	  Archive	  –	  responsible	  to	  submitters	  and	  users	  of	  the	  SRA	  /	  ENA.	  Is	  <br/>
concerned	  with	  discoverability	  and	  accessibility	  of	  data.	  Tension	  between	  obligation	  to	  <br/>
receive	  and	  archive	  everything	  and	  dealing	  with	  the	  challenges	  this	  presents	  in	  terms	  of	  <br/>
quantity	  and	  quality	  –	  and	  how	  this	  impinges	  on	  discoverability.	  Focus	  is	  on	  the	  qualities	  of	  <br/>
submissions	  –	  this	  is	  the	  key	  unit	  of	  analysis?	  Looks	  at	  doubling	  rates.	  Metrics	  that	  do	  <b>not	  </b><br/>
feature	  here	  are	  number	  of	  repeats,	  speed	  and	  cost	  of	  sequencing.	  <br/>
•&#160;&#160;Amazon	  Web	  Services	  –	  provides	  a	  space	  where	  people	  –	  customers	  –	  can	  store	  and	  analyse	  <br/>
their	  data.	  Is	  about	  its	  ‘instances’	  whose	  qualities	  are	  computational.	  The	  data	  are	  <br/>
<i>containerized</i>.	  Black	  boxes.	  –	  Nothing	  biological	  about	  the	  metrics	  that	  this	  speaker	  uses.	  <br/>
The	  black	  boxes	  could	  contain	  anything?	  Metrics	  are	  size	  and	  cost	  and	  speed	  and	  flexibility.	  <br/>
Size	  is	  not	  a	  problem.	  Nor	  is	  speed.	  Nor	  is	  cost	  if	  you	  buy	  your	  space	  in	  the	  cloud	  far	  enough	  <br/>
in	  advance.	  <br/>
	  <br/>
	  <br/>
	  <br/>
	  <br/>
	  <br/>
	  <br/>
46	  <br/>
	  <br/>
<hr/>
<a name=47></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
<b>Collaboratory&#160;2:&#160;Official&#160;Statistics&#160;&#160;<br/></b>One	  consensus	  emerging	  from	  the	  workshop	  was	  that	  this	  is	  an	  uncertain	  time	  and	  to	  what	  <br/>extent	  Big	  Data	  (BD)	  sources	  wil&#160;	  be	  used	  to	  replace,	  supplement	  or	  verify	  official	  statistics	  is	  yet	  <br/>to	  be	  seen.	  Al&#160;	  scenarios	  have	  potential	  risks	  as	  they	  raise	  fundamental	  questions	  about	  the	  <br/>substance	  and	  meaning	  of	  what	  is	  measured,	  captured	  and	  counted	  and	  in	  turn	  what	  comes	  to	  <br/>matter	  and	  count	  as	  official	  statistics.	  Some	  of	  those	  risks	  are	  perhaps	  a	  result	  of	  often-­‐implicit	  <br/>normative	  assumptions	  about	  BD	  sources	  and	  what	  they	  are	  measuring.	  By	  unpacking	  some	  <br/>implicit	  assumptions	  those	  risks	  can	  perhaps	  be	  identified	  and	  debated,	  which	  is	  something	  that	  <br/>ideally	  should	  happen	  at	  this	  deliberative	  and	  experimental	  stage.	  <br/>
Generally	  the	  risks	  pertain	  to	  what	  we	  could	  call	  the	  qualities	  of	  data,	  measurement	  and	  what	  is	  <br/>valued,	  which	  tend	  to	  get	  obscured	  perhaps	  because	  of	  the	  focus	  on	  questions	  of	  data	  volume	  <br/>and	  analytics.	  Fol&#160;owing	  the	  workshop	  three	  themes	  posed	  as	  questions	  arising	  from	  the	  <br/>presentations	  and	  discussions	  were	  identified	  and	  shared	  with	  the	  participating	  statisticians:	  <br/>
1.&#160;&#160;What	  is	  measured	  is	  what	  is	  valued?	  <br/>
2.&#160;&#160;What	  people	  do	  but	  not	  what	  they	  say?	  <br/>
3.&#160;&#160;Privacy	  and	  confidentiality	  but	  wither	  ethics	  and	  consent?	  <br/>
	  <br/>
Through	  written	  responses	  and	  conversations	  at	  subsequent	  meetings	  and	  events	  it	  was	  agreed	  <br/>that	  these	  themes	  covered	  the	  meta-­‐level	  issues	  and	  controversies	  raised	  at	  the	  col&#160;aboratory.	  <br/>Specific	  feedback	  on	  was	  annotated	  below	  and	  gives	  a	  flavour	  of	  the	  iterative	  process	  adopted	  <br/>in	  this	  col&#160;aboratory	  (<i>noted	  in	  italics;	  bul&#160;et	  points	  indicate	  comments	  from	  different	  people</i>).	  <br/>Additional	  themes	  were	  also	  added	  that	  address	  other	  issues	  and	  dilemmas	  arising	  from	  these	  <br/>questions:	  <br/>
4.&#160;&#160;Improving	  processes	  rather	  than	  producing	  outputs?	  <br/>
5.&#160;&#160;Not	  just	  methods	  but	  a	  change	  in	  organisational	  cultures	  and	  thinking?	  <br/>
a.&#160;&#160;Data	  science	  is	  not	  a	  person	  but	  a	  distributed	  set	  of	  skil&#160;s?	  <br/>
b.&#160;&#160;From	  NSI-­‐lead	  to	  col&#160;ectivised	  processes	  of	  innovation?	  <br/>
6.&#160;&#160;A	  new	  statistical	  leadership	  role	  for	  NSIs?	  <br/>
	  <br/>
1.&#160;What&#160;is&#160;measured is what is valued?&#160;&#160;<br/>BD	  sources	  change	  what	  we	  measure	  and	  then	  value.	  What	  is	  counted	  and	  counts	  is	  driven	  by	  <br/>what	  data	  is	  available	  and	  not	  only	  or	  necessarily	  by	  the	  questions	  posed	  and	  classifications	  <br/>imposed	  by	  statisticians	  or	  others.	  Does	  this	  mean	  that	  what	  is	  measured	  is	  more	  reactively	  <br/>than	  actively	  defined?	  If	  the	  answer	  is	  yes,	  then	  this	  potentially	  has	  policy	  implications.	  One	  can	  <br/>imagine,	  for	  example,	  that	  the	  issues,	  concerns	  and	  priorities	  of	  governing	  could	  be	  influenced	  <br/>and	  driven	  by	  the	  kinds	  of	  data	  organised	  and	  configured	  by	  others,	  most	  significantly,	  <br/>
47	  <br/>
	  <br/>
<hr/>
<a name=48></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
commercial	  operators.	  Do	  ‘others’	  such	  as	  commercial	  operators	  then	  become	  more	  important	  <br/>players	  in	  determining	  what	  comes	  to	  be	  measured	  and	  then	  valued?	  <br/>
•&#160;&#160;<i>The	  private	  sector	  has	  moved	  ahead	  of	  us	  and	  we	  are	  behind.	  Industry	  operators	  such	  as	  </i><br/>
<i>Google	  are	  investing	  more	  in	  Big	  Data	  than	  NSIs	  and	  attracting	  the	  best	  people	  from	  </i><br/>
<i>around	  the	  world.	  </i><br/>
•&#160;&#160;<i>At	  the	  same	  time,	  to	  work	  with	  BD	  requires	  establishing	  new	  partnerships	  outside	  of	  </i><br/>
<i>statistics	  and	  especial&#160;y	  working	  with	  data	  owners,	  researchers	  and	  different	  user	  </i><br/>
<i>groups.	  In	  other	  words,	  it	  is	  not	  possible	  to	  work	  separately	  from	  and	  competitively	  with	  </i><br/>
<i>the	  private	  sector	  but	  instead	  find	  new	  ways	  of	  working	  in	  partnership.	  </i><br/>
	  <br/>
Do	  those	  issues	  and	  phenomena	  that	  are	  most	  easily	  and	  readily	  compiled	  digitally	  become	  key	  <br/>drivers	  of	  what	  then	  is	  measured	  and	  valued?	  <br/>
•&#160;&#160;<i>These	  inquiries	  seem	  to	  question	  the	  role	  of	  Official	  Statistics.	  I	  would	  indeed	  reformulate	  </i><br/>
<i>them	  in	  a	  different	  way,	  namely:	  Official	  Statistics	  is	  what	  policy	  makers	  need,	  because	  it	  </i><br/>
<i>provides	  the	  guarantees	  necessary	  to	  make	  good	  and	  responsible	  decisions.	  However,	  </i><br/>
<i>BD	  can	  further	  improve	  Official	  Statistics	  in	  terms	  of	  timeliness	  and	  new	  phenomena	  that	  <br/>can	  be	  studied.	  Here,	  BD	  plays	  the	  major	  role	  with	  respect	  to	  Official	  Statistics,	  and	  not	  </i><br/>
<i>giving	  over	  to	  the	  possibility	  that	  other	  players	  could	  replace	  Official	  Statistics.	  </i><br/>
•&#160;&#160;<i>Companies	  are	  being	  driven	  by	  data	  push	  and	  we	  can	  learn	  from	  them:	  &#160;instead	  of	  </i><br/>
<i>searching	  for	  an	  answer	  in	  a	  data	  set	  (data	  pul&#160;),	  start	  with	  data	  and	  see	  what	  questions	  </i><br/>
<i>you	  might	  be	  able	  to	  ask	  (data	  push).	  </i><br/>
•&#160;&#160;<i>Not	  only	  does	  data	  drive	  what	  is	  measured	  but	  so	  too	  does	  it	  depend	  on	  the	  available	  </i><br/>
<i>technologies.	  </i><br/>
<i>	  </i><br/>
A	  related	  question	  is	  that	  BD	  sources	  are	  often	  cited	  as	  being	  less	  resource-­‐intensive	  and	  less	  <br/>costly	  and	  that	  these	  are	  key	  drivers	  for	  taking	  up	  these	  sources	  especially	  at	  a	  time	  of	  budget	  <br/>cuts.	  At	  the	  same	  time,	  the	  ‘actual’	  costs	  of	  using	  BD	  sources	  at	  present	  and	  into	  the	  future	  are	  <br/>unknown	  given	  that	  industry	  providers	  own	  much	  of	  this	  data	  and	  rigorous	  use	  of	  these	  sources	  <br/>for	  official	  statistics	  may	  wel&#160;	  require	  purchasing	  data.	  So	  cost	  is	  both	  a	  driver	  of	  what	  is	  <br/>measured	  and	  also	  a	  source	  of	  economic	  uncertainty	  and	  vulnerability.	  <br/>
These	  questions	  are	  connected	  to	  the	  ‘new’	  and	  novel	  in	  what	  BD	  sources	  measure	  and	  count	  <br/>which	  needs	  to	  be	  specified	  rather	  than	  assumed.	  Given	  the	  variety	  of	  sources—from	  search	  <br/>engine	  queries	  to	  social	  media	  messages	  and	  mobile	  phone	  usage—what	  is	  being	  measured	  <br/>and	  its	  relation	  to	  previous	  forms	  of	  measurement	  are	  diverse.	  &#160;Thus	  while	  BD	  is	  usually	  <br/>reduced	  to	  a	  notion	  of	  some	  kind	  of	  generic	  ‘data’	  we	  know	  that	  not	  all	  data	  is	  the	  same.	  <br/>Towards	  thinking	  about	  this,	  here	  are	  some	  suggested	  ways	  of	  thinking	  about	  what	  are	  ‘old’	  <br/>and	  ‘new’	  measures:&#160;<br/>
48	  <br/>
	  <br/>
<hr/>
<a name=49></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
1.&#160;&#160;<i>New	  phenomena	  and	  new	  measures?</i>	  Information	  and	  communication	  technologies	  <br/>
generate	  new	  relations,	  practices	  and	  phenomena	  that	  are	  now	  also	  the	  object	  of	  <br/>
measurement	  such	  as	  ICT	  usage,	  which	  for	  example	  has	  become	  a	  measure	  of	  an	  <br/>
‘information	  society.’	  &#160;Here	  both	  social	  relations	  (how	  people	  interact	  and	  communicate	  for	  <br/>
example)	  as	  wel&#160;	  as	  the	  measurement	  of	  society	  are	  simultaneously	  changing	  and	  being	  <br/>
done	  together.	  &#160;A	  good	  example	  of	  this	  is	  the	  medium-­‐specific	  elements	  of	  a	  platform;	  for	  <br/>
Twitter	  this	  includes	  retweets	  and	  hashtags	  that	  organise	  associations	  and	  social	  networks	  <br/>
in	  new	  and	  novel	  ways	  and	  also	  open	  up	  those	  networks	  to	  data	  analysis.	  <br/>
2.&#160;&#160;<i>One	  phenomenon	  for	  another?</i>	  Some	  forms	  of	  measurement	  are	  becoming	  more	  relevant	  <br/>
than	  others	  in	  part	  because	  of	  the	  characteristics	  of	  a	  source	  and	  the	  volume	  of	  data.	  &#160;A	  <br/>
good	  example	  of	  this	  is	  Twitter,	  where	  sentiment	  analysis	  could	  potentially	  replace	  opinion	  <br/>
surveys.	  &#160;What	  is	  the	  difference	  between	  sentiments	  and	  opinions	  and	  does	  this	  matter?	  <br/>
Perhaps	  (as	  suggested	  in	  the	  second	  theme	  below)	  sentiment	  is	  not	  a	  quality	  that	  is	  <br/>
intentionally	  conveyed	  but	  read-­‐off	  of	  messages	  and	  presumed.	  There	  is	  a	  long	  history	  <br/>
behind	  the	  acceptance	  of	  opinion	  research	  as	  a	  ‘real	  existing’	  social	  phenomenon	  that	  can	  <br/>be	  measured;	  can	  the	  same	  be	  said	  of	  sentiment?	  <br/>
3.&#160;&#160;<i>Old	  phenomena	  and	  new	  measures</i>?	  Some	  BD	  concern	  phenomena	  that	  could	  not	  be	  <br/>
practically	  measured	  very	  wel&#160;	  or	  at	  all	  in	  the	  past	  such	  as	  the	  spread	  of	  rumours	  or	  the	  <br/>
purchasing	  intentions	  of	  consumers	  or	  the	  movement	  and	  travel	  patterns	  of	  tourists.	  Here,	  <br/>
what	  previously	  was	  not	  is	  now	  rendered	  measurable.	  Do	  such	  phenomena	  become	  <br/>
‘elevated’	  and	  promoted	  as	  relevant	  and	  those	  that	  remain	  ‘old’	  and	  unmeasurable	  (e.g.,	  <br/>
rationalities)	  remain	  obscure?	  <br/>
4.&#160;&#160;<i>New	  phenomena	  and	  old	  measures?</i>	  BD	  sources,	  in	  part	  because	  they	  are	  unstructured,	  <br/>
contain	  what	  is	  sometimes	  referred	  to	  as	  noise	  or	  excessive	  content	  that	  needs	  to	  be	  <br/>
cleaned	  or	  reduced.	  Implicit	  in	  this	  evaluation	  is	  that	  what	  is	  of	  value	  is	  that	  which	  is	  <br/>
recognisable	  according	  to	  existing	  frames	  and	  understandings.	  &#160;Fol&#160;owing	  from	  (1)	  above,	  <br/>
perhaps,	  the	  content	  of	  BD	  sources	  reflects	  an	  incongruity	  between	  existing	  categories	  and	  <br/>
classifications	  and	  the	  kinds	  of	  phenomena	  generated	  or	  registered	  by	  a	  platform.	  &#160;	  <br/>
•&#160;&#160;<i>Instead	  of	  talking	  about	  an	  incongruity	  between	  BD	  and	  the	  Official	  Statistics	  </i><br/>
<i>framework	  (design	  metadata,	  classification,	  etc.),	  I	  would	  stress	  the	  fact	  that	  in	  </i><br/>
<i>Official	  Statistics	  you	  first	  ‘design	  and	  then	  ‘col&#160;ect’,	  with	  BD,	  instead,	  you	  first	  </i><br/>
<i>‘col&#160;ect’	  and	  then	  ‘design’.	  So,	  in	  a	  sense,	  a	  completely	  different	  ‘process.’	  </i><br/>
<i>	  <br/>This	  incongruity	  is	  not	  a	  unique	  condition	  of	  BD	  sources;	  other	  methods	  generate	  </i><br/>
<i>data	  that	  fal&#160;	  ‘outside’	  of	  imposed	  classification	  schemes	  and	  while	  sometimes	  </i><br/>
<i>excluded	  at	  other	  times	  these	  have	  changed	  classifications.	  &#160;This	  is	  evident	  in	  the	  </i><br/>
<i>assertion	  of	  new	  categories	  in	  a	  survey	  or	  census	  as	  in	  the	  case	  of	  the	  Jedi	  religion	  in	  </i><br/>
<i>the	  UK	  census.	  </i><br/>
<i>Instead	  of	  reproducing	  results	  compiled	  by	  methods	  such	  as	  surveys,	  is	  the	  issue	  then	  </i><br/>
<i>that	  BD	  measures	  phenomena	  that	  do	  not	  correspond	  with	  ‘old’	  measures	  and	  so	  </i><br/>
<i>instead	  of	  comparing	  the	  chal&#160;enge	  is	  to	  innovate	  new	  measures	  of	  society?	  Official	  </i><br/>
<i>statistics	  begin	  with	  ‘perfect’	  classifications	  –	  is	  it	  now	  the	  other	  way	  around	  </i><br/>
<i>whereby	  the	  issue	  is	  how	  to	  create	  new	  classifications	  that	  fit	  with	  BD	  sources?	  For	  </i><br/>
49	  <br/>
	  <br/>
<hr/>
<a name=50></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
<i>example,	  the	  UN	  Global	  Pulse	  initiative	  analyses	  Twitter	  for	  signals	  of	  distress	  rather	  </i><br/>
<i>than	  attempting	  to	  make	  meaning	  of	  the	  messages.	  Distress	  is	  identified	  as	  an	  </i><br/>
<i>anomaly	  in	  a	  regularised	  pattern	  of	  sentiment	  internal&#160;y	  constituted	  via	  the	  platform.	  </i><br/>
•&#160;&#160;<i>Users	  of	  Official	  Statistics	  are	  familiar	  with	  traditional	  and	  longstanding	  measures.	  </i><br/>
<i>Big	  Data	  sources	  introduce	  new	  kinds	  of	  measures	  such	  as	  signals	  and	  indicators	  of	  <br/>change	  that	  are	  also	  timelier	  (e.g.,	  UN	  Global	  Pulse).	  &#160;Official	  Statistics,	  whether	  from	  </i><br/>
<i>admin	  data,	  surveys	  or	  censuses,	  cannot	  match	  this;	  at	  the	  same	  time,	  signals	  and	  </i><br/>
<i>indicators	  cannot	  provide	  the	  quality,	  consistency,	  depth	  and	  trust	  that	  Official	  </i><br/>
<i>Statistics	  can.	  &#160;It	  is	  thus	  perhaps	  a	  question	  of	  the	  complementarity	  between	  these	  </i><br/>
<i>two	  sources	  rather	  than	  a	  question	  of	  one	  or	  the	  other.	  &#160;One	  criterion	  of	  assessment,	  </i><br/>
<i>which	  is	  central	  to	  the	  purposes	  of	  Official	  Statistics,	  is	  to	  assess	  the	  extent	  to	  which	  </i><br/>
<i>a	  particular	  kind	  of	  BD	  is	  useful	  for	  decision-­‐making	  purposes	  and	  policy	  evaluation.	  </i><br/>
•&#160;&#160;<i>There	  is	  a	  need	  to	  chal&#160;enge	  the	  assumption	  about	  what	  BD	  versus	  Official	  Statistics	  </i><br/>
<i>measure.	  Instead,	  why	  not	  start	  with	  what	  are	  the	  important	  questions	  and	  problems	  </i><br/>
<i>today	  and	  what	  data	  can	  answer	  these?	  &#160;Can	  phrase	  this	  as	  ‘if	  Official	  Statistics	  can’t	  <br/>answer	  questions	  that	  matter	  then	  they	  wil&#160;	  not	  be	  relevant.’	  &#160;And	  this	  includes	  </i><br/>
<i>timeliness—some	  questions	  need	  faster	  answers.	  </i><br/>
•&#160;&#160;<i>If	  you	  deal	  with	  these	  issues	  as	  output	  problems	  and	  evaluate	  them	  in	  relation	  to	  </i><br/>
<i>existing	  measures,	  then	  you	  wil&#160;	  always	  end	  up	  back	  with	  your	  own	  source	  and	  </i><br/>
<i>method.	  &#160;That	  is,	  BD	  cal&#160;s	  for	  not	  applying	  existing	  methods	  and	  adhering	  to	  the	  </i><br/>
<i>same	  tests	  of	  validity	  and	  quality.	  </i><br/>
•&#160;&#160;<i>At	  the	  same	  time,	  Official	  Statistics	  can	  serve	  the	  role	  of	  providing	  a	  benchmark	  to	  </i><br/>
<i>test	  new	  sources	  against	  and	  that	  is	  potential&#160;y	  an	  important	  value.</i>	  <br/>
	  <br/>
5.&#160;&#160;<i>From	  snapshots	  to	  societies	  in	  process</i>?	  Much	  is	  said	  about	  the	  timeliness	  of	  BD	  as	  a	  positive	  <br/>
quality.	  At	  the	  same	  time	  instabilities,	  discontinuities	  and	  uncertainties	  about	  BD	  data	  <br/>
sources	  over	  time	  are	  identified	  as	  a	  threat	  to	  time	  series	  types	  of	  analysis.	  Yet	  there	  is	  also	  <br/>
recognition	  that	  BD	  is	  more	  immediate	  and	  this	  immediacy	  is	  one	  quality	  that	  is	  valued.	  <br/>
What	  then	  are	  the	  implications	  for	  decision-­‐making?	  &#160;Does	  decision-­‐making	  become	  based	  <br/>
more	  on	  what	  is	  happening	  now,	  on	  societies	  in-­‐the-­‐making	  rather	  than	  on	  snapshots	  of	  <br/>
today/yesterday	  and	  change?	  <br/>
•&#160;&#160;<i>Coming	  at	  this	  question	  from	  another	  vantage	  point	  is	  that	  this	  suggests	  stabilising	  </i><br/>
<i>statistics	  based	  on	  existing	  and	  approved	  methodologies.	  How	  can	  this	  be	  done	  in	  a	  </i><br/>
<i>world	  that	  is	  becoming	  more	  agile	  and	  flexible?	  It	  is	  not	  possible.	  &#160;New	  paradigms	  </i><br/>
<i>and	  methodologies	  are	  required.	  </i><br/>
	  <br/>
2. What people do&#160;but not what they say they do?&#160;&#160;<br/>BD	  sources	  signal	  a	  move	  from	  data	  provided	  by	  respondents	  to	  that	  generated	  as	  a	  byproduct	  <br/>of	  what	  they	  do.	  &#160;That	  is,	  through	  methods	  such	  as	  surveys	  and	  interviews	  respondents	  can	  <br/>choose	  how	  and	  what	  to	  inform	  about	  themselves.	  The	  same	  does	  not	  hold	  for	  their	  digital	  <br/>traces	  and	  how	  those	  traces	  may	  ‘speak’	  for	  them.	  &#160;	  <br/>
50	  <br/>
	  <br/>
<hr/>
<a name=51></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
Ostensibly,	  one	  reason	  byproduct	  data	  is	  deemed	  valuable	  is	  because	  it	  reduces	  ‘respondent	  <br/>burden’,	  which	  in	  part	  is	  reflected	  in	  declining	  response	  rates.	  But,	  as	  raised	  a	  few	  times	  in	  the	  <br/>discussions,	  respondent	  data	  is	  not	  the	  same	  as	  byproduct	  data.	  The	  former	  is	  stated	  and	  <br/>measures	  a	  response	  and	  the	  latter	  is	  a	  register	  of	  &#160;behaviour.	  The	  latter	  more	  strongly	  apply	  to	  <br/>online	  BD	  sources	  but	  arguably	  could	  also	  hold	  for	  administrative	  sources,	  which	  are	  the	  <br/>byproduct	  of	  administrative	  transactions	  and	  not	  intended	  for	  statistical	  purposes.	  Here	  are	  <br/>some	  possible	  implications	  of	  these	  differences	  for	  further	  discussion.	  <br/>
1.&#160;&#160;<i>The	  respondent</i>.	  Much	  has	  been	  said	  about	  problems	  of	  respondent	  memory,	  the	  accuracy	  <br/>
of	  self-­‐reporting	  and	  the	  problems	  of	  non-­‐response	  bias.	  That	  is,	  people	  are	  not	  always	  <br/>
cooperative,	  reliable	  and	  responsive.	  But	  rather	  than	  resolving	  these	  issues	  do	  BD	  sources	  <br/>
just	  shift	  and	  redistribute	  the	  ‘problem’	  of	  the	  respondent?	  &#160;Users	  of	  online	  platforms	  or	  <br/>
administrative	  clients	  are	  not	  necessarily	  more	  reliable,	  accurate	  and	  responsive.	  &#160;People	  <br/>
can	  modify	  their	  behaviour	  and	  use	  of	  platforms,	  opt	  in	  and	  out	  of	  location	  services	  to	  avoid	  <br/>
or	  prevent	  detection,	  and	  create	  several	  versions	  of	  themselves	  through	  multiple	  devices	  or	  <br/>
profiles.	  	  <br/>
•&#160;&#160;<i>The	  failure	  of	  Google	  Flu	  Trends	  to	  predict	  trends	  in	  flu	  cases	  is	  a	  good	  example.	  Over	  </i><br/>
<i>time	  it	  became	  less	  reliable	  because	  people’s	  behaviour	  changed.	  &#160;Google	  cal&#160;ed	  this	  </i><br/>
<i>‘feedback’	  &#160;-­‐	  people	  reading	  about	  Google	  flu	  trends,	  googling	  about	  this	  and	  </i><br/>
<i>because	  of	  the	  autosuggest	  feature	  of	  the	  algorithm	  their	  googling	  contributed	  to	  </i><br/>
<i>the	  trend	  leading	  to	  an	  over-­‐estimate</i>.	  <br/>
	  <br/>
Thus	  there	  are	  many	  complications	  surrounding	  the	  ‘who’	  is	  the	  data	  about	  such	  that	  non-­‐<br/>
humans	  also	  become	  a	  consideration—is	  a	  data	  trace	  a	  measure	  of	  the	  behaviour	  of	  a	  <br/>
device	  (car,	  mobile	  phone,	  computer,	  scanner,	  sensor),	  platform	  (social	  media,	  browser),	  <br/>
algorithm	  (search	  engine,	  bot)	  or	  person	  (purchaser,	  browser,	  tweeter)?	  <br/>
Finally,	  does	  it	  matter	  for	  policy	  whether	  data	  is	  intentionally	  provided	  via	  people	  reporting	  <br/>
or	  being	  asked	  versus	  their	  behaviour	  being	  known	  via	  tracing	  and	  tracking?	  <br/>
2.&#160;&#160;<i>Causality	  and	  meaning	  making</i>.	  	  With	  the	  promotion	  of	  behaviour,	  ‘deeper’	  questions	  such	  <br/>
as	  why	  people	  do	  what	  they	  do	  and	  the	  meaning	  of	  what	  they	  do	  are	  potentially	  demoted.	  <br/>
Some	  insight	  about	  this	  could	  perhaps	  be	  gleaned	  by	  explaining	  what	  seems	  like	  the	  <br/>
(uncanny)	  correspondence	  between	  survey	  results	  on	  consumer	  confidence	  and	  Google	  <br/>
trends	  or	  between	  a	  migration	  survey	  and	  Google	  trends.	  &#160;Is	  this	  correspondence	  a	  <br/>
validation	  of	  survey	  results?	  Or	  is	  it	  a	  classic	  example	  of	  a	  spurious	  correlation?	  Are	  these	  <br/>
two	  methods	  measuring	  the	  same	  phenomenon/	  behaviour	  or	  is	  the	  correspondence	  a	  <br/>
measure	  of	  a	  common	  trend	  between	  two	  different	  phenomena/behaviours?	  Is	  this	  an	  <br/>
indication	  of	  the	  move	  away	  from	  a	  concern	  with	  causality	  and	  towards	  more	  pattern	  <br/>
analysis?	  <br/>
	  <br/>
51	  <br/>
	  <br/>
<hr/>
<a name=52></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
3.&#160;&#160;<i>Representativeness	  of	  the	  data</i>.	  The	  questions	  of	  what	  and	  who	  is	  a	  BD	  source	  is	  measuring	  <br/>
also	  extends	  to	  questions	  of	  representativeness.	  Much	  statistical	  work	  in	  the	  past	  has	  <br/>
attended	  to	  this	  question	  to	  ensure	  that	  results	  are	  not	  biased	  towards	  particular	  groups	  in	  <br/>
a	  society.	  Since	  socio-­‐demographics	  are	  typically	  not	  attached	  to	  many	  BD	  sources,	  then	  <br/>
what	  can	  be	  said	  about	  who	  is	  being	  measured	  and	  included?	  Rather	  than	  society,	  do	  BD	  <br/>
sources	  measure	  users	  of	  platform	  such	  as	  Twitter	  and	  Google?	  <br/>
•&#160;&#160;<i>This	  is	  less	  an	  issue	  when	  doing	  time	  series	  analyses	  for	  identifying	  change.	  Though	  </i><br/>
<i>this	  kind	  of	  analysis	  is	  self-­‐referential	  -­‐	  the	  population	  covered	  results	  in	  a	  pattern	  </i><br/>
<i>and	  when	  that	  pattern	  changes	  over	  time	  then	  this	  is	  a	  ‘signal’	  that	  something	  new	  is	  </i><br/>
<i>happening	  within	  that	  population.	  However,	  what	  of	  populations	  not	  included	  (since	  </i><br/>
<i>people	  are	  self	  selecting	  on	  a	  platform)	  in	  the	  time	  series	  and	  which	  cannot	  be	  </i><br/>
<i>identified	  due	  to	  privacy	  issues?	  &#160;If	  they	  were,	  would	  the	  pattern	  be	  different?	  &#160;Over	  </i><br/>
<i>time	  is	  the	  same	  population	  being	  measured?	  </i><br/>
	  <br/>
3.&#160;Privacy&#160;and&#160;confidentiality&#160;but wither ethics and&#160;consent?&#160;&#160;<br/>Historically	  and	  increasingly	  so,	  NSIs	  and	  their	  governments	  have	  made	  great	  efforts	  to	  ensure	  <br/>that	  the	  privacy	  and	  confidentiality	  of	  individual	  data	  are	  secured.	  A	  variety	  of	  techniques	  and	  <br/>rationalities	  have	  been	  used	  to	  do	  this	  such	  as	  anonymisation	  and	  protections	  against	  <br/>disclosure.	  Additionally,	  privacy	  is	  said	  to	  be	  secured	  when	  the	  object	  of	  concern	  is	  trends,	  <br/>patterns	  and	  aggregates	  rather	  than	  the	  details	  and	  specificities	  of	  individuals.	  Finally,	  practices	  <br/>of	  reusing	  data	  are	  said	  to	  be	  less	  intrusive	  and	  thus	  more	  respectful	  of	  privacy.	  These	  <br/>arguments	  implicitly	  assume	  that	  ethical	  concerns	  are	  principally	  about	  the	  identification	  of	  <br/>individuals.	  &#160;However,	  should	  ethical	  concerns	  also	  extend	  to	  questions	  of	  consent	  and	  intent?	  <br/>
•&#160;&#160;<i>There	  are	  also	  potential	  group	  privacy	  effects	  that	  cannot	  be	  resolved	  by	  the	  </i><br/>
<i>anonymisation	  of	  individuals.	  That	  is,	  even	  with	  individual	  privacy	  secured	  there	  are	  </i><br/>
<i>implications	  for	  the	  identification	  of	  groups	  who	  then	  can	  become	  the	  targets	  of	  </i><br/>
<i>policies.	  </i><br/>
•&#160;&#160;<i>Transparent	  use	  is	  one	  possible	  response.	  That	  is,	  treating	  al&#160;	  data	  as	  personal	  and	  </i><br/>
<i>thus	  applying	  the	  same	  protections	  no	  matter	  what	  the	  source	  is	  another</i>.	  	  <br/>
	  <br/>
These	  issues	  are	  also	  matters	  of	  concern	  to	  academic	  researchers	  who	  question	  the	  ethics	  of	  <br/>presuming	  that	  because	  data	  is	  generated	  in	  the	  ‘public’	  space	  of	  the	  internet,	  the	  consent	  of	  <br/>subjects	  is	  not	  required.	  For	  official	  statistics	  this	  potentially	  becomes	  more	  complicated	  if	  <br/>digital	  traces	  are	  used	  for	  or	  influence	  public	  policy	  decision-­‐making.	  Again	  the	  comparison	  to	  <br/>other	  methods	  is	  useful	  here.	  &#160;When	  respondents	  give	  an	  answer	  to	  a	  government	  survey	  or	  <br/>census	  questionnaire	  they	  are	  aware	  that	  this	  data	  wil&#160;	  likely	  be	  used	  for	  public	  policy	  purposes.	  <br/>The	  same	  cannot	  be	  said	  for	  BD	  sources.	  The	  intent	  of	  a	  user’s	  engagement	  with	  a	  social	  media	  <br/>platform	  is	  to	  communicate,	  be	  social	  or	  get	  information	  and	  not	  to	  serve	  the	  governmental	  (or	  <br/>
52	  <br/>
	  <br/>
<hr/>
<a name=53></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
research)	  purposes	  of	  others.	  &#160;Is	  one	  implication	  that	  the	  active	  involvement	  of	  respondents	  in	  <br/>shaping	  or	  influencing	  the	  evidence-­‐base	  of	  policy	  is	  undermined	  by	  the	  use	  of	  BD	  sources?	  <br/>
Because	  of	  the	  issues	  of	  privacy	  and	  ethics,	  might	  BD	  sources	  be	  leveraged	  more	  for	  measuring	  <br/>things—traffic,	  cars,	  crops,	  water,	  or	  prices—rather	  than	  people—tweets,	  messages,	  profiles	  or	  <br/>searches?	  <br/>
•&#160;&#160;<i>We	  do	  agree	  that	  we	  are	  in	  an	  experimental	  phase.	  However,	  given	  that	  BD	  sources	  can	  </i><br/>
<i>be	  very	  much	  different	  in	  terms	  of	  intrinsic	  characteristics	  and	  access	  modalities,	  even	  at	  </i><br/>
<i>this	  stage	  some	  typologies	  seem	  more	  promising	  in	  terms	  of	  possible	  usage	  on	  the	  short	  </i><br/>
<i>term.	  In	  particular	  mobile	  phone	  data	  and	  data	  deriving	  form	  ‘traditional’	  transaction	  </i><br/>
<i>processing	  systems	  (e.g.,	  scanner	  data)	  appears	  more	  promising	  to	  be	  used	  for	  OS	  </i><br/>
<i>purposes	  in	  the	  short	  term.	  </i><br/>
•&#160;&#160;<i>This	  issue	  of	  measurement	  is	  taken	  up	  in	  the	  proposed	  UNECE	  classification	  system,	  </i><br/>
<i>which	  is	  mostly	  event	  based	  (rather	  than	  about	  separate	  individuals)	  with	  a	  move	  away	  </i><br/>
<i>from	  the	  ‘unit’	  to	  the	  ‘event’,	  or	  from	  people	  to	  places	  (e.g.,	  satel&#160;ite	  images):	  </i><br/>
•&#160;&#160;<i>Human-­‐sourced	  information	  (Social	  Networks)	  <br/></i>•&#160;&#160;<i>Process-­‐mediated	  data	  (Traditional	  Business	  Systems	  and	  Websites)	  <br/></i>•&#160;&#160;<i>Machine-­‐generated	  data	  (Automated	  Systems)	  </i><br/>
	  <br/>
The	  fol&#160;owing	  additional	  questions	  arose	  in	  response	  to	  the	  above	  questions:	  <br/>
4.&#160;Improving&#160;processes&#160;rather&#160;than&#160;producing&#160;outputs?&#160;<br/>In	  the	  face	  of	  the	  many	  questions	  such	  as	  those	  raised	  above,	  the	  potential	  of	  Big	  Data	  to	  <br/>inform	  statistical	  and	  other	  processes	  could	  perhaps	  be	  strategically	  the	  best	  focus	  of	  <br/>experimentation.	  That	  is,	  rather	  than	  testing	  BD	  as	  a	  source	  of	  Official	  Statistics,	  how	  can	  BD	  be	  <br/>used	  to	  monitor,	  evaluate	  and	  improve	  statistical	  processes	  and	  in	  this	  way	  not	  only	  be	  low	  risk	  <br/>but	  enable	  early	  experimentation	  and	  build	  capacity	  working	  with	  new	  forms	  of	  data?	  For	  <br/>example,	  how	  could	  smart	  energy	  meters	  be	  used	  to	  identify	  vacant	  properties	  and	  the	  optimal	  <br/>times	  that	  people	  are	  at	  home	  and	  available	  for	  enumerator	  visits	  and	  thereby	  improve	  <br/>response	  rates	  and	  decrease	  revisits?	  <br/>
With	  the	  increasing	  move	  to	  online	  censuses,	  government	  services	  and	  surveys,	  the	  potential	  of	  <br/>paradata	  (usage	  and	  behaviour	  data	  such	  as	  clicks,	  duration,	  pages	  read;	  also	  field	  operational	  <br/>data)	  is	  another	  potential	  area	  for	  experimentation.	  &#160;While	  stil&#160;	  raising	  questions	  of	  ethics,	  if	  <br/>made	  transparent,	  paradata	  could	  be	  used	  to	  improve	  statistical	  data	  col&#160;ection	  processes.	  <br/>
This	  aspect	  of	  BD,	  which	  could	  be	  called	  a	  process	  orientation,	  cuts	  across	  and	  addresses	  all	  of	  <br/>the	  three	  themes	  above.	  &#160;It	  changes	  the	  focus	  of	  each	  of	  the	  themes—whether	  about	  <br/>measures,	  respondents	  or	  ethics—to	  how	  BD	  can	  serve	  as	  a	  supplement	  to	  and	  improvement	  of	  <br/>Official	  Statistics.	  <br/>
53	  <br/>
	  <br/>
<hr/>
<a name=54></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
5.&#160;Not&#160;just&#160;methods&#160;but&#160;a&#160;change&#160;in&#160;organisational&#160;cultures&#160;and&#160;thinking?&#160;&#160;<br/>Many	  of	  the	  issues	  raised	  at	  events	  and	  meetings	  involve	  the	  repetition	  and	  sometimes	  over	  <br/>generalisation	  of	  issues.	  &#160;There	  is	  also	  much	  resistance	  expressed	  to	  change,	  of	  statisticians	  <br/>holding	  back	  and	  waiting	  to	  see	  what	  others	  do,	  etc.	  The	  initial	  reaction	  of	  statisticians	  to	  the	  <br/>new	  opportunities	  afforded	  by	  BD	  was	  previously	  and	  for	  some	  continues	  to	  be	  that	  of	  <br/>scepticism.	  They	  are	  generally	  risk	  adverse	  and	  come	  out	  of	  rigid	  institutional	  structures.	  One	  <br/>definition	  of	  BD	  offered	  that	  reflected	  this	  and	  which	  could	  be	  interpreted	  as	  a	  search	  for	  a	  way	  <br/>to	  retain	  authority	  was	  that	  of	  ‘secondary	  data’.	  An	  alternative	  reaction	  was	  to	  re-­‐brand	  <br/>statistics	  as	  ‘Greater	  Statistics’.	  &#160;	  <br/>
In	  response	  to	  these	  observations	  and	  arising	  from	  a	  number	  of	  conversations,	  it	  was	  suggested	  <br/>that	  part	  of	  instil&#160;ing	  a	  new	  culture	  involves	  the	  reiteration	  of	  statements	  as	  a	  way	  for	  a	  <br/>community	  to	  emerge	  around	  common	  problematisations	  and	  concepts.	  That	  is,	  existing	  and	  <br/>accepted	  methodologies	  such	  as	  censuses	  and	  surveys	  emerged	  over	  a	  long	  period	  of	  time	  and	  <br/>debate	  through	  various	  transnational	  forums	  and	  practices.	  &#160;At	  certain	  points	  in	  time	  what	  <br/>could	  be	  called	  a	  relatively	  stable	  ‘technical	  settlement’	  was	  reached.	  &#160;That	  is	  perhaps	  one	  way	  <br/>to	  describe	  the	  current	  situation	  with	  respect	  to	  BD.	  However,	  there	  are	  many	  differences.	  &#160;In	  <br/>addition	  to	  the	  issues	  of	  ownership	  of	  data	  and	  reliance	  on	  the	  practices	  of	  others	  (e.g.,	  <br/>industry	  or	  admin	  data	  owners)	  a	  different	  and	  experimental	  approach	  is	  required.	  &#160;As	  <br/>expressed	  under	  the	  first	  theme,	  BD	  does	  not	  call	  for	  the	  usual	  practice	  of	  ‘designing	  then	  <br/>col&#160;ecting’	  but	  ‘col&#160;ecting	  then	  designing’.	  &#160;The	  latter	  involves	  an	  experimental	  orientation,	  of	  <br/>working	  with	  data	  to	  test	  its	  qualities,	  uncertainties,	  capacities,	  patterns	  and	  so	  on	  and	  through	  <br/>which	  new	  methods,	  concepts	  and	  measures	  can	  be	  generated	  and	  debated	  and	  new	  technical	  <br/>settlements	  can	  perhaps	  be	  established.	  &#160;To	  do	  so	  requires	  organisational	  cultures	  that	  are	  agile	  <br/>and	  flexible,	  and	  able	  to	  engage	  in	  experiments,	  simulations	  and	  model&#160;ing.	  As	  the	  sandbox	  and	  <br/>innovation	  labs	  have	  shown,	  these	  require	  not	  only	  new	  computational	  techniques	  but	  new	  <br/>technical	  infrastructures.	  <br/>
a. Data science is&#160;not a person but a distributed set of&#160;skills?&#160;<br/>Many	  comments	  note	  that	  the	  required	  skil&#160;s	  to	  work	  with	  BD	  are	  distributed	  amongst	  a	  team	  –	  <br/>methodologists	  and	  IT	  people	  -­‐	  rather	  than	  residing	  in	  any	  one	  person	  such	  as	  a	  ‘data	  scientist’.	  <br/>‘Data	  science’	  is	  also	  described	  as	  a	  mindset	  rather	  than	  a	  person.	  <br/>
b.&#160;From&#160;NSI-lead to collectivised processes&#160;of&#160;innovation?&#160;&#160;<br/>One	  model	  of	  innovation	  that	  is	  being	  experimented	  with	  involves	  statisticians	  from	  across	  NSIs	  <br/>working	  together	  with	  BD	  to	  test	  and	  model	  phenomena	  (e.g.,	  UNECE	  sandbox	  project)	  as	  <br/>opposed	  to	  the	  more	  usual	  decentralised	  practice	  of	  NSI’s	  developing	  new	  methods	  and	  then	  <br/>sharing	  with	  others	  as	  best	  practice.	  Though	  the	  latter	  is	  often	  mutually	  informed	  the	  former	  is	  <br/>a	  different	  site	  and	  practice	  of	  innovation.	  Such	  col&#160;aborations	  with	  various	  experts	  and	  <br/>
54	  <br/>
	  <br/>
<hr/>
<a name=55></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
stakeholders	  are	  also	  a	  means	  of	  reducing	  investment	  costs	  and	  developing	  methodologies	  <br/>especially	  at	  a	  time	  of	  cutbacks	  and	  austerity.	  <br/>
6.&#160;A&#160;new&#160;statistical&#160;leadership&#160;role&#160;for&#160;NSIs?&#160;<br/>BD	  is	  an	  opportunity	  for	  NSIs	  to	  show	  responsible	  statistical	  leadership	  through	  their	  adherence	  <br/>to	  the	  recently	  adopted	  UN	  Fundamental	  Principles	  of	  Statistics	  (impartiality,	  reliability,	  <br/>relevancy,	  profitability,	  confidentiality	  and	  transparency).	  This	  could	  include	  providing	  <br/>accreditation	  or	  certification	  on	  different	  data	  and	  measures.	  <br/>
Statistical	  organisations	  already	  have	  an	  advantage:	  &#160;their	  capacity	  to	  work	  with	  a	  range	  of	  data	  <br/>sources	  and	  statistical	  outputs.	  They	  already	  have	  long-­‐tested	  skil&#160;s	  validating,	  aggregating	  and	  <br/>combining	  data	  from	  different	  sources.	  This	  may	  be	  a	  future	  role	  where	  analysis	  rather	  than	  <br/>col&#160;ection	  is	  the	  primary	  mode	  of	  activity.	  <br/>
	  <br/>
	  <br/>
	  <br/>
	  <br/>
	  <br/>
	  <br/>
	  <br/>
	  <br/>
	  <br/>
	  <br/>
55	  <br/>
	  <br/>
<hr/>
<a name=56></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
<b>Collaboratory&#160;3:&#160;Urban&#160;Waste&#160;Management&#160;</b><br/>
Policy&#160;and&#160;behaviour&#160;change&#160;<br/>In	  the	  last	  ten	  years,	  the	  Greater	  Manchester	  Waste	  Disposal	  Authority	  (GMWDA)	  has	  made	  <br/>great	  improvements	  in	  diverting	  waste	  from	  landfil&#160;	  (from	  4%	  in	  2003	  to	  55%	  in	  2014)	  but	  the	  <br/>Authority	  is	  striving	  to	  improve	  on	  this	  target	  and	  to	  ensure	  that	  there	  is	  75-­‐90%	  diversion	  by	  <br/>2019-­‐2020.	  By	  this	  date	  they	  have	  also	  set	  themselves	  the	  ambitious	  target	  of	  an	  overall	  42-­‐<br/>50%	  recycling	  rate.	  In	  order	  to	  achieve	  these	  aims,	  they	  are	  testing	  a	  number	  of	  different	  types	  <br/>of	  public	  engagement	  and	  using	  a	  variety	  of	  communication	  campaigns	  to	  try	  to	  create	  <br/>behaviour	  change.	  To	  reach	  national	  and	  EU	  targets,	  the	  authority	  needs	  to	  maximise	  the	  <br/>quantity	  and	  quality	  of	  recyclable	  materials	  that	  they	  col&#160;ect.	  This	  requires	  col&#160;aboration	  from	  <br/>the	  public	  to	  sort	  their	  rubbish	  more	  accurately.	  A	  Waste	  Composition	  Analysis	  conducted	  in	  <br/>2011	  found	  that	  74%	  of	  the	  waste	  in	  residual	  bins	  could	  be	  recycled.	  An	  EU	  LIFE	  +	  project	  has	  <br/>been	  exploring	  the	  impact	  of	  a	  number	  of	  communication	  campaigns	  on	  ‘low	  performing’	  <br/>areas.	  The	  project	  is	  looking	  at	  tonnage	  data	  and	  trying	  to	  match	  this	  data	  to	  metrics	  of	  <br/>participation	  of	  households	  and	  the	  performance	  of	  each	  authority.	  It	  has	  come	  up	  against	  <br/>many	  methodological	  challenges.	  Waste	  is	  inherently	  complex	  and	  behaviour	  patterns	  are	  <br/>difficult	  to	  detect	  in	  the	  current	  data	  which	  is	  available.	  Social	  scientists	  point	  out	  that	  obtaining	  <br/>accurate	  data	  on	  waste	  in	  urban	  areas	  is	  notoriously	  difficult,	  particularly	  in	  areas	  with	  dense	  <br/>and	  mobile	  populations.	  There	  are	  many	  connections	  which	  cannot	  be	  explained.	  For	  example,	  <br/>it	  was	  expected	  that	  low	  recycling	  rates	  would	  exist	  in	  areas	  with	  high	  deprivation	  but	  this	  was	  <br/>not	  uniformly	  found	  in	  the	  data.	  Also,	  in	  some	  areas	  after	  communication	  campaigns	  the	  <br/>tonnage	  of	  waste	  col&#160;ected	  had	  gone	  down	  but	  the	  participation	  has	  gone	  up,	  or	  vice-­‐versa.	  <br/>
In	  recent	  years	  recycling	  rates	  have	  started	  to	  level	  off.	  It	  is	  questioned	  whether	  residents	  have	  <br/>reached	  the	  limit	  of	  habitual	  change.	  Social	  science	  research	  suggests	  that	  recycling	  rates	  <br/>should	  be	  understood	  in	  relation	  to	  existing	  social	  practices	  and	  consideration	  of	  the	  <br/>infrastructural	  difficulties	  for	  recyclates	  storage	  and	  col&#160;ections.	  The	  Authority	  argued	  that	  they	  <br/>must	  bring	  about	  ‘behaviour	  change’	  among	  residents	  by	  encouraging	  education	  about	  <br/>resource	  efficiency	  and	  promoting	  wider	  ‘cultural	  change’	  around	  sustainability.	  They	  are	  <br/>interested	  in	  whether	  Big	  Data	  could	  assist	  them	  in	  their	  efforts	  to	  understand	  what	  makes	  a	  <br/>‘good’	  and	  accurate	  recycler	  and	  to	  target	  resources	  for	  those	  who	  do	  not	  comply.	  On	  this	  <br/>issue,	  there	  was	  considerable	  dissent	  from	  the	  social	  scientists,	  who	  reiterated	  the	  point	  that	  <br/>the	  use	  of	  this	  kind	  of	  terminology	  was	  problematic	  and	  could	  result	  in	  further	  stigmatisation	  of	  <br/>marginalised	  individuals.	  <br/>
Data metrics&#160;<br/>The	  GMWDA	  relies	  on	  specific	  kinds	  of	  data	  flows	  of	  the	  tonnage	  data	  concerning	  the	  materials	  <br/>which	  are	  col&#160;ected.	  Every	  year,	  a	  total	  of	  36,000	  individual	  tickets	  are	  created	  and	  900,000	  tons	  <br/>
56	  <br/>
	  <br/>
<hr/>
<a name=57></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
of	  waste	  are	  col&#160;ected.	  They	  use	  this	  data	  to	  map	  habits,	  project	  trends	  and	  calculate	  recycling	  <br/>rates.	  Each	  month,	  the	  GMWDA	  use	  tonnage	  information	  to	  calculate	  the	  performance	  in	  each	  <br/>of	  the	  nine	  col&#160;ection	  authorities.	  The	  information	  is	  inputted	  onto	  Defra’s	  Waste	  Data	  Flow,	  a	  <br/>mandatory	  online	  national	  survey	  which	  is	  used	  to	  make	  the	  service	  delivery	  visible	  and	  <br/>operates	  as	  evidence	  that	  the	  contract	  with	  the	  private	  partner	  Viridor	  Laing	  (Greater	  <br/>Manchester)	  Limited,	  is	  being	  realised	  and	  maintained.	  The	  tonnage	  data	  is	  large	  in	  volume	  but	  <br/>does	  not	  classify	  as	  ‘big	  data’	  as	  it	  does	  not	  fit	  the	  criteria	  in	  relation	  to	  velocity	  or	  variety.	  The	  <br/>authority	  is	  interested	  in	  whether	  they	  could	  use	  other	  forms	  of	  real-­‐time	  data	  alongside	  this	  <br/>tonnage	  information	  to	  make	  better	  policy	  decisions,	  deliver	  more	  efficient	  public	  services	  and	  <br/>reach	  new	  EU	  targets.	  <br/>
New metrics&#160;<br/>The	  now	  ubiquitous	  use	  of	  digital	  technologies	  in	  their	  diverse	  forms	  increasingly	  allows	  all	  <br/>kinds	  of	  activities	  to	  become	  informational.	  Data	  is	  routinely	  and	  continuously	  generated	  by	  <br/>devices,	  algorithms,	  instruments,	  and	  platforms	  that	  track	  transactions,	  or	  that	  elicit,	  classify	  <br/>and	  codify	  data	  in	  particular	  ways.	  Transactions	  or	  fluctuations	  can	  be	  tracked,	  counted,	  and	  <br/>modelled.	  The	  exponential	  increase	  in	  computing	  power	  and	  storage	  capacity	  has	  radically	  <br/>changed	  the	  availability	  of	  data,	  its	  modes	  of	  circulation,	  the	  means	  by	  which	  it	  is	  generated	  <br/>and	  presented	  and	  the	  ways	  in	  which	  it	  is	  used	  to	  model	  and	  predict	  future	  conditions	  in	  an	  <br/>ever	  growing	  number	  of	  fields.	  Rather	  than	  producing	  results	  compiled	  by	  recognised	  methods	  <br/>such	  as	  surveys,	  Big	  Data	  offers	  the	  basis	  for	  experimental	  projects	  using	  model&#160;ing	  and	  <br/>simulation	  techniques.	  In	  this	  way	  Big	  Data	  offers	  opportunities	  for	  analysing	  trends	  and	  <br/>patterns	  from	  aggregated	  data	  tracked	  in	  real	  time.	  It	  also	  offers	  opportunities	  for	  creating	  <br/>accurate	  forecasts,	  models	  and	  projections.	  Big	  Data	  sources	  therefore	  have	  the	  potential	  to	  <br/>change	  what	  is	  measured	  and	  how	  value	  is	  attributed.	  <br/>
Bolton	  has	  introduced	  in-­‐cab	  technology	  to	  col&#160;ect	  more	  detailed	  and	  timely	  information	  about	  <br/>their	  col&#160;ection	  rounds.	  The	  introduction	  of	  this	  new	  technology	  signals	  a	  transformation	  from	  a	  <br/>paper	  to	  a	  high	  tech	  digital	  mode	  of	  working	  and	  therefore,	  a	  significant	  change	  in	  working	  <br/>cultures.	  The	  drivers’	  knowledge	  is	  crucial	  to	  deliver	  a	  service	  which	  caters	  for	  the	  needs	  of	  <br/>each	  local	  area.	  In	  Bolton,	  a	  tension	  has	  arisen	  between	  knowledge	  provided	  on	  the	  ‘expert	  <br/>system’	  and	  the	  expert	  knowledge	  of	  the	  drivers.	  The	  Authority	  is	  interested	  in	  whether	  they	  <br/>could	  generate	  data	  continuously	  using	  other	  forms	  of	  digital	  technologies	  which	  could	  predict	  <br/>patterns	  and	  habits.	  For	  example,	  they	  would	  like	  to	  use	  sensors	  to	  record	  the	  quantity	  and	  <br/>quality	  of	  waste	  in	  bins	  and	  therefore	  predict	  future	  waste	  arising.	  The	  data	  could	  be	  used	  to	  <br/>create	  tailored	  services	  rather	  than	  relying	  on	  pre-­‐designed	  routes.	  Rather	  than	  data	  being	  used	  <br/>for	  reactive	  monitoring	  this	  kind	  of	  Big	  Data	  would	  be	  anticipatory	  and	  predictive.	  It	  would	  <br/>open	  up	  the	  possibility	  of	  model&#160;ing,	  simulation	  and	  forecasting.	  This	  wil&#160;	  be	  particularly	  <br/>important	  in	  the	  future.	  <br/>
57	  <br/>
	  <br/>
<hr/>
<a name=58></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
In	  2014,	  the	  EU	  introduced	  a	  new	  Waste	  and	  Circular	  Economy	  Package	  which	  is	  expected	  to	  <br/>change	  the	  way	  in	  which	  waste	  data	  is	  calculated	  so	  that	  a	  single	  methodology	  wil&#160;	  be	  used	  <br/>across	  Europe	  to	  define	  the	  success	  of	  recycling	  rates	  and	  to	  gain	  clearer	  information	  on	  the	  <br/>quality	  of	  materials	  being	  recovered	  and	  circulated	  in	  the	  economy.	  The	  EU	  wil&#160;	  require	  <br/>Member	  States	  to	  carry	  out	  precise	  measurement	  and	  reporting	  of	  what	  is	  actually	  recycled,	  as	  <br/>opposed	  to	  what	  is	  prepared	  for	  recycling.	  Their	  goal	  is	  to	  have	  50%	  of	  municipal	  waste	  being	  <br/>recycled	  by	  2020.	  The	  new	  form	  of	  measurement	  wil&#160;	  require	  waste	  disposal	  authorities	  to	  <br/>record	  the	  quantity	  of	  materials	  recovered	  for	  recycling	  rather	  than	  the	  quantity	  of	  materials	  <br/>diverted	  from	  landfil&#160;	  which	  means	  that	  new	  forms	  of	  measurement	  wil&#160;	  be	  required.	  Recycled	  <br/>materials	  are	  increasingly	  commodities	  which	  are	  being	  traded	  in	  the	  global	  commodity	  <br/>markets.	  <br/>
Re-use&#160;<br/>Re-­‐use	  is	  also	  an	  important	  element	  of	  the	  GMWDA’s	  strategy.	  There	  are	  key	  moments	  where	  <br/>individuals	  throw	  away	  large	  quantities	  of	  waste,	  such	  as	  moving	  house	  or	  after	  the	  death	  of	  a	  <br/>relative.	  Items	  are	  usually	  passed	  along	  a	  social	  network	  or	  they	  are	  disposed	  of.	  The	  <br/>‘lumpiness’	  which	  is	  caused	  by	  these	  incidents	  is	  usually	  written	  out	  of	  large	  data	  models.	  <br/>Existing	  research	  questions	  whether	  the	  individual	  household	  is	  the	  most	  useful	  unit	  of	  analysis	  <br/>as	  materials	  flow	  through	  social	  networks.	  Could	  these	  unexpected	  moments	  of	  social	  life	  be	  <br/>accounted	  for	  in	  the	  data?	  Further,	  is	  the	  household	  the	  most	  useful	  unit	  of	  analysis?	  Would	  it	  <br/>be	  more	  appropriate	  to	  focus	  on	  an	  alternative	  measure	  to	  explore	  behaviour	  change	  such	  as	  <br/>the	  individual	  or	  the	  social	  network?	  <br/>
Big&#160;Data&#160;analytics&#160;<br/>Traditional	  forms	  of	  statistical	  model&#160;ing	  and	  prediction	  depend	  on	  underlying	  regularity	  <br/>whereas	  Big	  Data	  involves	  new	  forms	  of	  uncertainty.	  The	  tools	  which	  are	  used	  are	  open-­‐ended	  <br/>and	  serendipitous.	  It	  is	  not	  possible	  to	  know	  what	  you	  wil&#160;	  find	  in	  advance	  and	  whether	  the	  <br/>data	  wil&#160;	  be	  useful.	  The	  general	  question	  arises	  of	  how	  to	  ensure	  meaningful	  use	  and	  <br/>interpretation	  of	  the	  data.	  Rather	  than	  looking	  for	  averages,	  Big	  Data	  can	  be	  used	  to	  create	  <br/>patterns	  and	  predictions	  in	  order	  to	  understand	  populations	  in	  new	  ways.	  However,	  the	  <br/>experiments	  and	  simulations	  must	  be	  approached	  with	  caution	  as	  connections	  may	  be	  found	  in	  <br/>data	  but	  these	  are	  not	  necessarily	  causal	  or	  meaningful	  relations.	  There	  is	  so	  much	  data	  on	  <br/>offer	  that	  ‘false	  correlations‘	  are	  likely	  to	  emerge,	  and	  such	  ‘findings’	  need	  to	  be	  verified	  by	  <br/>other	  means.	  Also,	  the	  science	  of	  forecasting	  depends	  on	  underlying	  regularities.	  In	  order	  to	  <br/>create	  accurate	  predictions	  data	  must	  be	  compatible.	  The	  question	  arises,	  would	  it	  be	  possible	  <br/>to	  predict	  current	  and	  projected	  data	  trends	  in	  waste	  management?	  <br/>
With	  Big	  Data	  there	  are	  outstanding	  issues	  of	  how	  to	  address	  the	  huge	  volumes	  of	  data	  <br/>generated,	  the	  advantages	  and	  disadvantages	  of	  techniques	  of	  mining	  and	  sampling,	  of	  <br/>
58	  <br/>
	  <br/>
<hr/>
<a name=59></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
generating	  patterns,	  and	  identifying	  trends	  and	  correlations.	  Visualisations	  offer	  a	  powerful	  way	  <br/>of	  displaying	  data	  to	  look	  for	  comparisons,	  correlations	  and	  causation.	  They	  can	  be	  used	  as	  a	  <br/>space	  in	  which	  to	  articulate	  problems	  and	  explore	  solutions	  and	  may	  be	  useful	  when	  we	  do	  not	  <br/>necessarily	  know	  what	  the	  specific	  questions	  we	  want	  to	  explore.	  Also,	  urban	  laboratories	  could	  <br/>be	  useful	  experimental	  spaces	  for	  evidence-­‐based	  research	  providing	  the	  basis	  for	  new	  <br/>col&#160;aborations	  between	  public	  bodies	  and	  academics	  that	  might	  help	  to	  negotiate	  the	  tensions	  <br/>between	  the	  need	  to	  ‘make	  things	  happen’	  and	  the	  potential,	  but	  uncertain,	  benefits	  of	  <br/>exploring	  possibilities	  in	  an	  open-­‐ended	  way.	  <br/>
Openness&#160;and&#160;ethics&#160;<br/>Bins	  are	  not	  exclusive	  property.	  Rather	  they	  and	  their	  contents	  are	  public/private	  col&#160;aborations	  <br/>which	  connect	  the	  householder,	  the	  waste	  col&#160;ection	  authority	  and	  other	  agents.	  &#160;If	  new	  ways	  <br/>of	  measuring	  data,	  such	  as	  sensors,	  are	  introduced	  the	  relationship	  between	  the	  public/private	  <br/>may	  be	  changed	  in	  interesting	  ways.	  Senior	  Officers	  of	  the	  Authority	  believe	  that	  there	  is	  a	  need	  <br/>for	  debating	  the	  potential	  of	  installing	  chips	  in	  bins	  as	  they	  believe	  that	  they	  would	  enable	  them	  <br/>to	  provide	  a	  more	  efficient	  and	  personalised	  service,	  but	  there	  have	  been	  a	  number	  of	  <br/>campaigns	  in	  the	  media	  which	  stress	  that	  chips	  or	  sensors	  in	  bins	  would	  be	  detrimental	  to	  the	  <br/>public,	  akin	  to	  surveil&#160;ance	  technology	  which	  would	  allow	  the	  authority	  to	  ‘spy’	  on	  households.	  <br/>However,	  it	  is	  questioned	  by	  social	  scientists	  whether	  the	  data	  which	  is	  generated	  from	  these	  <br/>devices	  would	  produce	  Big	  Data,	  or	  whether	  the	  data	  would	  simply	  correspond	  to	  existing	  <br/>metrics.	  <br/>
Feedback&#160;to the&#160;public&#160;<br/>There	  is	  a	  high	  level	  of	  mistrust	  about	  putting	  sensors	  into	  bins	  and	  individuals’	  information	  <br/>being	  misused	  but	  there	  are	  other	  possibilities	  about	  what	  waste	  data	  could	  do.	  There	  have	  <br/>been	  a	  number	  of	  trials	  where	  a	  points	  system	  (similar	  to	  supermarket	  nectar	  points)	  has	  been	  <br/>introduced	  to	  incentivise	  recycling.	  With	  this	  technology,	  it	  is	  possible	  for	  individuals	  to	  ‘opt	  in’	  <br/>and	  trace	  their	  personal	  information	  and	  thereby	  support	  an	  ethic	  of	  participation.	  Could	  chips	  <br/>or	  sensors	  on	  bins	  support	  the	  idea	  of	  ownership	  of	  bins,	  so	  individuals	  could	  trace	  their	  bin’s	  <br/>contents?	  If	  data	  could	  be	  used	  to	  personal	  the	  service	  and	  make	  savings,	  could	  the	  sense	  of	  <br/>fear	  and	  paranoia	  about	  data	  sources	  be	  overcome?	  <br/>
Repurposing&#160;of&#160;data&#160;<br/>Big	  Data	  challenges	  linear	  models	  of	  knowledge	  production	  and	  the	  ways	  in	  which	  information	  <br/>can	  be	  used	  to	  make	  decisions.	  Often	  data	  is	  re-­‐purposed.	  It	  is	  connected	  with	  other	  data	  sets	  <br/>and	  therefore	  used	  for	  a	  different	  purpose	  than	  the	  one	  it	  was	  originally	  col&#160;ected	  which	  raises	  <br/>questions	  about	  if	  data	  is	  made	  open,	  what	  could	  it	  connect	  to?	  Some	  members	  of	  the	  public	  <br/>are	  suspicious	  about	  information	  about	  the	  contents	  of	  their	  bin	  being	  col&#160;ected	  and	  shared.	  <br/>Data	  protection	  is	  about	  limiting	  connections	  that	  the	  data	  makes	  and	  the	  area	  is	  fraught	  with	  <br/>
59	  <br/>
	  <br/>
<hr/>
<a name=60></a>Supplementary	  Appendix	  -­‐	  Socialising	  Big	  Data:	  From	  concept	  to	  practice	  <br/>
difficulties	  as	  it	  is	  often	  difficult	  to	  know	  how	  data	  wil&#160;	  be	  repurposed.	  In	  Scandinavian	  countries	  <br/>new	  sensor	  devices	  have	  been	  introduced	  as	  there	  issues	  about	  trust	  are	  approached	  <br/>differently	  which	  signals	  a	  different	  relationship	  between	  the	  authority	  and	  the	  public.	  <br/>
Local	  authorities	  are	  under	  increased	  financial	  pressure	  and	  have	  less	  staff	  than	  ever	  before.	  <br/>Could	  private	  sector	  companies	  assist	  them	  and	  devise	  new	  apps	  with	  their	  data?	  Or,	  would	  it	  <br/>be	  possible	  for	  the	  GMWDA	  to	  learn	  from	  private	  sector	  companies	  and	  to	  use	  individual’s	  data	  <br/>while	  ensuring	  that	  personal	  details	  are	  kept	  private?	  Even	  though	  there	  was	  clear	  interest	  and	  <br/>support	  in	  the	  run-­‐up	  to	  the	  col&#160;aboratory	  from	  people	  working	  in	  the	  private	  waste	  sector,	  <br/>they	  did	  not	  attend	  at	  short	  notice.	  This	  meant	  that	  our	  discussions	  were	  limited	  in	  relation	  to	  <br/>these	  issues	  and	  the	  questions	  remains,	  how	  could	  we	  engage	  with	  the	  private	  sector	  on	  Big	  <br/>Data	  questions?	  <br/>
	  <br/>
60	  <br/>
	  <br/>
<hr/>
</body>
</html>
